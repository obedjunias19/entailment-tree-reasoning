{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c09eae3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:57.196768Z",
     "iopub.status.busy": "2025-11-18T03:40:57.196146Z",
     "iopub.status.idle": "2025-11-18T03:40:58.612576Z",
     "shell.execute_reply": "2025-11-18T03:40:58.611544Z"
    },
    "papermill": {
     "duration": 1.423352,
     "end_time": "2025-11-18T03:40:58.613877",
     "exception": false,
     "start_time": "2025-11-18T03:40:57.190525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_all_hf.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6bc630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.623479Z",
     "iopub.status.busy": "2025-11-18T03:40:58.623049Z",
     "iopub.status.idle": "2025-11-18T03:40:58.627779Z",
     "shell.execute_reply": "2025-11-18T03:40:58.627256Z"
    },
    "papermill": {
     "duration": 0.010688,
     "end_time": "2025-11-18T03:40:58.628857",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.618169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# train_df = pd.DataFrame(data[\"questions\"])\n",
    "# train_df.to_csv('train_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# dev_df = pd.DataFrame(data[\"questions\"])\n",
    "# dev_df.to_csv('dev_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# dev_df.head()\n",
    "\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# test_df = pd.DataFrame(data[\"questions\"])\n",
    "# test_df.to_csv('test_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6857f089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.638655Z",
     "iopub.status.busy": "2025-11-18T03:40:58.638205Z",
     "iopub.status.idle": "2025-11-18T03:40:58.641070Z",
     "shell.execute_reply": "2025-11-18T03:40:58.640535Z"
    },
    "papermill": {
     "duration": 0.00788,
     "end_time": "2025-11-18T03:40:58.642138",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.634258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297c0c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.649728Z",
     "iopub.status.busy": "2025-11-18T03:40:58.649548Z",
     "iopub.status.idle": "2025-11-18T03:40:58.654961Z",
     "shell.execute_reply": "2025-11-18T03:40:58.654425Z"
    },
    "papermill": {
     "duration": 0.010584,
     "end_time": "2025-11-18T03:40:58.655960",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.645376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "# import ast\n",
    "\n",
    "# # Load your dataset\n",
    "# df = pd.read_csv(\"/kaggle/working/train_logical_combinations_output.csv\")  # replace with your file\n",
    "\n",
    "# # Safe eval to ensure lists are properly loaded\n",
    "# def safe_eval(val):\n",
    "#     if isinstance(val, list):\n",
    "#         return val\n",
    "#     if pd.isna(val):\n",
    "#         return []\n",
    "#     if isinstance(val, str):\n",
    "#         try:\n",
    "#             return ast.literal_eval(val)\n",
    "#         except:\n",
    "#             return []\n",
    "#     return []\n",
    "\n",
    "# df['logical_combinations'] = df['logical_combinations'].apply(safe_eval)\n",
    "\n",
    "# # Prepare storage for QA sets\n",
    "# qa_sets = {\n",
    "#     'AND': [],\n",
    "#     'OR': [],\n",
    "#     'NEITHER': [],\n",
    "#     'Mixed': []\n",
    "# }\n",
    "\n",
    "# # Label rotation - separate rotator for each question type\n",
    "# class LabelRotator:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.labels = ['A', 'B', 'C', 'D']\n",
    "#         self.current_index = 0\n",
    "    \n",
    "#     def get_next_label(self):\n",
    "#         label = self.labels[self.current_index]\n",
    "#         self.current_index = (self.current_index + 1) % len(self.labels)\n",
    "#         # print(f\"DEBUG {self.name}: Assigned label {label}, next will be {self.labels[self.current_index]}\")\n",
    "#         return label\n",
    "\n",
    "# # Create separate rotators for each question type\n",
    "# rotators = {\n",
    "#     'AND': LabelRotator('AND'),\n",
    "#     'OR': LabelRotator('OR'),\n",
    "#     'NEITHER': LabelRotator('NEITHER'),\n",
    "#     'Mixed': LabelRotator('Mixed')\n",
    "# }\n",
    "\n",
    "# def create_qa_item(question, correct_ans, incorrect_ans, qa_type):\n",
    "#     \"\"\"Helper function to create a QA item with proper label rotation\"\"\"\n",
    "    \n",
    "#     # Get correct label from the appropriate rotator\n",
    "#     correct_label = rotators[qa_type].get_next_label()\n",
    "    \n",
    "#     # Ensure we have exactly 3 incorrect answers\n",
    "#     if len(incorrect_ans) < 3:\n",
    "#         print(f\"Warning: Only {len(incorrect_ans)} incorrect answers available for {qa_type}\")\n",
    "#         return None\n",
    "    \n",
    "#     selected_incorrect = random.sample(incorrect_ans, 3)\n",
    "    \n",
    "#     # Create options array with 4 positions\n",
    "#     options = [''] * 4\n",
    "    \n",
    "#     # Place correct answer at the designated position\n",
    "#     correct_pos = rotators[qa_type].labels.index(correct_label)\n",
    "#     options[correct_pos] = correct_ans\n",
    "    \n",
    "#     # Fill remaining positions with incorrect answers\n",
    "#     incorrect_positions = [i for i in range(4) if i != correct_pos]\n",
    "#     for i, pos in enumerate(incorrect_positions):\n",
    "#         options[pos] = selected_incorrect[i]\n",
    "    \n",
    "#     return {\n",
    "#         'question': question,\n",
    "#         'A': options[0],\n",
    "#         'B': options[1],\n",
    "#         'C': options[2],\n",
    "#         'D': options[3],\n",
    "#         'correct_label': correct_label,\n",
    "#         'correct_answer_text': correct_ans,\n",
    "#         'qa_type': qa_type\n",
    "#     }\n",
    "\n",
    "# # Track counts for each type\n",
    "# type_counts = {'AND': 0, 'OR': 0, 'NEITHER': 0, 'Mixed': 0}\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     question = row['question']\n",
    "#     combos = row['logical_combinations']\n",
    "    \n",
    "#     # Extract AND/OR/NEITHER correct and incorrect lists\n",
    "#     and_correct = combos.get('AND_combinations', {}).get('correct', [])\n",
    "#     and_incorrect = combos.get('AND_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     or_correct = combos.get('OR_combinations', {}).get('correct', [])\n",
    "#     or_incorrect = combos.get('OR_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     neither_correct = combos.get('NEITHER_combinations', {}).get('correct', [])\n",
    "#     neither_incorrect = combos.get('NEITHER_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     # --- AND-only QA ---\n",
    "#     if and_correct and len(and_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(and_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, and_incorrect, 'AND')\n",
    "#         if qa_item:\n",
    "#             qa_sets['AND'].append(qa_item)\n",
    "#             type_counts['AND'] += 1\n",
    "#             # print(f\"AND Question {type_counts['AND']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- OR-only QA ---\n",
    "#     if or_correct and len(or_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(or_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, or_incorrect, 'OR')\n",
    "#         if qa_item:\n",
    "#             qa_sets['OR'].append(qa_item)\n",
    "#             type_counts['OR'] += 1\n",
    "#             # print(f\"OR Question {type_counts['OR']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- NEITHER-only QA ---\n",
    "#     if neither_correct and len(neither_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(neither_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, neither_incorrect, 'NEITHER')\n",
    "#         if qa_item:\n",
    "#             qa_sets['NEITHER'].append(qa_item)\n",
    "#             type_counts['NEITHER'] += 1\n",
    "#             # print(f\"NEITHER Question {type_counts['NEITHER']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- Mixed QA ---\n",
    "#     all_correct_types = [\n",
    "#         ('AND', and_correct),\n",
    "#         ('OR', or_correct),\n",
    "#         ('NEITHER', neither_correct)\n",
    "#     ]\n",
    "#     all_incorrect_types = and_incorrect + or_incorrect + neither_incorrect\n",
    "    \n",
    "#     # Ensure at least one correct exists and enough incorrect answers\n",
    "#     valid_categories = [cat for cat, lst in all_correct_types if lst]\n",
    "#     if valid_categories and len(all_incorrect_types) >= 3:\n",
    "#         chosen_category = random.choice(valid_categories)\n",
    "#         chosen_correct_list = dict(all_correct_types)[chosen_category]\n",
    "#         correct_ans = random.choice(chosen_correct_list)\n",
    "#         qa_item = create_qa_item(question, correct_ans, all_incorrect_types, 'Mixed')\n",
    "#         if qa_item:\n",
    "#             qa_sets['Mixed'].append(qa_item)\n",
    "#             type_counts['Mixed'] += 1\n",
    "#             # print(f\"Mixed Question {type_counts['Mixed']}: Label {qa_item['correct_label']}\")\n",
    "\n",
    "# print(f\"\\n=== GENERATION COMPLETE ===\")\n",
    "# for qtype, count in type_counts.items():\n",
    "#     print(f\"{qtype}: {count} questions generated\")\n",
    "\n",
    "# # --- Convert to DataFrames and save ---\n",
    "# for key, qlist in qa_sets.items():\n",
    "#     if qlist:  # Only save if we have questions\n",
    "#         df_out = pd.DataFrame(qlist)\n",
    "#         df_out.to_csv(f'train_qa_{key}.csv', index=False)\n",
    "#         print(f\"\\n{key} QA saved: {len(df_out)} questions in train_qa_{key}.csv\")\n",
    "        \n",
    "#         # Show label distribution for verification\n",
    "#         label_counts = df_out['correct_label'].value_counts().sort_index()\n",
    "#         print(f\"  Label distribution: {dict(label_counts)}\")\n",
    "        \n",
    "#         # Show label sequence for first 8 questions to verify rotation\n",
    "#         print(f\"  Label sequence (first 8): {list(df_out['correct_label'].head(8))}\")\n",
    "#     else:\n",
    "#         print(f\"{key}: No valid QA pairs generated\")\n",
    "\n",
    "# # Overall statistics\n",
    "# total_questions = sum(len(qlist) for qlist in qa_sets.values())\n",
    "# print(f\"\\nFinal total questions generated: {total_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096dfbb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.663430Z",
     "iopub.status.busy": "2025-11-18T03:40:58.663008Z",
     "iopub.status.idle": "2025-11-18T03:40:58.665695Z",
     "shell.execute_reply": "2025-11-18T03:40:58.665190Z"
    },
    "papermill": {
     "duration": 0.007517,
     "end_time": "2025-11-18T03:40:58.666743",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.659226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and  = pd.read_csv('/kaggle/working/test_qa_AND.csv')\n",
    "\n",
    "# train_qa_and.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d207e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.673903Z",
     "iopub.status.busy": "2025-11-18T03:40:58.673706Z",
     "iopub.status.idle": "2025-11-18T03:40:58.676449Z",
     "shell.execute_reply": "2025-11-18T03:40:58.675941Z"
    },
    "papermill": {
     "duration": 0.007508,
     "end_time": "2025-11-18T03:40:58.677397",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.669889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3849dd1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.684587Z",
     "iopub.status.busy": "2025-11-18T03:40:58.684318Z",
     "iopub.status.idle": "2025-11-18T03:40:58.687801Z",
     "shell.execute_reply": "2025-11-18T03:40:58.687139Z"
    },
    "papermill": {
     "duration": 0.008295,
     "end_time": "2025-11-18T03:40:58.688888",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.680593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# and_df = pd.read_csv(\"train_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"train_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"train_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"train_qa_Mixed.csv\")\n",
    "\n",
    "# train_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# train_df.to_csv(\"train_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"dev_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"dev_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"dev_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"dev_qa_Mixed.csv\")\n",
    "\n",
    "# dev_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# dev_df.to_csv(\"dev_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"test_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"test_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"test_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"test_qa_Mixed.csv\")\n",
    "\n",
    "# test_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# test_df.to_csv(\"test_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e014bb07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.696664Z",
     "iopub.status.busy": "2025-11-18T03:40:58.696169Z",
     "iopub.status.idle": "2025-11-18T03:40:58.699365Z",
     "shell.execute_reply": "2025-11-18T03:40:58.698844Z"
    },
    "papermill": {
     "duration": 0.008239,
     "end_time": "2025-11-18T03:40:58.700369",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.692130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "# train_df[\"choices\"] = train_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# train_df[\"label\"] = train_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_train_df = train_df[[\"question\", \"choices\", \"label\", \"qa_type\"]]\n",
    "\n",
    "# hf_train_df.to_json(\"train_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# dev_df[\"choices\"] = dev_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# dev_df[\"label\"] = dev_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_dev_df = dev_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_dev_df.to_json(\"dev_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "# test_df[\"choices\"] = test_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# test_df[\"label\"] = test_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_test_df = test_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_test_df.to_json(\"test_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b4466b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.707706Z",
     "iopub.status.busy": "2025-11-18T03:40:58.707508Z",
     "iopub.status.idle": "2025-11-18T03:40:58.710246Z",
     "shell.execute_reply": "2025-11-18T03:40:58.709717Z"
    },
    "papermill": {
     "duration": 0.007553,
     "end_time": "2025-11-18T03:40:58.711307",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.703754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651ecee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:40:58.718464Z",
     "iopub.status.busy": "2025-11-18T03:40:58.718212Z",
     "iopub.status.idle": "2025-11-18T03:41:10.203288Z",
     "shell.execute_reply": "2025-11-18T03:41:10.202355Z"
    },
    "papermill": {
     "duration": 11.490236,
     "end_time": "2025-11-18T03:41:10.204612",
     "exception": false,
     "start_time": "2025-11-18T03:40:58.714376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n",
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "✓ PyArrow 19.0.1\n",
      "✓ Datasets 4.4.1\n",
      "✓ Transformers 4.53.3\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Clean uninstall everything\n",
    "# !pip uninstall -y protobuf pyarrow google-protobuf datasets transformers accelerate bitsandbytes peft trl\n",
    "\n",
    "# # Step 2: Install in the correct order with compatible versions\n",
    "!pip install --upgrade --no-cache-dir protobuf==3.20.3\n",
    "# !pip install --no-cache-dir pyarrow==12.0.1\n",
    "# !pip install --no-cache-dir datasets==2.14.0\n",
    "# !pip install --no-cache-dir transformers==4.35.2\n",
    "# !pip install --no-cache-dir accelerate\n",
    "\n",
    "# Step 3: Verify installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "try:\n",
    "    import pyarrow as pa\n",
    "    print(f\"✓ PyArrow {pa.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PyArrow failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"✓ Datasets {datasets.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Datasets failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import __version__\n",
    "    print(f\"✓ Transformers {__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Transformers failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfe0408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:41:10.213462Z",
     "iopub.status.busy": "2025-11-18T03:41:10.213061Z",
     "iopub.status.idle": "2025-11-18T03:41:10.216437Z",
     "shell.execute_reply": "2025-11-18T03:41:10.215870Z"
    },
    "papermill": {
     "duration": 0.008969,
     "end_time": "2025-11-18T03:41:10.217588",
     "exception": false,
     "start_time": "2025-11-18T03:41:10.208619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Uninstall and reinstall datasets with matching pyarrow version\n",
    "# !pip uninstall -y datasets  pyarrow\n",
    "# !pip install --no-cache-dir pyarrow\n",
    "# !pip install --no-cache-dir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27744a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:41:10.225798Z",
     "iopub.status.busy": "2025-11-18T03:41:10.225366Z",
     "iopub.status.idle": "2025-11-18T03:41:17.182263Z",
     "shell.execute_reply": "2025-11-18T03:41:17.181387Z"
    },
    "papermill": {
     "duration": 6.962553,
     "end_time": "2025-11-18T03:41:17.183813",
     "exception": false,
     "start_time": "2025-11-18T03:41:10.221260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\r\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyarrow, evaluate\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45f347f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:41:17.195065Z",
     "iopub.status.busy": "2025-11-18T03:41:17.194813Z",
     "iopub.status.idle": "2025-11-18T03:41:17.199530Z",
     "shell.execute_reply": "2025-11-18T03:41:17.198794Z"
    },
    "papermill": {
     "duration": 0.011701,
     "end_time": "2025-11-18T03:41:17.200580",
     "exception": false,
     "start_time": "2025-11-18T03:41:17.188879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "# from transformers import TrainingArguments, Trainer, DataCollatorForMultipleChoice\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import json\n",
    "# import evaluate\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # Custom Dataset class to replace datasets.load_dataset\n",
    "# import json\n",
    "\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item[\"qa_type\"] \n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type \n",
    "#         }\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", tokenizer)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", tokenizer)\n",
    "\n",
    "# data_collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "\n",
    "# # Rest of your code remains the same\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = p.predictions.argmax(-1)\n",
    "#     return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./deberta-v3-mcqa\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=1e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=4,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_steps=50,\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe3160",
   "metadata": {
    "papermill": {
     "duration": 0.004439,
     "end_time": "2025-11-18T03:41:17.209502",
     "exception": false,
     "start_time": "2025-11-18T03:41:17.205063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ba7d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:41:17.220193Z",
     "iopub.status.busy": "2025-11-18T03:41:17.220002Z",
     "iopub.status.idle": "2025-11-18T03:41:17.230860Z",
     "shell.execute_reply": "2025-11-18T03:41:17.230336Z"
    },
    "papermill": {
     "duration": 0.018018,
     "end_time": "2025-11-18T03:41:17.232021",
     "exception": false,
     "start_time": "2025-11-18T03:41:17.214003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch\n",
    "# from torch.optim import AdamW\n",
    "# from tqdm.auto import tqdm\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import random\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# training_config = {\n",
    "#     'max_epochs': 10,\n",
    "#     'patience': 3,  # Early stopping patience\n",
    "#     'min_delta': 0.001,  # Minimum improvement to count\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 2e-5,\n",
    "#     'warmup_steps': 500,\n",
    "#     'gradient_accumulation_steps': 2,\n",
    "#     'weight_decay': 0.01,\n",
    "#     'max_length': 256\n",
    "# }\n",
    "\n",
    "# print(\"\\nTraining Configuration:\")\n",
    "# for key, value in training_config.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "# # Custom Dataset\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 if line.strip():\n",
    "#                     self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#         print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "#         # Print dataset statistics\n",
    "#         type_counts = defaultdict(int)\n",
    "#         for item in self.data:\n",
    "#             type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "#         print(\"Dataset composition:\")\n",
    "#         for qa_type, count in sorted(type_counts.items()):\n",
    "#             print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type\n",
    "#         }\n",
    "\n",
    "# def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "#     \"\"\"\n",
    "#     Compute comprehensive metrics for dataset paper\n",
    "#     Returns per-type metrics with BOTH micro and macro averaging\n",
    "#     \"\"\"\n",
    "#     predictions = np.array(predictions)\n",
    "#     labels = np.array(labels)\n",
    "#     qa_types = np.array(qa_types)\n",
    "    \n",
    "#     unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "#     results = {\n",
    "#         'per_type': {},\n",
    "#         'macro_across_types': {},\n",
    "#         'micro_overall': {},\n",
    "#         'confusion_matrices': {}\n",
    "#     }\n",
    "    \n",
    "#     # Per-type metrics (with both micro and macro within type)\n",
    "#     for qa_type in unique_types:\n",
    "#         mask = qa_types == qa_type\n",
    "#         type_preds = predictions[mask]\n",
    "#         type_labels = labels[mask]\n",
    "        \n",
    "#         if len(type_preds) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         # MACRO: Average metrics across the 4 answer choices for this type\n",
    "#         macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # MICRO: Global metrics for this type (same as accuracy)\n",
    "#         micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # Per-class metrics for this type (for detailed analysis)\n",
    "#         per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "#         results['per_type'][qa_type] = {\n",
    "#             # Macro metrics (average across 4 answer choices)\n",
    "#             'macro': {\n",
    "#                 'precision': macro_precision,\n",
    "#                 'recall': macro_recall,\n",
    "#                 'f1': macro_f1,\n",
    "#             },\n",
    "#             # Micro metrics (global for this type)\n",
    "#             'micro': {\n",
    "#                 'precision': micro_precision,  # same as accuracy\n",
    "#                 'recall': micro_recall,        # same as accuracy\n",
    "#                 'f1': micro_f1,                # same as accuracy\n",
    "#                 'accuracy': accuracy,\n",
    "#             },\n",
    "#             # Per-answer-choice metrics\n",
    "#             'per_choice': {\n",
    "#                 f'choice_{i}': {\n",
    "#                     'precision': per_class_precision[i],\n",
    "#                     'recall': per_class_recall[i],\n",
    "#                     'f1': per_class_f1[i],\n",
    "#                     'support': per_class_support[i]\n",
    "#                 } for i in range(4)\n",
    "#             },\n",
    "#             'support': len(type_preds),\n",
    "#             'correct': (type_preds == type_labels).sum()\n",
    "#         }\n",
    "        \n",
    "#         # Confusion matrix for this type\n",
    "#         results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "#             type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "    \n",
    "#     # Macro metrics across logical types (what you typically report in paper)\n",
    "#     macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "#     macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "#     macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "#     macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "#     results['macro_across_types'] = {\n",
    "#         'precision': macro_across_types_precision,\n",
    "#         'recall': macro_across_types_recall,\n",
    "#         'f1': macro_across_types_f1,\n",
    "#         'accuracy': macro_across_types_accuracy\n",
    "#     }\n",
    "    \n",
    "#     # Micro metrics overall (global across all instances)\n",
    "#     micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#         labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#     )\n",
    "#     micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "#     results['micro_overall'] = {\n",
    "#         'accuracy': micro_accuracy,\n",
    "#         'precision': micro_precision,\n",
    "#         'recall': micro_recall,\n",
    "#         'f1': micro_f1,\n",
    "#         'support': len(predictions),\n",
    "#         'correct': (predictions == labels).sum()\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def evaluate_comprehensive(model, dataloader, device):\n",
    "#     \"\"\"Comprehensive evaluation with all metrics\"\"\"\n",
    "#     model.eval()\n",
    "    \n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "#     all_types = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "#             qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "#             all_predictions.extend(predictions.cpu().tolist())\n",
    "#             all_labels.extend(labels.cpu().tolist())\n",
    "#             all_types.extend(qa_types)\n",
    "    \n",
    "#     metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "#     return metrics\n",
    "\n",
    "# def print_results_table(metrics, epoch=None, model_name=None):\n",
    "#     \"\"\"Print results table\"\"\"\n",
    "    \n",
    "#     if epoch is not None:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         if model_name:\n",
    "#             print(f\"Model: {model_name} | Epoch {epoch}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "    \n",
    "#     print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for qa_type in sorted(metrics['per_type'].keys()):\n",
    "#         m_macro = metrics['per_type'][qa_type]['macro']\n",
    "#         m_micro = metrics['per_type'][qa_type]['micro']\n",
    "#         support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "#         print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "#               f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     m = metrics['macro_across_types']\n",
    "#     print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "#     m = metrics['micro_overall']\n",
    "#     print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", \n",
    "#                            tokenizer, max_length=256)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", \n",
    "#                           tokenizer, max_length=256)\n",
    "\n",
    "# # Setup data loaders\n",
    "# batch_size = training_config['batch_size']\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Setup model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"\\nDevice: {device}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Setup optimizer and scheduler\n",
    "# optimizer = AdamW(model.parameters(), \n",
    "#                  lr=training_config['learning_rate'], \n",
    "#                  weight_decay=training_config['weight_decay'])\n",
    "# num_training_steps = training_config['max_epochs'] * len(train_loader) // training_config['gradient_accumulation_steps']\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=training_config['warmup_steps'],\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "# # Training loop with early stopping\n",
    "# best_macro_f1 = 0\n",
    "# best_epoch = 0\n",
    "# epochs_without_improvement = 0\n",
    "# best_metrics = None\n",
    "# training_history = []\n",
    "\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(f\"Training {model_name} with Early Stopping\")\n",
    "# print(f\"Max Epochs: {training_config['max_epochs']}, Patience: {training_config['patience']}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# for epoch in range(training_config['max_epochs']):\n",
    "#     print(f\"\\n{'='*100}\")\n",
    "#     print(f\"Epoch {epoch + 1}/{training_config['max_epochs']}\")\n",
    "#     print(f\"{'='*100}\")\n",
    "    \n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "#     for step, batch in enumerate(progress_bar):\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "#         # Forward pass (no mixed precision for P100)\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "#         loss = outputs.loss / training_config['gradient_accumulation_steps']\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Gradient accumulation\n",
    "#         if (step + 1) % training_config['gradient_accumulation_steps'] == 0:\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "        \n",
    "#         total_loss += loss.item() * training_config['gradient_accumulation_steps']\n",
    "#         progress_bar.set_postfix({\"loss\": f\"{total_loss / (step + 1):.4f}\"})\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     print(f\"\\nTrain Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "#     # Evaluation\n",
    "#     print(\"\\nEvaluating...\")\n",
    "#     metrics = evaluate_comprehensive(model, eval_loader, device)\n",
    "#     print_results_table(metrics, epoch=epoch + 1, model_name=model_name)\n",
    "    \n",
    "#     macro_f1 = metrics['macro_across_types']['f1']\n",
    "#     macro_acc = metrics['macro_across_types']['accuracy']\n",
    "    \n",
    "#     # Save history\n",
    "#     training_history.append({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'train_loss': avg_train_loss,\n",
    "#         'macro_f1': macro_f1,\n",
    "#         'macro_accuracy': macro_acc,\n",
    "#         'macro_precision': metrics['macro_across_types']['precision'],\n",
    "#         'macro_recall': metrics['macro_across_types']['recall']\n",
    "#     })\n",
    "    \n",
    "#     # Early stopping check\n",
    "#     improvement = macro_f1 - best_macro_f1\n",
    "    \n",
    "#     if improvement > training_config['min_delta']:\n",
    "#         best_macro_f1 = macro_f1\n",
    "#         best_epoch = epoch + 1\n",
    "#         best_metrics = metrics\n",
    "#         epochs_without_improvement = 0\n",
    "        \n",
    "#         save_dir = f\"./{model_name.replace('/', '-')}-best\"\n",
    "#         print(f\"\\n  New best Macro F1: {macro_f1:.4f} (↑{improvement:.4f})! Saving to {save_dir}\")\n",
    "#         model.save_pretrained(save_dir)\n",
    "#         tokenizer.save_pretrained(save_dir)\n",
    "        \n",
    "#         def convert_to_serializable(obj):\n",
    "#             if isinstance(obj, dict):\n",
    "#                 return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "#             elif isinstance(obj, (np.integer, np.floating)):\n",
    "#                 return float(obj)\n",
    "#             elif isinstance(obj, np.ndarray):\n",
    "#                 return obj.tolist()\n",
    "#             return obj\n",
    "        \n",
    "#         results_for_paper = {\n",
    "#             'model': model_name,\n",
    "#             'best_epoch': best_epoch,\n",
    "#             'training_config': training_config,\n",
    "#             'training_history': training_history,\n",
    "#             'best_metrics': convert_to_serializable(best_metrics)\n",
    "#         }\n",
    "        \n",
    "#         with open(f\"{save_dir}/results_detailed.json\", \"w\") as f:\n",
    "#             json.dump(results_for_paper, f, indent=2)\n",
    "#     else:\n",
    "#         epochs_without_improvement += 1\n",
    "#         print(f\"\\n⚠ No improvement for {epochs_without_improvement} epoch(s) \"\n",
    "#               f\"(current: {macro_f1:.4f}, best: {best_macro_f1:.4f})\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if epochs_without_improvement >= training_config['patience']:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         print(f\"Early stopping triggered!\")\n",
    "#         print(f\"Best Macro F1: {best_macro_f1:.4f} at epoch {best_epoch}\")\n",
    "#         print(f\"Training stopped at epoch {epoch + 1}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "#         break\n",
    "\n",
    "# # Final summary\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(\"Training Complete!\")\n",
    "# print(f\"{'='*100}\")\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}/{epoch + 1}\")\n",
    "# print(f\"Best Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# if best_metrics is not None:\n",
    "#     print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "#     print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# else:\n",
    "#     print(\"Best Validation Macro F1: n/a (no improvement over initial baseline)\")\n",
    "#     print(\"Best Validation Macro Accuracy: n/a\")\n",
    "\n",
    "\n",
    "# # Plot training curves\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# epochs_list = [h['epoch'] for h in training_history]\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.plot(epochs_list, [h['train_loss'] for h in training_history], marker='o', label='Train Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.plot(epochs_list, [h['macro_f1'] for h in training_history], marker='o', color='green', label='Macro F1')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Macro F1')\n",
    "# plt.title('Validation Macro F1')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.plot(epochs_list, [h['macro_accuracy'] for h in training_history], marker='o', color='blue', label='Macro Accuracy')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Macro Accuracy')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{model_name.replace(\"/\", \"-\")}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "# print(f\"\\n  Saved training curves to {model_name.replace('/', '-')}_training_curves.png\")\n",
    "\n",
    "# # Summary table for paper\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY FOR PAPER:\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}\")\n",
    "# print(f\"Total Epochs Trained: {len(training_history)}\")\n",
    "# print(f\"Converged: {'Yes (early stopping)' if epochs_without_improvement >= training_config['patience'] else 'No (completed all epochs)'}\")\n",
    "# print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93d30ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:41:17.242448Z",
     "iopub.status.busy": "2025-11-18T03:41:17.242074Z",
     "iopub.status.idle": "2025-11-18T03:45:33.636214Z",
     "shell.execute_reply": "2025-11-18T03:45:33.635315Z"
    },
    "papermill": {
     "duration": 256.400861,
     "end_time": "2025-11-18T03:45:33.637500",
     "exception": false,
     "start_time": "2025-11-18T03:41:17.236639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Configuration:\n",
      "  batch_size: 4\n",
      "  max_length: 256\n",
      "Model: bert-base-uncased\n",
      "\n",
      "Loading model: bert-base-uncased...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a7821a4b934db2a560252685d51689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec31f7b2d6904afeb9fce5e855abdbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b01d9582685434dac203a995db8443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063fb660ba3b4c528c9d9eaa098acba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 03:41:28.947144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763437289.130301      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763437289.184130      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b6b92057124ed188ea77cafe23d9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6000 examples from /kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 1500 (25.0%)\n",
      "  Mixed: 1500 (25.0%)\n",
      "  NEITHER: 1500 (25.0%)\n",
      "  OR: 1500 (25.0%)\n",
      "Loaded 2000 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 500 (25.0%)\n",
      "  Mixed: 500 (25.0%)\n",
      "  NEITHER: 500 (25.0%)\n",
      "  OR: 500 (25.0%)\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Dev Set Evaluation: bert-base-uncased\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941c717c4f114299afe211b3b4590eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: bert-base-uncased (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.2267     0.2267     0.2267     0.2265     1500\n",
      "Mixed            0.2347     0.2351     0.2347     0.2348     1500\n",
      "NEITHER          0.3233     0.3230     0.3233     0.3231     1500\n",
      "OR               0.2300     0.2297     0.2300     0.2298     1500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.2537     0.2536     0.2537     0.2536        -\n",
      "Micro Avg        0.2537     0.2537     0.2537     0.2537     6000\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Test Set Evaluation: bert-base-uncased\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d4db0b03884281a8b3ce7b584c7fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: bert-base-uncased (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.2060     0.2062     0.2060     0.2044      500\n",
      "Mixed            0.2160     0.2144     0.2160     0.2143      500\n",
      "NEITHER          0.3300     0.3309     0.3300     0.3303      500\n",
      "OR               0.2600     0.2596     0.2600     0.2592      500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.2530     0.2528     0.2530     0.2521        -\n",
      "Micro Avg        0.2530     0.2530     0.2530     0.2530     2000\n",
      "====================================================================================================\n",
      "\n",
      "Results saved to bert-base-uncased_zeroshot_results.json\n",
      "\n",
      "====================================================================================================\n",
      "ZERO-SHOT RESULTS SUMMARY (TEST SET):\n",
      "====================================================================================================\n",
      "Model: bert-base-uncased\n",
      "Evaluation Type: Zero-Shot (No Training)\n",
      "Test Examples: 2000\n",
      "Macro F1 (across types): 0.2521\n",
      "Macro Accuracy (across types): 0.2530\n",
      "Micro F1 (overall): 0.2530\n",
      "Micro Accuracy (overall): 0.2530\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "\n",
    "eval_config = {\n",
    "    'batch_size': 4,  # Can use larger batch for inference\n",
    "    'max_length': 256\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluation Configuration:\")\n",
    "for key, value in eval_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nLoading model: {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "class MCQADataset(Dataset):\n",
    "    def __init__(self, json_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        with open(json_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    self.data.append(json.loads(line.strip()))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "        # Print dataset statistics\n",
    "        type_counts = defaultdict(int)\n",
    "        for item in self.data:\n",
    "            type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "        print(\"Dataset composition:\")\n",
    "        for qa_type, count in sorted(type_counts.items()):\n",
    "            print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item[\"question\"]\n",
    "        choices = item[\"choices\"]\n",
    "        label = item[\"label\"]\n",
    "        qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            [question] * 4,\n",
    "            choices,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(label),\n",
    "            \"qa_type\": qa_type\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "    \"\"\"Compute comprehensive metrics\"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    qa_types = np.array(qa_types)\n",
    "    \n",
    "    unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "    results = {\n",
    "        'per_type': {},\n",
    "        'macro_across_types': {},\n",
    "        'micro_overall': {},\n",
    "        'confusion_matrices': {}\n",
    "    }\n",
    "    \n",
    "    for qa_type in unique_types:\n",
    "        mask = qa_types == qa_type\n",
    "        type_preds = predictions[mask]\n",
    "        type_labels = labels[mask]\n",
    "        \n",
    "        if len(type_preds) == 0:\n",
    "            continue\n",
    "        \n",
    "        macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "        results['per_type'][qa_type] = {\n",
    "            'macro': {\n",
    "                'precision': macro_precision,\n",
    "                'recall': macro_recall,\n",
    "                'f1': macro_f1,\n",
    "            },\n",
    "            'micro': {\n",
    "                'precision': micro_precision,\n",
    "                'recall': micro_recall,\n",
    "                'f1': micro_f1,\n",
    "                'accuracy': accuracy,\n",
    "            },\n",
    "            'per_choice': {\n",
    "                f'choice_{i}': {\n",
    "                    'precision': per_class_precision[i],\n",
    "                    'recall': per_class_recall[i],\n",
    "                    'f1': per_class_f1[i],\n",
    "                    'support': per_class_support[i]\n",
    "                } for i in range(4)\n",
    "            },\n",
    "            'support': len(type_preds),\n",
    "            'correct': (type_preds == type_labels).sum()\n",
    "        }\n",
    "        \n",
    "        results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "            type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "    \n",
    "    macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "    macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "    macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "    macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "    results['macro_across_types'] = {\n",
    "        'precision': macro_across_types_precision,\n",
    "        'recall': macro_across_types_recall,\n",
    "        'f1': macro_across_types_f1,\n",
    "        'accuracy': macro_across_types_accuracy\n",
    "    }\n",
    "    \n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "    )\n",
    "    micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "    results['micro_overall'] = {\n",
    "        'accuracy': micro_accuracy,\n",
    "        'precision': micro_precision,\n",
    "        'recall': micro_recall,\n",
    "        'f1': micro_f1,\n",
    "        'support': len(predictions),\n",
    "        'correct': (predictions == labels).sum()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_zero_shot(model, dataloader, tokenizer, device):\n",
    "    \"\"\"Zero-shot evaluation\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_types = []\n",
    "    \n",
    "    print(\"\\nRunning zero-shot evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            correct_labels = batch[\"labels\"]\n",
    "            qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(correct_labels.cpu().tolist())\n",
    "            all_types.extend(qa_types)\n",
    "    \n",
    "    metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_results_table(metrics, model_name=None):\n",
    "    \"\"\"Print results table\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    if model_name:\n",
    "        print(f\"Model: {model_name} (Zero-Shot)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for qa_type in sorted(metrics['per_type'].keys()):\n",
    "        m_macro = metrics['per_type'][qa_type]['macro']\n",
    "        m_micro = metrics['per_type'][qa_type]['micro']\n",
    "        support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "        print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "              f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    m = metrics['macro_across_types']\n",
    "    print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "    m = metrics['micro_overall']\n",
    "    print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Load test dataset\n",
    "dev_dataset = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_dataset = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Dev Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "dev_metrics = evaluate_zero_shot(model, dev_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(dev_metrics, model_name=model_name)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Test Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "# Save results\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "# Save both\n",
    "results_for_paper = {\n",
    "    'model': model_name,\n",
    "    'evaluation_type': 'zero-shot',\n",
    "    'config': eval_config,\n",
    "    'dev_metrics': convert_to_serializable(dev_metrics),\n",
    "    'test_metrics': convert_to_serializable(test_metrics),\n",
    "}\n",
    "\n",
    "output_file = f\"{model_name.replace('/', '-')}_zeroshot_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results_for_paper, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "# Summary based on test set\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ZERO-SHOT RESULTS SUMMARY (TEST SET):\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Evaluation Type: Zero-Shot (No Training)\")\n",
    "print(f\"Test Examples: {test_metrics['micro_overall']['support']}\")\n",
    "print(f\"Macro F1 (across types): {test_metrics['macro_across_types']['f1']:.4f}\")\n",
    "print(f\"Macro Accuracy (across types): {test_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "print(f\"Micro F1 (overall): {test_metrics['micro_overall']['f1']:.4f}\")\n",
    "print(f\"Micro Accuracy (overall): {test_metrics['micro_overall']['accuracy']:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8229833,
     "sourceId": 13735887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 282.980482,
   "end_time": "2025-11-18T03:45:36.636222",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-18T03:40:53.655740",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02afc5320bdc47f0832aec8e483d4be4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "03a7821a4b934db2a560252685d51689": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1d3657d0af6f44d6896ab32640013790",
        "IPY_MODEL_e8d3589c55be4fa4bae35952cc5c08ee",
        "IPY_MODEL_e2e8bfb650994c81895680a0e0f92116"
       ],
       "layout": "IPY_MODEL_ceffa848378d496181705df997199e1b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "063fb660ba3b4c528c9d9eaa098acba2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3e6f0c2d6e3d437493f30d22db0f20cf",
        "IPY_MODEL_cc223522449e4dd7b579e943b0b92596",
        "IPY_MODEL_274068d9a8a7415795cf8b86945b8869"
       ],
       "layout": "IPY_MODEL_4197ee5e6cf64b9fa12cc8be5ecdd9b4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "07733205a2fd4ca3976405407619e01a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d0933c4bfee4728a584951e0870b58a",
       "placeholder": "​",
       "style": "IPY_MODEL_e1fade2cf0b442e18365ed498358b32a",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "0e8771a15dc64406b083e809d97298d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "144fc03a97a54f3ebc101900873853d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_647e1f1a35094857ad224eb3524cd394",
       "placeholder": "​",
       "style": "IPY_MODEL_899d4a47718546f58e85b4149c91c1a8",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "14f53d9e27794b9eac59bca7c9da726d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1cb3dd5e58c2492fa007dfc06253a312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51aa545fc6154e078fc7fd3607b32e9c",
       "placeholder": "​",
       "style": "IPY_MODEL_02afc5320bdc47f0832aec8e483d4be4",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 3.21MB/s]"
      }
     },
     "1d3657d0af6f44d6896ab32640013790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_504d2d71056a42828711f827ecc37242",
       "placeholder": "​",
       "style": "IPY_MODEL_fd5cdd3858bb4b18917dbe79081e4ec7",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "216e51b575154f3d99d5e58a50451ac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "274068d9a8a7415795cf8b86945b8869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c1711eb05e84affb26df730c355a30d",
       "placeholder": "​",
       "style": "IPY_MODEL_a47f146ec3f64e1facfe87f2c879c20a",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 6.90MB/s]"
      }
     },
     "2d0933c4bfee4728a584951e0870b58a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "327f5156912c4dba97ddaf1f58f53198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "332c2eca2f65479caadaf9af52d3fb9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "38f49d1762ca4bb98f7aec90dd4a3a30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a6f8f55173643dd931d4eaa9fd58857": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e6f0c2d6e3d437493f30d22db0f20cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_758ae4051ece43669a3b85b16b4d9470",
       "placeholder": "​",
       "style": "IPY_MODEL_c8b9ce79e3104e329ba78badca2ff3c8",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "4197ee5e6cf64b9fa12cc8be5ecdd9b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "504d2d71056a42828711f827ecc37242": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "507e42efe2964331a2a3cfdc170b1758": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51aa545fc6154e078fc7fd3607b32e9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "647e1f1a35094857ad224eb3524cd394": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6549856b794945c0a16a608ed37190b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "65b6b92057124ed188ea77cafe23d9f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b45936b7461349d5b1e8d2ce3855f2a4",
        "IPY_MODEL_de3af0f652ce49f3872cdd19440e5775",
        "IPY_MODEL_db9a9d0dc49d42d2b4c1c3888726f39b"
       ],
       "layout": "IPY_MODEL_ca98f3729c174a43ac61cae050d89901",
       "tabbable": null,
       "tooltip": null
      }
     },
     "65bf679b68de40da94422b2dcf3e5813": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6990b2051f8b4b898ce5470f005a3f01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_327f5156912c4dba97ddaf1f58f53198",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_507e42efe2964331a2a3cfdc170b1758",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "6af5034442f14793a42ae0af402c38a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f8d2377f11e45c7aaed824fe564e101": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "723e007d06a842beb85097d129baae14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c64c44837cf14a5d92c90fc35efc7ef7",
       "placeholder": "​",
       "style": "IPY_MODEL_b73187b1dad647438f7cf0be80d418d3",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 77.5kB/s]"
      }
     },
     "758ae4051ece43669a3b85b16b4d9470": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77488e65c0d54f7393dd9f5bf988f6d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_87db0a37e1344084b870cb9a36e9d93b",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9bd266600c1048d6a29f1ff87de42590",
       "tabbable": null,
       "tooltip": null,
       "value": 570.0
      }
     },
     "874f282eb57e46d8b525cd957f71a845": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "87db0a37e1344084b870cb9a36e9d93b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "899d4a47718546f58e85b4149c91c1a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b01d9582685434dac203a995db8443f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da9808359e904a89b4e636e9111c050d",
        "IPY_MODEL_9d1e42067d1b44b6ac8d50f3ff840f9a",
        "IPY_MODEL_1cb3dd5e58c2492fa007dfc06253a312"
       ],
       "layout": "IPY_MODEL_8ecf8a5438a54e0286bb84f730a1b7d5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8c1711eb05e84affb26df730c355a30d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ecf8a5438a54e0286bb84f730a1b7d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9283977596654a929d5a01e5669e50ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "92d4db0b03884281a8b3ce7b584c7fc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_144fc03a97a54f3ebc101900873853d1",
        "IPY_MODEL_6990b2051f8b4b898ce5470f005a3f01",
        "IPY_MODEL_cce9a9d33acc4584bd973db0b3afb192"
       ],
       "layout": "IPY_MODEL_3a6f8f55173643dd931d4eaa9fd58857",
       "tabbable": null,
       "tooltip": null
      }
     },
     "935a4539a5b34777bcff63e1f6b2d5c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "941c717c4f114299afe211b3b4590eca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_07733205a2fd4ca3976405407619e01a",
        "IPY_MODEL_c29b205f1acb41a08d67a756e6223657",
        "IPY_MODEL_c20611517a524d19a3074061523561fd"
       ],
       "layout": "IPY_MODEL_ab45ec4573cd4c28b6ffceb47e3c6488",
       "tabbable": null,
       "tooltip": null
      }
     },
     "995b5f4584904598bd7860443136c748": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bd266600c1048d6a29f1ff87de42590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9d1e42067d1b44b6ac8d50f3ff840f9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_995b5f4584904598bd7860443136c748",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aaef01162c7e4940ae8dce847dd05ea3",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "a1921fb7f0404203ba370c4adcc56f90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a47f146ec3f64e1facfe87f2c879c20a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a8bc7e4d69e447609359addbb3d5aec8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aaef01162c7e4940ae8dce847dd05ea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab45ec4573cd4c28b6ffceb47e3c6488": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b45936b7461349d5b1e8d2ce3855f2a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d01815bcca1e4e46b52d9bec0aa3055c",
       "placeholder": "​",
       "style": "IPY_MODEL_9283977596654a929d5a01e5669e50ff",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b73187b1dad647438f7cf0be80d418d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b895416657d6433f8a08dc85820b3b91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b93cce52300a4846b4b5d53766e9b7ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bd47e54907e2488b8cb21a9ee7779a80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6af5034442f14793a42ae0af402c38a9",
       "placeholder": "​",
       "style": "IPY_MODEL_e28fde4e24244d11a91ea011d44fb586",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "c20611517a524d19a3074061523561fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_216e51b575154f3d99d5e58a50451ac2",
       "placeholder": "​",
       "style": "IPY_MODEL_e0d9148d8b074d25b2ff709a4bf03b94",
       "tabbable": null,
       "tooltip": null,
       "value": " 1500/1500 [02:49&lt;00:00,  8.86it/s]"
      }
     },
     "c29b205f1acb41a08d67a756e6223657": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_38f49d1762ca4bb98f7aec90dd4a3a30",
       "max": 1500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b93cce52300a4846b4b5d53766e9b7ca",
       "tabbable": null,
       "tooltip": null,
       "value": 1500.0
      }
     },
     "c64c44837cf14a5d92c90fc35efc7ef7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8b9ce79e3104e329ba78badca2ff3c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca98f3729c174a43ac61cae050d89901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc223522449e4dd7b579e943b0b92596": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a1921fb7f0404203ba370c4adcc56f90",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fd4f7abf7fc143b4a03029ef78be25cb",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "cce9a9d33acc4584bd973db0b3afb192": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a8bc7e4d69e447609359addbb3d5aec8",
       "placeholder": "​",
       "style": "IPY_MODEL_874f282eb57e46d8b525cd957f71a845",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [00:56&lt;00:00,  8.84it/s]"
      }
     },
     "ceffa848378d496181705df997199e1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d01815bcca1e4e46b52d9bec0aa3055c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d55c04dd85594f29ac5a0955746bf40e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da9808359e904a89b4e636e9111c050d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_14f53d9e27794b9eac59bca7c9da726d",
       "placeholder": "​",
       "style": "IPY_MODEL_332c2eca2f65479caadaf9af52d3fb9b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "db9a9d0dc49d42d2b4c1c3888726f39b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f59573fb4f5a4199b2d74664f091754d",
       "placeholder": "​",
       "style": "IPY_MODEL_b895416657d6433f8a08dc85820b3b91",
       "tabbable": null,
       "tooltip": null,
       "value": " 440M/440M [00:01&lt;00:00, 468MB/s]"
      }
     },
     "de3af0f652ce49f3872cdd19440e5775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f43421827bc046cb992e5af879206aea",
       "max": 440449768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6549856b794945c0a16a608ed37190b1",
       "tabbable": null,
       "tooltip": null,
       "value": 440449768.0
      }
     },
     "e0d9148d8b074d25b2ff709a4bf03b94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1fade2cf0b442e18365ed498358b32a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e28fde4e24244d11a91ea011d44fb586": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2e8bfb650994c81895680a0e0f92116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_935a4539a5b34777bcff63e1f6b2d5c7",
       "placeholder": "​",
       "style": "IPY_MODEL_d55c04dd85594f29ac5a0955746bf40e",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 5.90kB/s]"
      }
     },
     "e8d3589c55be4fa4bae35952cc5c08ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0e8771a15dc64406b083e809d97298d6",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6f8d2377f11e45c7aaed824fe564e101",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "ec31f7b2d6904afeb9fce5e855abdbac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd47e54907e2488b8cb21a9ee7779a80",
        "IPY_MODEL_77488e65c0d54f7393dd9f5bf988f6d6",
        "IPY_MODEL_723e007d06a842beb85097d129baae14"
       ],
       "layout": "IPY_MODEL_65bf679b68de40da94422b2dcf3e5813",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f43421827bc046cb992e5af879206aea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f59573fb4f5a4199b2d74664f091754d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd4f7abf7fc143b4a03029ef78be25cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fd5cdd3858bb4b18917dbe79081e4ec7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
