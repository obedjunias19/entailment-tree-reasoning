{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf72c98f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-27T15:15:59.057646Z",
     "iopub.status.busy": "2025-12-27T15:15:59.056664Z",
     "iopub.status.idle": "2025-12-27T15:16:00.605164Z",
     "shell.execute_reply": "2025-12-27T15:16:00.604270Z"
    },
    "papermill": {
     "duration": 1.555806,
     "end_time": "2025-12-27T15:16:00.606451",
     "exception": false,
     "start_time": "2025-12-27T15:15:59.050645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/__huggingface_repos__.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base_training_curves.png\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/spm.model\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/config.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/results_detailed.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/tokenizer.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/tokenizer_config.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/model.safetensors\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/special_tokens_map.json\n",
      "/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best/added_tokens.json\n",
      "/kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_all_hf.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd88be00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.620134Z",
     "iopub.status.busy": "2025-12-27T15:16:00.619467Z",
     "iopub.status.idle": "2025-12-27T15:16:00.623601Z",
     "shell.execute_reply": "2025-12-27T15:16:00.622821Z"
    },
    "papermill": {
     "duration": 0.011909,
     "end_time": "2025-12-27T15:16:00.624865",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.612956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# train_df = pd.DataFrame(data[\"questions\"])\n",
    "# train_df.to_csv('train_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# dev_df = pd.DataFrame(data[\"questions\"])\n",
    "# dev_df.to_csv('dev_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# dev_df.head()\n",
    "\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# test_df = pd.DataFrame(data[\"questions\"])\n",
    "# test_df.to_csv('test_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fde447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.633044Z",
     "iopub.status.busy": "2025-12-27T15:16:00.632519Z",
     "iopub.status.idle": "2025-12-27T15:16:00.636001Z",
     "shell.execute_reply": "2025-12-27T15:16:00.635383Z"
    },
    "papermill": {
     "duration": 0.008607,
     "end_time": "2025-12-27T15:16:00.637077",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.628470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697ec8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.645297Z",
     "iopub.status.busy": "2025-12-27T15:16:00.645121Z",
     "iopub.status.idle": "2025-12-27T15:16:00.650475Z",
     "shell.execute_reply": "2025-12-27T15:16:00.649955Z"
    },
    "papermill": {
     "duration": 0.010686,
     "end_time": "2025-12-27T15:16:00.651513",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.640827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "# import ast\n",
    "\n",
    "# # Load your dataset\n",
    "# df = pd.read_csv(\"/kaggle/working/train_logical_combinations_output.csv\")  # replace with your file\n",
    "\n",
    "# # Safe eval to ensure lists are properly loaded\n",
    "# def safe_eval(val):\n",
    "#     if isinstance(val, list):\n",
    "#         return val\n",
    "#     if pd.isna(val):\n",
    "#         return []\n",
    "#     if isinstance(val, str):\n",
    "#         try:\n",
    "#             return ast.literal_eval(val)\n",
    "#         except:\n",
    "#             return []\n",
    "#     return []\n",
    "\n",
    "# df['logical_combinations'] = df['logical_combinations'].apply(safe_eval)\n",
    "\n",
    "# # Prepare storage for QA sets\n",
    "# qa_sets = {\n",
    "#     'AND': [],\n",
    "#     'OR': [],\n",
    "#     'NEITHER': [],\n",
    "#     'Mixed': []\n",
    "# }\n",
    "\n",
    "# # Label rotation - separate rotator for each question type\n",
    "# class LabelRotator:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.labels = ['A', 'B', 'C', 'D']\n",
    "#         self.current_index = 0\n",
    "    \n",
    "#     def get_next_label(self):\n",
    "#         label = self.labels[self.current_index]\n",
    "#         self.current_index = (self.current_index + 1) % len(self.labels)\n",
    "#         # print(f\"DEBUG {self.name}: Assigned label {label}, next will be {self.labels[self.current_index]}\")\n",
    "#         return label\n",
    "\n",
    "# # Create separate rotators for each question type\n",
    "# rotators = {\n",
    "#     'AND': LabelRotator('AND'),\n",
    "#     'OR': LabelRotator('OR'),\n",
    "#     'NEITHER': LabelRotator('NEITHER'),\n",
    "#     'Mixed': LabelRotator('Mixed')\n",
    "# }\n",
    "\n",
    "# def create_qa_item(question, correct_ans, incorrect_ans, qa_type):\n",
    "#     \"\"\"Helper function to create a QA item with proper label rotation\"\"\"\n",
    "    \n",
    "#     # Get correct label from the appropriate rotator\n",
    "#     correct_label = rotators[qa_type].get_next_label()\n",
    "    \n",
    "#     # Ensure we have exactly 3 incorrect answers\n",
    "#     if len(incorrect_ans) < 3:\n",
    "#         print(f\"Warning: Only {len(incorrect_ans)} incorrect answers available for {qa_type}\")\n",
    "#         return None\n",
    "    \n",
    "#     selected_incorrect = random.sample(incorrect_ans, 3)\n",
    "    \n",
    "#     # Create options array with 4 positions\n",
    "#     options = [''] * 4\n",
    "    \n",
    "#     # Place correct answer at the designated position\n",
    "#     correct_pos = rotators[qa_type].labels.index(correct_label)\n",
    "#     options[correct_pos] = correct_ans\n",
    "    \n",
    "#     # Fill remaining positions with incorrect answers\n",
    "#     incorrect_positions = [i for i in range(4) if i != correct_pos]\n",
    "#     for i, pos in enumerate(incorrect_positions):\n",
    "#         options[pos] = selected_incorrect[i]\n",
    "    \n",
    "#     return {\n",
    "#         'question': question,\n",
    "#         'A': options[0],\n",
    "#         'B': options[1],\n",
    "#         'C': options[2],\n",
    "#         'D': options[3],\n",
    "#         'correct_label': correct_label,\n",
    "#         'correct_answer_text': correct_ans,\n",
    "#         'qa_type': qa_type\n",
    "#     }\n",
    "\n",
    "# # Track counts for each type\n",
    "# type_counts = {'AND': 0, 'OR': 0, 'NEITHER': 0, 'Mixed': 0}\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     question = row['question']\n",
    "#     combos = row['logical_combinations']\n",
    "    \n",
    "#     # Extract AND/OR/NEITHER correct and incorrect lists\n",
    "#     and_correct = combos.get('AND_combinations', {}).get('correct', [])\n",
    "#     and_incorrect = combos.get('AND_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     or_correct = combos.get('OR_combinations', {}).get('correct', [])\n",
    "#     or_incorrect = combos.get('OR_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     neither_correct = combos.get('NEITHER_combinations', {}).get('correct', [])\n",
    "#     neither_incorrect = combos.get('NEITHER_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     # --- AND-only QA ---\n",
    "#     if and_correct and len(and_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(and_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, and_incorrect, 'AND')\n",
    "#         if qa_item:\n",
    "#             qa_sets['AND'].append(qa_item)\n",
    "#             type_counts['AND'] += 1\n",
    "#             # print(f\"AND Question {type_counts['AND']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- OR-only QA ---\n",
    "#     if or_correct and len(or_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(or_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, or_incorrect, 'OR')\n",
    "#         if qa_item:\n",
    "#             qa_sets['OR'].append(qa_item)\n",
    "#             type_counts['OR'] += 1\n",
    "#             # print(f\"OR Question {type_counts['OR']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- NEITHER-only QA ---\n",
    "#     if neither_correct and len(neither_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(neither_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, neither_incorrect, 'NEITHER')\n",
    "#         if qa_item:\n",
    "#             qa_sets['NEITHER'].append(qa_item)\n",
    "#             type_counts['NEITHER'] += 1\n",
    "#             # print(f\"NEITHER Question {type_counts['NEITHER']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- Mixed QA ---\n",
    "#     all_correct_types = [\n",
    "#         ('AND', and_correct),\n",
    "#         ('OR', or_correct),\n",
    "#         ('NEITHER', neither_correct)\n",
    "#     ]\n",
    "#     all_incorrect_types = and_incorrect + or_incorrect + neither_incorrect\n",
    "    \n",
    "#     # Ensure at least one correct exists and enough incorrect answers\n",
    "#     valid_categories = [cat for cat, lst in all_correct_types if lst]\n",
    "#     if valid_categories and len(all_incorrect_types) >= 3:\n",
    "#         chosen_category = random.choice(valid_categories)\n",
    "#         chosen_correct_list = dict(all_correct_types)[chosen_category]\n",
    "#         correct_ans = random.choice(chosen_correct_list)\n",
    "#         qa_item = create_qa_item(question, correct_ans, all_incorrect_types, 'Mixed')\n",
    "#         if qa_item:\n",
    "#             qa_sets['Mixed'].append(qa_item)\n",
    "#             type_counts['Mixed'] += 1\n",
    "#             # print(f\"Mixed Question {type_counts['Mixed']}: Label {qa_item['correct_label']}\")\n",
    "\n",
    "# print(f\"\\n=== GENERATION COMPLETE ===\")\n",
    "# for qtype, count in type_counts.items():\n",
    "#     print(f\"{qtype}: {count} questions generated\")\n",
    "\n",
    "# # --- Convert to DataFrames and save ---\n",
    "# for key, qlist in qa_sets.items():\n",
    "#     if qlist:  # Only save if we have questions\n",
    "#         df_out = pd.DataFrame(qlist)\n",
    "#         df_out.to_csv(f'train_qa_{key}.csv', index=False)\n",
    "#         print(f\"\\n{key} QA saved: {len(df_out)} questions in train_qa_{key}.csv\")\n",
    "        \n",
    "#         # Show label distribution for verification\n",
    "#         label_counts = df_out['correct_label'].value_counts().sort_index()\n",
    "#         print(f\"  Label distribution: {dict(label_counts)}\")\n",
    "        \n",
    "#         # Show label sequence for first 8 questions to verify rotation\n",
    "#         print(f\"  Label sequence (first 8): {list(df_out['correct_label'].head(8))}\")\n",
    "#     else:\n",
    "#         print(f\"{key}: No valid QA pairs generated\")\n",
    "\n",
    "# # Overall statistics\n",
    "# total_questions = sum(len(qlist) for qlist in qa_sets.values())\n",
    "# print(f\"\\nFinal total questions generated: {total_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c8f96e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.659119Z",
     "iopub.status.busy": "2025-12-27T15:16:00.658924Z",
     "iopub.status.idle": "2025-12-27T15:16:00.661873Z",
     "shell.execute_reply": "2025-12-27T15:16:00.661181Z"
    },
    "papermill": {
     "duration": 0.008093,
     "end_time": "2025-12-27T15:16:00.663014",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.654921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and  = pd.read_csv('/kaggle/working/test_qa_AND.csv')\n",
    "\n",
    "# train_qa_and.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b54bc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.670639Z",
     "iopub.status.busy": "2025-12-27T15:16:00.670289Z",
     "iopub.status.idle": "2025-12-27T15:16:00.673184Z",
     "shell.execute_reply": "2025-12-27T15:16:00.672616Z"
    },
    "papermill": {
     "duration": 0.007942,
     "end_time": "2025-12-27T15:16:00.674249",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.666307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9274a654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.682010Z",
     "iopub.status.busy": "2025-12-27T15:16:00.681835Z",
     "iopub.status.idle": "2025-12-27T15:16:00.685102Z",
     "shell.execute_reply": "2025-12-27T15:16:00.684558Z"
    },
    "papermill": {
     "duration": 0.008386,
     "end_time": "2025-12-27T15:16:00.686140",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.677754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# and_df = pd.read_csv(\"train_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"train_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"train_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"train_qa_Mixed.csv\")\n",
    "\n",
    "# train_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# train_df.to_csv(\"train_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"dev_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"dev_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"dev_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"dev_qa_Mixed.csv\")\n",
    "\n",
    "# dev_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# dev_df.to_csv(\"dev_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"test_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"test_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"test_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"test_qa_Mixed.csv\")\n",
    "\n",
    "# test_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# test_df.to_csv(\"test_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f210c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.694706Z",
     "iopub.status.busy": "2025-12-27T15:16:00.694348Z",
     "iopub.status.idle": "2025-12-27T15:16:00.697491Z",
     "shell.execute_reply": "2025-12-27T15:16:00.696980Z"
    },
    "papermill": {
     "duration": 0.008875,
     "end_time": "2025-12-27T15:16:00.698459",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.689584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "# train_df[\"choices\"] = train_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# train_df[\"label\"] = train_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_train_df = train_df[[\"question\", \"choices\", \"label\", \"qa_type\"]]\n",
    "\n",
    "# hf_train_df.to_json(\"train_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# dev_df[\"choices\"] = dev_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# dev_df[\"label\"] = dev_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_dev_df = dev_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_dev_df.to_json(\"dev_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "# test_df[\"choices\"] = test_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# test_df[\"label\"] = test_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_test_df = test_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_test_df.to_json(\"test_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e34efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.706032Z",
     "iopub.status.busy": "2025-12-27T15:16:00.705868Z",
     "iopub.status.idle": "2025-12-27T15:16:00.708577Z",
     "shell.execute_reply": "2025-12-27T15:16:00.708054Z"
    },
    "papermill": {
     "duration": 0.007739,
     "end_time": "2025-12-27T15:16:00.709518",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.701779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2094f615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:00.717352Z",
     "iopub.status.busy": "2025-12-27T15:16:00.716948Z",
     "iopub.status.idle": "2025-12-27T15:16:12.167237Z",
     "shell.execute_reply": "2025-12-27T15:16:12.166329Z"
    },
    "papermill": {
     "duration": 11.455456,
     "end_time": "2025-12-27T15:16:12.168441",
     "exception": false,
     "start_time": "2025-12-27T15:16:00.712985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n",
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "  PyArrow 19.0.1\n",
      "  Datasets 4.4.1\n",
      "  Transformers 4.53.3\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Clean uninstall everything\n",
    "# !pip uninstall -y protobuf pyarrow google-protobuf datasets transformers accelerate bitsandbytes peft trl\n",
    "\n",
    "# # Step 2: Install in the correct order with compatible versions\n",
    "!pip install --upgrade --no-cache-dir protobuf==3.20.3\n",
    "# !pip install --no-cache-dir pyarrow==12.0.1\n",
    "# !pip install --no-cache-dir datasets==2.14.0\n",
    "# !pip install --no-cache-dir transformers==4.35.2\n",
    "# !pip install --no-cache-dir accelerate\n",
    "\n",
    "# Step 3: Verify installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "try:\n",
    "    import pyarrow as pa\n",
    "    print(f\"  PyArrow {pa.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PyArrow failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"  Datasets {datasets.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Datasets failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import __version__\n",
    "    print(f\"  Transformers {__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Transformers failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511f96c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:12.177520Z",
     "iopub.status.busy": "2025-12-27T15:16:12.177163Z",
     "iopub.status.idle": "2025-12-27T15:16:12.180336Z",
     "shell.execute_reply": "2025-12-27T15:16:12.179829Z"
    },
    "papermill": {
     "duration": 0.008748,
     "end_time": "2025-12-27T15:16:12.181333",
     "exception": false,
     "start_time": "2025-12-27T15:16:12.172585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Uninstall and reinstall datasets with matching pyarrow version\n",
    "# !pip uninstall -y datasets  pyarrow\n",
    "# !pip install --no-cache-dir pyarrow\n",
    "# !pip install --no-cache-dir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfa0747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:12.189830Z",
     "iopub.status.busy": "2025-12-27T15:16:12.189608Z",
     "iopub.status.idle": "2025-12-27T15:16:19.013611Z",
     "shell.execute_reply": "2025-12-27T15:16:19.012632Z"
    },
    "papermill": {
     "duration": 6.829874,
     "end_time": "2025-12-27T15:16:19.015027",
     "exception": false,
     "start_time": "2025-12-27T15:16:12.185153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\r\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyarrow, evaluate\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "299aa481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:19.026653Z",
     "iopub.status.busy": "2025-12-27T15:16:19.026420Z",
     "iopub.status.idle": "2025-12-27T15:16:19.031269Z",
     "shell.execute_reply": "2025-12-27T15:16:19.030575Z"
    },
    "papermill": {
     "duration": 0.012054,
     "end_time": "2025-12-27T15:16:19.032420",
     "exception": false,
     "start_time": "2025-12-27T15:16:19.020366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "# from transformers import TrainingArguments, Trainer, DataCollatorForMultipleChoice\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import json\n",
    "# import evaluate\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # Custom Dataset class to replace datasets.load_dataset\n",
    "# import json\n",
    "\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item[\"qa_type\"] \n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type \n",
    "#         }\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", tokenizer)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", tokenizer)\n",
    "\n",
    "# data_collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "\n",
    "# # Rest of your code remains the same\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = p.predictions.argmax(-1)\n",
    "#     return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./deberta-v3-mcqa\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=1e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=4,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_steps=50,\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eca68349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:19.043444Z",
     "iopub.status.busy": "2025-12-27T15:16:19.043183Z",
     "iopub.status.idle": "2025-12-27T15:16:19.055484Z",
     "shell.execute_reply": "2025-12-27T15:16:19.054726Z"
    },
    "papermill": {
     "duration": 0.019502,
     "end_time": "2025-12-27T15:16:19.056539",
     "exception": false,
     "start_time": "2025-12-27T15:16:19.037037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch\n",
    "# from torch.optim import AdamW\n",
    "# from tqdm.auto import tqdm\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "# import random\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# training_config = {\n",
    "#     'max_epochs': 10,\n",
    "#     'patience': 3,  # Early stopping patience\n",
    "#     'min_delta': 0.001,  # Minimum improvement to count\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 2e-5,\n",
    "#     'warmup_steps': 500,\n",
    "#     'gradient_accumulation_steps': 2,\n",
    "#     'weight_decay': 0.01,\n",
    "#     'max_length': 256\n",
    "# }\n",
    "\n",
    "# print(\"\\nTraining Configuration:\")\n",
    "# for key, value in training_config.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "# # Custom Dataset\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 if line.strip():\n",
    "#                     self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#         print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "#         # Print dataset statistics\n",
    "#         type_counts = defaultdict(int)\n",
    "#         for item in self.data:\n",
    "#             type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "#         print(\"Dataset composition:\")\n",
    "#         for qa_type, count in sorted(type_counts.items()):\n",
    "#             print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type\n",
    "#         }\n",
    "\n",
    "# def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "#     \"\"\"\n",
    "#     Compute comprehensive metrics for dataset paper\n",
    "#     Returns per-type metrics with BOTH micro and macro averaging\n",
    "#     \"\"\"\n",
    "#     predictions = np.array(predictions)\n",
    "#     labels = np.array(labels)\n",
    "#     qa_types = np.array(qa_types)\n",
    "    \n",
    "#     unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "#     results = {\n",
    "#         'per_type': {},\n",
    "#         'macro_across_types': {},\n",
    "#         'micro_overall': {},\n",
    "#         'confusion_matrices': {}\n",
    "#     }\n",
    "    \n",
    "#     # Per-type metrics (with both micro and macro within type)\n",
    "#     for qa_type in unique_types:\n",
    "#         mask = qa_types == qa_type\n",
    "#         type_preds = predictions[mask]\n",
    "#         type_labels = labels[mask]\n",
    "        \n",
    "#         if len(type_preds) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         # MACRO: Average metrics across the 4 answer choices for this type\n",
    "#         macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # MICRO: Global metrics for this type (same as accuracy)\n",
    "#         micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # Per-class metrics for this type (for detailed analysis)\n",
    "#         per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "#         results['per_type'][qa_type] = {\n",
    "#             # Macro metrics (average across 4 answer choices)\n",
    "#             'macro': {\n",
    "#                 'precision': macro_precision,\n",
    "#                 'recall': macro_recall,\n",
    "#                 'f1': macro_f1,\n",
    "#             },\n",
    "#             # Micro metrics (global for this type)\n",
    "#             'micro': {\n",
    "#                 'precision': micro_precision,  # same as accuracy\n",
    "#                 'recall': micro_recall,        # same as accuracy\n",
    "#                 'f1': micro_f1,                # same as accuracy\n",
    "#                 'accuracy': accuracy,\n",
    "#             },\n",
    "#             # Per-answer-choice metrics\n",
    "#             'per_choice': {\n",
    "#                 f'choice_{i}': {\n",
    "#                     'precision': per_class_precision[i],\n",
    "#                     'recall': per_class_recall[i],\n",
    "#                     'f1': per_class_f1[i],\n",
    "#                     'support': per_class_support[i]\n",
    "#                 } for i in range(4)\n",
    "#             },\n",
    "#             'support': len(type_preds),\n",
    "#             'correct': (type_preds == type_labels).sum()\n",
    "#         }\n",
    "        \n",
    "#         # Confusion matrix for this type\n",
    "#         results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "#             type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "    \n",
    "#     # Macro metrics across logical types (what you typically report in paper)\n",
    "#     macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "#     macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "#     macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "#     macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "#     results['macro_across_types'] = {\n",
    "#         'precision': macro_across_types_precision,\n",
    "#         'recall': macro_across_types_recall,\n",
    "#         'f1': macro_across_types_f1,\n",
    "#         'accuracy': macro_across_types_accuracy\n",
    "#     }\n",
    "    \n",
    "#     # Micro metrics overall (global across all instances)\n",
    "#     micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#         labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#     )\n",
    "#     micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "#     results['micro_overall'] = {\n",
    "#         'accuracy': micro_accuracy,\n",
    "#         'precision': micro_precision,\n",
    "#         'recall': micro_recall,\n",
    "#         'f1': micro_f1,\n",
    "#         'support': len(predictions),\n",
    "#         'correct': (predictions == labels).sum()\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def evaluate_comprehensive(model, dataloader, device):\n",
    "#     \"\"\"Comprehensive evaluation with all metrics\"\"\"\n",
    "#     model.eval()\n",
    "    \n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "#     all_types = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "#             qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "#             all_predictions.extend(predictions.cpu().tolist())\n",
    "#             all_labels.extend(labels.cpu().tolist())\n",
    "#             all_types.extend(qa_types)\n",
    "    \n",
    "#     metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "#     return metrics\n",
    "\n",
    "# def print_results_table(metrics, epoch=None, model_name=None):\n",
    "#     \"\"\"Print results table\"\"\"\n",
    "    \n",
    "#     if epoch is not None:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         if model_name:\n",
    "#             print(f\"Model: {model_name} | Epoch {epoch}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "    \n",
    "#     print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for qa_type in sorted(metrics['per_type'].keys()):\n",
    "#         m_macro = metrics['per_type'][qa_type]['macro']\n",
    "#         m_micro = metrics['per_type'][qa_type]['micro']\n",
    "#         support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "#         print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "#               f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     m = metrics['macro_across_types']\n",
    "#     print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "#     m = metrics['micro_overall']\n",
    "#     print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", \n",
    "#                            tokenizer, max_length=256)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", \n",
    "#                           tokenizer, max_length=256)\n",
    "\n",
    "# # Setup data loaders\n",
    "# batch_size = training_config['batch_size']\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Setup model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"\\nDevice: {device}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Setup optimizer and scheduler\n",
    "# optimizer = AdamW(model.parameters(), \n",
    "#                  lr=training_config['learning_rate'], \n",
    "#                  weight_decay=training_config['weight_decay'])\n",
    "# num_training_steps = training_config['max_epochs'] * len(train_loader) // training_config['gradient_accumulation_steps']\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=training_config['warmup_steps'],\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "# # Training loop with early stopping\n",
    "# best_macro_f1 = 0\n",
    "# best_epoch = 0\n",
    "# epochs_without_improvement = 0\n",
    "# best_metrics = None\n",
    "# training_history = []\n",
    "\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(f\"Training {model_name} with Early Stopping\")\n",
    "# print(f\"Max Epochs: {training_config['max_epochs']}, Patience: {training_config['patience']}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# for epoch in range(training_config['max_epochs']):\n",
    "#     print(f\"\\n{'='*100}\")\n",
    "#     print(f\"Epoch {epoch + 1}/{training_config['max_epochs']}\")\n",
    "#     print(f\"{'='*100}\")\n",
    "    \n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "#     for step, batch in enumerate(progress_bar):\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "#         # Forward pass (no mixed precision for P100)\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "#         loss = outputs.loss / training_config['gradient_accumulation_steps']\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Gradient accumulation\n",
    "#         if (step + 1) % training_config['gradient_accumulation_steps'] == 0:\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "        \n",
    "#         total_loss += loss.item() * training_config['gradient_accumulation_steps']\n",
    "#         progress_bar.set_postfix({\"loss\": f\"{total_loss / (step + 1):.4f}\"})\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     print(f\"\\nTrain Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "#     # Evaluation\n",
    "#     print(\"\\nEvaluating...\")\n",
    "#     metrics = evaluate_comprehensive(model, eval_loader, device)\n",
    "#     print_results_table(metrics, epoch=epoch + 1, model_name=model_name)\n",
    "    \n",
    "#     macro_f1 = metrics['macro_across_types']['f1']\n",
    "#     macro_acc = metrics['macro_across_types']['accuracy']\n",
    "    \n",
    "#     # Save history\n",
    "#     training_history.append({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'train_loss': avg_train_loss,\n",
    "#         'macro_f1': macro_f1,\n",
    "#         'macro_accuracy': macro_acc,\n",
    "#         'macro_precision': metrics['macro_across_types']['precision'],\n",
    "#         'macro_recall': metrics['macro_across_types']['recall']\n",
    "#     })\n",
    "    \n",
    "#     # Early stopping check\n",
    "#     improvement = macro_f1 - best_macro_f1\n",
    "    \n",
    "#     if improvement > training_config['min_delta']:\n",
    "#         best_macro_f1 = macro_f1\n",
    "#         best_epoch = epoch + 1\n",
    "#         best_metrics = metrics\n",
    "#         epochs_without_improvement = 0\n",
    "        \n",
    "#         save_dir = f\"./{model_name.replace('/', '-')}-best\"\n",
    "#         print(f\"\\n  New best Macro F1: {macro_f1:.4f} (↑{improvement:.4f})! Saving to {save_dir}\")\n",
    "#         model.save_pretrained(save_dir)\n",
    "#         tokenizer.save_pretrained(save_dir)\n",
    "        \n",
    "#         def convert_to_serializable(obj):\n",
    "#             if isinstance(obj, dict):\n",
    "#                 return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "#             elif isinstance(obj, (np.integer, np.floating)):\n",
    "#                 return float(obj)\n",
    "#             elif isinstance(obj, np.ndarray):\n",
    "#                 return obj.tolist()\n",
    "#             return obj\n",
    "        \n",
    "#         results_for_paper = {\n",
    "#             'model': model_name,\n",
    "#             'best_epoch': best_epoch,\n",
    "#             'training_config': training_config,\n",
    "#             'training_history': training_history,\n",
    "#             'best_metrics': convert_to_serializable(best_metrics)\n",
    "#         }\n",
    "        \n",
    "#         with open(f\"{save_dir}/results_detailed.json\", \"w\") as f:\n",
    "#             json.dump(results_for_paper, f, indent=2)\n",
    "#     else:\n",
    "#         epochs_without_improvement += 1\n",
    "#         print(f\"\\n   No improvement for {epochs_without_improvement} epoch(s) \"\n",
    "#               f\"(current: {macro_f1:.4f}, best: {best_macro_f1:.4f})\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if epochs_without_improvement >= training_config['patience']:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         print(f\"Early stopping triggered!\")\n",
    "#         print(f\"Best Macro F1: {best_macro_f1:.4f} at epoch {best_epoch}\")\n",
    "#         print(f\"Training stopped at epoch {epoch + 1}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "#         break\n",
    "\n",
    "# # Final summary\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(\"Training Complete!\")\n",
    "# print(f\"{'='*100}\")\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}/{epoch + 1}\")\n",
    "# print(f\"Best Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# if best_metrics is not None:\n",
    "#     print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "#     print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# else:\n",
    "#     print(\"Best Validation Macro F1: n/a (no improvement over initial baseline)\")\n",
    "#     print(\"Best Validation Macro Accuracy: n/a\")\n",
    "\n",
    "\n",
    "# # Plot training curves\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# epochs_list = [h['epoch'] for h in training_history]\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.plot(epochs_list, [h['train_loss'] for h in training_history], marker='o', label='Train Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.plot(epochs_list, [h['macro_f1'] for h in training_history], marker='o', color='green', label='Macro F1')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Macro F1')\n",
    "# plt.title('Validation Macro F1')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.plot(epochs_list, [h['macro_accuracy'] for h in training_history], marker='o', color='blue', label='Macro Accuracy')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Macro Accuracy')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{model_name.replace(\"/\", \"-\")}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "# print(f\"\\n  Saved training curves to {model_name.replace('/', '-')}_training_curves.png\")\n",
    "\n",
    "# # Summary table for paper\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY FOR PAPER:\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}\")\n",
    "# print(f\"Total Epochs Trained: {len(training_history)}\")\n",
    "# print(f\"Converged: {'Yes (early stopping)' if epochs_without_improvement >= training_config['patience'] else 'No (completed all epochs)'}\")\n",
    "# print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7400158e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:16:19.067255Z",
     "iopub.status.busy": "2025-12-27T15:16:19.067078Z",
     "iopub.status.idle": "2025-12-27T15:22:23.955197Z",
     "shell.execute_reply": "2025-12-27T15:22:23.954286Z"
    },
    "papermill": {
     "duration": 364.895181,
     "end_time": "2025-12-27T15:22:23.956374",
     "exception": false,
     "start_time": "2025-12-27T15:16:19.061193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Configuration:\n",
      "  batch_size: 4\n",
      "  max_length: 256\n",
      "Model: deberta-v3\n",
      "\n",
      "Loading model: deberta-v3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 15:16:29.644487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766848589.826865      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766848589.879012      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "Loaded 6000 examples from /kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 1500 (25.0%)\n",
      "  Mixed: 1500 (25.0%)\n",
      "  NEITHER: 1500 (25.0%)\n",
      "  OR: 1500 (25.0%)\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40147ef181a44960933ba937922d080a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.8760     0.8787     0.8760     0.8758      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8760     0.8787     0.8760     0.8758        -\n",
      "Micro Avg        0.8760     0.8760     0.8760     0.8760      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05669b0fc3be4ca186ee5e2d481ce0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.9080     0.9077     0.9083     0.9079      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9080     0.9077     0.9083     0.9079        -\n",
      "Micro Avg        0.9080     0.9080     0.9080     0.9080      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  OR: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a778ddc96b471da4e8203a40d8c16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "OR               0.8720     0.8773     0.8717     0.8717      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8720     0.8773     0.8717     0.8717        -\n",
      "Micro Avg        0.8720     0.8720     0.8720     0.8720      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  OR: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34356e8d55d6462eaabae8ff5b336189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "OR               0.8800     0.8806     0.8801     0.8802      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8800     0.8806     0.8801     0.8802        -\n",
      "Micro Avg        0.8800     0.8800     0.8800     0.8800      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  NEITHER: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd23757aafc44a078e0cf44bc64c5026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEITHER          0.8480     0.8493     0.8479     0.8477      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8480     0.8493     0.8479     0.8477        -\n",
      "Micro Avg        0.8480     0.8480     0.8480     0.8480      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  NEITHER: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc44ba609417413b89d904f9ba00661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEITHER          0.8920     0.8933     0.8920     0.8922      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8920     0.8933     0.8920     0.8922        -\n",
      "Micro Avg        0.8920     0.8920     0.8920     0.8920      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  Mixed: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e559453b8d84d588d4442d35e49f0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mixed            0.8240     0.8267     0.8236     0.8234      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8240     0.8267     0.8236     0.8234        -\n",
      "Micro Avg        0.8240     0.8240     0.8240     0.8240      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  Mixed: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586b7ca0587d411db18c520c18aaeac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mixed            0.8480     0.8491     0.8480     0.8481      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8480     0.8491     0.8480     0.8481        -\n",
      "Micro Avg        0.8480     0.8480     0.8480     0.8480      250\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Dev Set Evaluation: deberta-v3\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195626791ce94a738051d02b5309c5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: deberta-v3 (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.8520     0.8520     0.8520     0.8520     1500\n",
      "Mixed            0.8040     0.8040     0.8040     0.8039     1500\n",
      "NEITHER          0.8387     0.8396     0.8387     0.8387     1500\n",
      "OR               0.8407     0.8409     0.8407     0.8404     1500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8338     0.8341     0.8338     0.8337        -\n",
      "Micro Avg        0.8338     0.8338     0.8338     0.8338     6000\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Test Set Evaluation: deberta-v3\n",
      "====================================================================================================\n",
      "\n",
      "Results saved to deberta-v3_zeroshot_results.json\n",
      "\n",
      "====================================================================================================\n",
      "ZERO-SHOT RESULTS SUMMARY (TEST SET):\n",
      "====================================================================================================\n",
      "Model: deberta-v3\n",
      "Evaluation Type: Zero-Shot (No Training)\n",
      "Test Examples: 250\n",
      "Macro F1 (across types): 0.8481\n",
      "Macro Accuracy (across types): 0.8480\n",
      "Micro F1 (overall): 0.8480\n",
      "Micro Accuracy (overall): 0.8480\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model\n",
    "model_path = \"/kaggle/input/deberta-csqalogic/pytorch/default/1/microsoft-deberta-v3-base-best\"\n",
    "model_name = 'deberta-v3'\n",
    "\n",
    "\n",
    "eval_config = {\n",
    "    'batch_size': 4,  # Can use larger batch for inference\n",
    "    'max_length': 256\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluation Configuration:\")\n",
    "for key, value in eval_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nLoading model: {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_path)\n",
    "\n",
    "class MCQADataset(Dataset):\n",
    "    def __init__(self, json_path, tokenizer, max_length=256, start_idx=None, end_idx=None):\n",
    "        self.data = []\n",
    "        with open(json_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    self.data.append(json.loads(line.strip()))\n",
    "\n",
    "        # Apply partitioning\n",
    "        if start_idx is not None or end_idx is not None:\n",
    "            self.data = self.data[start_idx:end_idx]\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} examples from {json_path}\")        \n",
    "        # Print dataset statistics\n",
    "        type_counts = defaultdict(int)\n",
    "        for item in self.data:\n",
    "            type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "        print(\"Dataset composition:\")\n",
    "        for qa_type, count in sorted(type_counts.items()):\n",
    "            print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item[\"question\"]\n",
    "        choices = item[\"choices\"]\n",
    "        label = item[\"label\"]\n",
    "        qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            [question] * 4,\n",
    "            choices,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(label),\n",
    "            \"qa_type\": qa_type\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "    \"\"\"Compute comprehensive metrics\"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    qa_types = np.array(qa_types)\n",
    "    \n",
    "    unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "    results = {\n",
    "        'per_type': {},\n",
    "        'macro_across_types': {},\n",
    "        'micro_overall': {},\n",
    "        'confusion_matrices': {}\n",
    "    }\n",
    "    \n",
    "    for qa_type in unique_types:\n",
    "        mask = qa_types == qa_type\n",
    "        type_preds = predictions[mask]\n",
    "        type_labels = labels[mask]\n",
    "        \n",
    "        if len(type_preds) == 0:\n",
    "            continue\n",
    "        \n",
    "        macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "        results['per_type'][qa_type] = {\n",
    "            'macro': {\n",
    "                'precision': macro_precision,\n",
    "                'recall': macro_recall,\n",
    "                'f1': macro_f1,\n",
    "            },\n",
    "            'micro': {\n",
    "                'precision': micro_precision,\n",
    "                'recall': micro_recall,\n",
    "                'f1': micro_f1,\n",
    "                'accuracy': accuracy,\n",
    "            },\n",
    "            'per_choice': {\n",
    "                f'choice_{i}': {\n",
    "                    'precision': per_class_precision[i],\n",
    "                    'recall': per_class_recall[i],\n",
    "                    'f1': per_class_f1[i],\n",
    "                    'support': per_class_support[i]\n",
    "                } for i in range(4)\n",
    "            },\n",
    "            'support': len(type_preds),\n",
    "            'correct': (type_preds == type_labels).sum()\n",
    "        }\n",
    "        \n",
    "        results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "            type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "    \n",
    "    macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "    macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "    macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "    macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "    results['macro_across_types'] = {\n",
    "        'precision': macro_across_types_precision,\n",
    "        'recall': macro_across_types_recall,\n",
    "        'f1': macro_across_types_f1,\n",
    "        'accuracy': macro_across_types_accuracy\n",
    "    }\n",
    "    \n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "    )\n",
    "    micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "    results['micro_overall'] = {\n",
    "        'accuracy': micro_accuracy,\n",
    "        'precision': micro_precision,\n",
    "        'recall': micro_recall,\n",
    "        'f1': micro_f1,\n",
    "        'support': len(predictions),\n",
    "        'correct': (predictions == labels).sum()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_zero_shot(model, dataloader, tokenizer, device):\n",
    "    \"\"\"Zero-shot evaluation\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_types = []\n",
    "    \n",
    "    print(\"\\nRunning zero-shot evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            correct_labels = batch[\"labels\"]\n",
    "            qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(correct_labels.cpu().tolist())\n",
    "            all_types.extend(qa_types)\n",
    "    \n",
    "    metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_results_table(metrics, model_name=None):\n",
    "    \"\"\"Print results table\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    if model_name:\n",
    "        print(f\"Model: {model_name} (Zero-Shot)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for qa_type in sorted(metrics['per_type'].keys()):\n",
    "        m_macro = metrics['per_type'][qa_type]['macro']\n",
    "        m_micro = metrics['per_type'][qa_type]['micro']\n",
    "        support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "        print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "              f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    m = metrics['macro_across_types']\n",
    "    print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "    m = metrics['micro_overall']\n",
    "    print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Load test dataset\n",
    "dev_dataset = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "#AND\n",
    "test_dataset_first = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=0,\n",
    "    end_idx=250\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=250,\n",
    "    end_idx=500\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#OR\n",
    "test_dataset_first = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=500,\n",
    "    end_idx=750\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=750,\n",
    "    end_idx=1000\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#NNOR\n",
    "test_dataset_first = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1000,\n",
    "    end_idx=1250\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1250,\n",
    "    end_idx=1500\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#Mixed\n",
    "test_dataset_first = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1500,\n",
    "    end_idx=1750\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1750,\n",
    "    end_idx=2000\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Dev Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "dev_metrics = evaluate_zero_shot(model, dev_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(dev_metrics, model_name=model_name)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Test Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save results\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "# Save both\n",
    "results_for_paper = {\n",
    "    'model': model_name,\n",
    "    'evaluation_type': 'zero-shot',\n",
    "    'config': eval_config,\n",
    "    'dev_metrics': convert_to_serializable(dev_metrics),\n",
    "    'test_metrics': convert_to_serializable(test_metrics),\n",
    "}\n",
    "\n",
    "output_file = f\"{model_name.replace('/', '-')}_zeroshot_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results_for_paper, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "# Summary based on test set\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ZERO-SHOT RESULTS SUMMARY (TEST SET):\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Evaluation Type: Zero-Shot (No Training)\")\n",
    "print(f\"Test Examples: {test_metrics['micro_overall']['support']}\")\n",
    "print(f\"Macro F1 (across types): {test_metrics['macro_across_types']['f1']:.4f}\")\n",
    "print(f\"Macro Accuracy (across types): {test_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "print(f\"Micro F1 (overall): {test_metrics['micro_overall']['f1']:.4f}\")\n",
    "print(f\"Micro Accuracy (overall): {test_metrics['micro_overall']['accuracy']:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf090fb",
   "metadata": {
    "papermill": {
     "duration": 0.005948,
     "end_time": "2025-12-27T15:22:23.969404",
     "exception": false,
     "start_time": "2025-12-27T15:22:23.963456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8229833,
     "sourceId": 13735887,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 543703,
     "modelInstanceId": 529710,
     "sourceId": 698320,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 392.100307,
   "end_time": "2025-12-27T15:22:27.500309",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-27T15:15:55.400002",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "000b587b5a204cd4afaf069f570218f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0074b00e60f6472482b5c2e1df712c5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "031a128b09544113b820d4734780f8d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1c82ca60c67e47cf8b3aa65aaaeceb44",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7898f334d6c48efa892e73c5d8866aa",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "03276ac0794544ddb7e10a74127597be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "03a778ddc96b471da4e8203a40d8c16f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f1aa9ecdccd94598a044c9778dfbb521",
        "IPY_MODEL_031a128b09544113b820d4734780f8d4",
        "IPY_MODEL_3fa79020e1b64f4781dea60dde1e6409"
       ],
       "layout": "IPY_MODEL_87b2fd572de4431684bf7761d1012316",
       "tabbable": null,
       "tooltip": null
      }
     },
     "03ae15a57744462ab456363a5b765e66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_000b587b5a204cd4afaf069f570218f4",
       "placeholder": "​",
       "style": "IPY_MODEL_08e61ec363024556b7dd9cf5261122b3",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.02it/s]"
      }
     },
     "05669b0fc3be4ca186ee5e2d481ce0c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_39716ec0095b480fbfdd02de5aab4ae6",
        "IPY_MODEL_ee561955d82347b9b8a8e3382beae16b",
        "IPY_MODEL_03ae15a57744462ab456363a5b765e66"
       ],
       "layout": "IPY_MODEL_8ae9f00dfd1545bc9ca846d48c67014a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "066d90f01a1143f3978e61982941e7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08e61ec363024556b7dd9cf5261122b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0e8311a0538b49a1af6eda250a65f9e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0edfddafaa2f4d9e98e4378a4ce394e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0fabf8debc5d4c6f9c5c7fcc72382cca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "104e6a7ee0c94258a68e84f81c437c93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "178202ba34ae48fd863398de16d430c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1801622ddcaf4b14a69b5323fdf01566": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b5f6c9b38b8a4716b68e9b85f0417ead",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03276ac0794544ddb7e10a74127597be",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "195626791ce94a738051d02b5309c5a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ee2294f601494afcac5c60b0f2301e53",
        "IPY_MODEL_73f952f9703544179faa013f5a5eab63",
        "IPY_MODEL_c2b9d964e9c546cd9a18e75b4be68806"
       ],
       "layout": "IPY_MODEL_0e8311a0538b49a1af6eda250a65f9e6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "19587120d2634fb2adbbf45084e049ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19957cb560fa4675be67692f90bfe124": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9416c4f368a64c339e8fdf7b7ec8eb0e",
       "placeholder": "​",
       "style": "IPY_MODEL_2c6d4ac03a1a495b9cc1275464e32f16",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.02it/s]"
      }
     },
     "1a99b0730f824b1c98cf4695878e76d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c82ca60c67e47cf8b3aa65aaaeceb44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d35a13d559047c18b0570787096c0f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d38b1008feb4fb7b4f87f7a92a918c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "209fbbc70fbb4e6f9921bf27ead0bb1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "26b48063a4fd486282386d24c00117d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2c6d4ac03a1a495b9cc1275464e32f16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d0029972ac447bd8a35a86592bf0cd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "30e877ee808f4b77bf2188c4d05a1f69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "34356e8d55d6462eaabae8ff5b336189": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d10c0557a314f66bf85b7077ac07203",
        "IPY_MODEL_939a88bba61846e981a8401ef747f1b6",
        "IPY_MODEL_53ee7894c6594018976544a089f7a4bf"
       ],
       "layout": "IPY_MODEL_668d4c370a414fb4a9903ee787bec9f9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "35aa1e9e0d564ef38a3cd0e1c54a0515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36cb4b7e4d0343a8ab54f08cac257911": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f357e8c5ee6f495c867922b9b7522fe4",
       "placeholder": "​",
       "style": "IPY_MODEL_178202ba34ae48fd863398de16d430c8",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "39716ec0095b480fbfdd02de5aab4ae6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_104e6a7ee0c94258a68e84f81c437c93",
       "placeholder": "​",
       "style": "IPY_MODEL_0074b00e60f6472482b5c2e1df712c5a",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "3a40a1c0529b4e48b953ec08fada9505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3a57bf59770c4c07bc41f70c782218df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3baa198bf22c4f70a662a7034accbeb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47f912f7dd3c438292ac14971109fb57",
       "placeholder": "​",
       "style": "IPY_MODEL_70a81a552ab44525b10a069629981218",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "3efcaa8bb2d5485693b395238d1e760b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3fa79020e1b64f4781dea60dde1e6409": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cd84fc2aebe34990b65c28d6975bdc5c",
       "placeholder": "​",
       "style": "IPY_MODEL_f518b78477ca41c096eaedb284d1e47a",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.02it/s]"
      }
     },
     "40147ef181a44960933ba937922d080a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3baa198bf22c4f70a662a7034accbeb8",
        "IPY_MODEL_4af17da3f77c4b49a15c868648c161d2",
        "IPY_MODEL_544aa9987e4d4895a1f7f557e802efc6"
       ],
       "layout": "IPY_MODEL_0fabf8debc5d4c6f9c5c7fcc72382cca",
       "tabbable": null,
       "tooltip": null
      }
     },
     "47f912f7dd3c438292ac14971109fb57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a9506a053eb414a9852e99e5bce3e2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d412a3fb5a244f3a78aeef7e7f6b375",
       "placeholder": "​",
       "style": "IPY_MODEL_be5da53c7f2d4a69bee4441771d121ce",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "4af17da3f77c4b49a15c868648c161d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a99b0730f824b1c98cf4695878e76d7",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3a57bf59770c4c07bc41f70c782218df",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "4d366e9f30034dcdb20c97c6792fb00b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d657b7a47d5406c93f7feca83cb2e72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53619e91e7fb4d68a11301cf8cfe47f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53742deb2cb9425a8c9d15bc0969ad48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53ee7894c6594018976544a089f7a4bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53742deb2cb9425a8c9d15bc0969ad48",
       "placeholder": "​",
       "style": "IPY_MODEL_209fbbc70fbb4e6f9921bf27ead0bb1f",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.04it/s]"
      }
     },
     "544aa9987e4d4895a1f7f557e802efc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_066d90f01a1143f3978e61982941e7f6",
       "placeholder": "​",
       "style": "IPY_MODEL_2d0029972ac447bd8a35a86592bf0cd5",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:11&lt;00:00,  6.03it/s]"
      }
     },
     "586b7ca0587d411db18c520c18aaeac5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fdbd7354e877476f8fa292ccc35b748b",
        "IPY_MODEL_f0818d598a7f4661967ac47d602459fd",
        "IPY_MODEL_76ff731fe4e34bd0937ba551ee69304c"
       ],
       "layout": "IPY_MODEL_aeafa42fe28f4c79a215236e3a2e15b1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5bc319571b9c41568adacebcae460b8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c674890af724f51a1fe50ef08f7999b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "646ead03e1724da3b74bc029f1ce261b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "668d4c370a414fb4a9903ee787bec9f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68cfa8890f584e2fadc9ab527c886f2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69c5e621c95e469bb93b6f5a701a0c6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7ce6934eb304159b9e439f663729713",
       "placeholder": "​",
       "style": "IPY_MODEL_bf778281e7254c8185da77ddf6e9280e",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "6d10c0557a314f66bf85b7077ac07203": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb2bdc3d9e70431385e5f2b4c3bc94fc",
       "placeholder": "​",
       "style": "IPY_MODEL_3a40a1c0529b4e48b953ec08fada9505",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "70a81a552ab44525b10a069629981218": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73c1f46052164b62a09e4e17481e743e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73f952f9703544179faa013f5a5eab63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c674890af724f51a1fe50ef08f7999b",
       "max": 1500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30e877ee808f4b77bf2188c4d05a1f69",
       "tabbable": null,
       "tooltip": null,
       "value": 1500.0
      }
     },
     "76ff731fe4e34bd0937ba551ee69304c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_646ead03e1724da3b74bc029f1ce261b",
       "placeholder": "​",
       "style": "IPY_MODEL_d5f251f5e537498d945387ebbab50440",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.01it/s]"
      }
     },
     "7846bd70fca046f8ae25fe3120b350a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e559453b8d84d588d4442d35e49f0b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4a9506a053eb414a9852e99e5bce3e2d",
        "IPY_MODEL_ba5b8426335a40ff9eb0ee4b6f98a15f",
        "IPY_MODEL_19957cb560fa4675be67692f90bfe124"
       ],
       "layout": "IPY_MODEL_1d35a13d559047c18b0570787096c0f7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "87b2fd572de4431684bf7761d1012316": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ae9f00dfd1545bc9ca846d48c67014a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ca3f0c7e70147499cc2aa7c47303c6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "939a88bba61846e981a8401ef747f1b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_35aa1e9e0d564ef38a3cd0e1c54a0515",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3efcaa8bb2d5485693b395238d1e760b",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "9416c4f368a64c339e8fdf7b7ec8eb0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98fe915c9c2c49138a9719059bb79f9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d412a3fb5a244f3a78aeef7e7f6b375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7ca573d0b88472186451a42902d404b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aeafa42fe28f4c79a215236e3a2e15b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0c27068f1334c12bb462411e87b0767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68cfa8890f584e2fadc9ab527c886f2b",
       "placeholder": "​",
       "style": "IPY_MODEL_73c1f46052164b62a09e4e17481e743e",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.03it/s]"
      }
     },
     "b2bb4f59afb34027bdc812d0a24dd03b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5f6c9b38b8a4716b68e9b85f0417ead": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba5b8426335a40ff9eb0ee4b6f98a15f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0edfddafaa2f4d9e98e4378a4ce394e0",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d657b7a47d5406c93f7feca83cb2e72",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "bd23757aafc44a078e0cf44bc64c5026": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_36cb4b7e4d0343a8ab54f08cac257911",
        "IPY_MODEL_1801622ddcaf4b14a69b5323fdf01566",
        "IPY_MODEL_e7fe166921ac4f2094f23cac76ae830b"
       ],
       "layout": "IPY_MODEL_eeb2e8f9a6f94c948d45575f339aef93",
       "tabbable": null,
       "tooltip": null
      }
     },
     "be5da53c7f2d4a69bee4441771d121ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bf3c476a4b1b4fb1a4ee1a567c67cd6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf778281e7254c8185da77ddf6e9280e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c2b9d964e9c546cd9a18e75b4be68806": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b2bb4f59afb34027bdc812d0a24dd03b",
       "placeholder": "​",
       "style": "IPY_MODEL_26b48063a4fd486282386d24c00117d1",
       "tabbable": null,
       "tooltip": null,
       "value": " 1500/1500 [04:08&lt;00:00,  6.03it/s]"
      }
     },
     "cb0de8dc50434c89b7c9143324105aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb2bdc3d9e70431385e5f2b4c3bc94fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd3c403776dd4bc097569a61d484eba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cd84fc2aebe34990b65c28d6975bdc5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5f251f5e537498d945387ebbab50440": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d660a18b7c70473dbb85c5be768cafa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc44ba609417413b89d904f9ba00661a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_69c5e621c95e469bb93b6f5a701a0c6c",
        "IPY_MODEL_ecfd12ae738e433e80b2dfc51f3d9dee",
        "IPY_MODEL_b0c27068f1334c12bb462411e87b0767"
       ],
       "layout": "IPY_MODEL_a7ca573d0b88472186451a42902d404b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e7ce6934eb304159b9e439f663729713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7fe166921ac4f2094f23cac76ae830b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4cdd2c100aa446991dfaceb29db7e47",
       "placeholder": "​",
       "style": "IPY_MODEL_cb0de8dc50434c89b7c9143324105aa3",
       "tabbable": null,
       "tooltip": null,
       "value": " 63/63 [00:10&lt;00:00,  6.01it/s]"
      }
     },
     "ecfd12ae738e433e80b2dfc51f3d9dee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7846bd70fca046f8ae25fe3120b350a8",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_53619e91e7fb4d68a11301cf8cfe47f0",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "ee2294f601494afcac5c60b0f2301e53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19587120d2634fb2adbbf45084e049ec",
       "placeholder": "​",
       "style": "IPY_MODEL_98fe915c9c2c49138a9719059bb79f9d",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "ee561955d82347b9b8a8e3382beae16b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bf3c476a4b1b4fb1a4ee1a567c67cd6f",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fb867b2d2d5e4f1baa7c75484fa12d73",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "eeb2e8f9a6f94c948d45575f339aef93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0818d598a7f4661967ac47d602459fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5bc319571b9c41568adacebcae460b8e",
       "max": 63.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d366e9f30034dcdb20c97c6792fb00b",
       "tabbable": null,
       "tooltip": null,
       "value": 63.0
      }
     },
     "f1aa9ecdccd94598a044c9778dfbb521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d38b1008feb4fb7b4f87f7a92a918c4",
       "placeholder": "​",
       "style": "IPY_MODEL_d660a18b7c70473dbb85c5be768cafa3",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "f357e8c5ee6f495c867922b9b7522fe4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4cdd2c100aa446991dfaceb29db7e47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f518b78477ca41c096eaedb284d1e47a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7898f334d6c48efa892e73c5d8866aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fb867b2d2d5e4f1baa7c75484fa12d73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fdbd7354e877476f8fa292ccc35b748b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ca3f0c7e70147499cc2aa7c47303c6e",
       "placeholder": "​",
       "style": "IPY_MODEL_cd3c403776dd4bc097569a61d484eba8",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
