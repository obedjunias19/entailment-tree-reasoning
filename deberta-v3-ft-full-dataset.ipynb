{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a203938e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:25.546164Z",
     "iopub.status.busy": "2025-11-18T03:53:25.545865Z",
     "iopub.status.idle": "2025-11-18T03:53:27.154195Z",
     "shell.execute_reply": "2025-11-18T03:53:27.153201Z"
    },
    "papermill": {
     "duration": 1.615868,
     "end_time": "2025-11-18T03:53:27.155553",
     "exception": false,
     "start_time": "2025-11-18T03:53:25.539685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_all_hf.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e0cfb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.164131Z",
     "iopub.status.busy": "2025-11-18T03:53:27.163779Z",
     "iopub.status.idle": "2025-11-18T03:53:27.167486Z",
     "shell.execute_reply": "2025-11-18T03:53:27.166911Z"
    },
    "papermill": {
     "duration": 0.00924,
     "end_time": "2025-11-18T03:53:27.168695",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.159455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# train_df = pd.DataFrame(data[\"questions\"])\n",
    "# train_df.to_csv('train_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# dev_df = pd.DataFrame(data[\"questions\"])\n",
    "# dev_df.to_csv('dev_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# dev_df.head()\n",
    "\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# test_df = pd.DataFrame(data[\"questions\"])\n",
    "# test_df.to_csv('test_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b91c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.177113Z",
     "iopub.status.busy": "2025-11-18T03:53:27.176651Z",
     "iopub.status.idle": "2025-11-18T03:53:27.179915Z",
     "shell.execute_reply": "2025-11-18T03:53:27.179337Z"
    },
    "papermill": {
     "duration": 0.008969,
     "end_time": "2025-11-18T03:53:27.181260",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.172291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de01fc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.189603Z",
     "iopub.status.busy": "2025-11-18T03:53:27.189351Z",
     "iopub.status.idle": "2025-11-18T03:53:27.195731Z",
     "shell.execute_reply": "2025-11-18T03:53:27.195113Z"
    },
    "papermill": {
     "duration": 0.012101,
     "end_time": "2025-11-18T03:53:27.196910",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.184809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "# import ast\n",
    "\n",
    "# # Load your dataset\n",
    "# df = pd.read_csv(\"/kaggle/working/train_logical_combinations_output.csv\")  # replace with your file\n",
    "\n",
    "# # Safe eval to ensure lists are properly loaded\n",
    "# def safe_eval(val):\n",
    "#     if isinstance(val, list):\n",
    "#         return val\n",
    "#     if pd.isna(val):\n",
    "#         return []\n",
    "#     if isinstance(val, str):\n",
    "#         try:\n",
    "#             return ast.literal_eval(val)\n",
    "#         except:\n",
    "#             return []\n",
    "#     return []\n",
    "\n",
    "# df['logical_combinations'] = df['logical_combinations'].apply(safe_eval)\n",
    "\n",
    "# # Prepare storage for QA sets\n",
    "# qa_sets = {\n",
    "#     'AND': [],\n",
    "#     'OR': [],\n",
    "#     'NEITHER': [],\n",
    "#     'Mixed': []\n",
    "# }\n",
    "\n",
    "# # Label rotation - separate rotator for each question type\n",
    "# class LabelRotator:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.labels = ['A', 'B', 'C', 'D']\n",
    "#         self.current_index = 0\n",
    "    \n",
    "#     def get_next_label(self):\n",
    "#         label = self.labels[self.current_index]\n",
    "#         self.current_index = (self.current_index + 1) % len(self.labels)\n",
    "#         # print(f\"DEBUG {self.name}: Assigned label {label}, next will be {self.labels[self.current_index]}\")\n",
    "#         return label\n",
    "\n",
    "# # Create separate rotators for each question type\n",
    "# rotators = {\n",
    "#     'AND': LabelRotator('AND'),\n",
    "#     'OR': LabelRotator('OR'),\n",
    "#     'NEITHER': LabelRotator('NEITHER'),\n",
    "#     'Mixed': LabelRotator('Mixed')\n",
    "# }\n",
    "\n",
    "# def create_qa_item(question, correct_ans, incorrect_ans, qa_type):\n",
    "#     \"\"\"Helper function to create a QA item with proper label rotation\"\"\"\n",
    "    \n",
    "#     # Get correct label from the appropriate rotator\n",
    "#     correct_label = rotators[qa_type].get_next_label()\n",
    "    \n",
    "#     # Ensure we have exactly 3 incorrect answers\n",
    "#     if len(incorrect_ans) < 3:\n",
    "#         print(f\"Warning: Only {len(incorrect_ans)} incorrect answers available for {qa_type}\")\n",
    "#         return None\n",
    "    \n",
    "#     selected_incorrect = random.sample(incorrect_ans, 3)\n",
    "    \n",
    "#     # Create options array with 4 positions\n",
    "#     options = [''] * 4\n",
    "    \n",
    "#     # Place correct answer at the designated position\n",
    "#     correct_pos = rotators[qa_type].labels.index(correct_label)\n",
    "#     options[correct_pos] = correct_ans\n",
    "    \n",
    "#     # Fill remaining positions with incorrect answers\n",
    "#     incorrect_positions = [i for i in range(4) if i != correct_pos]\n",
    "#     for i, pos in enumerate(incorrect_positions):\n",
    "#         options[pos] = selected_incorrect[i]\n",
    "    \n",
    "#     return {\n",
    "#         'question': question,\n",
    "#         'A': options[0],\n",
    "#         'B': options[1],\n",
    "#         'C': options[2],\n",
    "#         'D': options[3],\n",
    "#         'correct_label': correct_label,\n",
    "#         'correct_answer_text': correct_ans,\n",
    "#         'qa_type': qa_type\n",
    "#     }\n",
    "\n",
    "# # Track counts for each type\n",
    "# type_counts = {'AND': 0, 'OR': 0, 'NEITHER': 0, 'Mixed': 0}\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     question = row['question']\n",
    "#     combos = row['logical_combinations']\n",
    "    \n",
    "#     # Extract AND/OR/NEITHER correct and incorrect lists\n",
    "#     and_correct = combos.get('AND_combinations', {}).get('correct', [])\n",
    "#     and_incorrect = combos.get('AND_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     or_correct = combos.get('OR_combinations', {}).get('correct', [])\n",
    "#     or_incorrect = combos.get('OR_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     neither_correct = combos.get('NEITHER_combinations', {}).get('correct', [])\n",
    "#     neither_incorrect = combos.get('NEITHER_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     # --- AND-only QA ---\n",
    "#     if and_correct and len(and_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(and_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, and_incorrect, 'AND')\n",
    "#         if qa_item:\n",
    "#             qa_sets['AND'].append(qa_item)\n",
    "#             type_counts['AND'] += 1\n",
    "#             # print(f\"AND Question {type_counts['AND']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- OR-only QA ---\n",
    "#     if or_correct and len(or_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(or_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, or_incorrect, 'OR')\n",
    "#         if qa_item:\n",
    "#             qa_sets['OR'].append(qa_item)\n",
    "#             type_counts['OR'] += 1\n",
    "#             # print(f\"OR Question {type_counts['OR']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- NEITHER-only QA ---\n",
    "#     if neither_correct and len(neither_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(neither_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, neither_incorrect, 'NEITHER')\n",
    "#         if qa_item:\n",
    "#             qa_sets['NEITHER'].append(qa_item)\n",
    "#             type_counts['NEITHER'] += 1\n",
    "#             # print(f\"NEITHER Question {type_counts['NEITHER']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- Mixed QA ---\n",
    "#     all_correct_types = [\n",
    "#         ('AND', and_correct),\n",
    "#         ('OR', or_correct),\n",
    "#         ('NEITHER', neither_correct)\n",
    "#     ]\n",
    "#     all_incorrect_types = and_incorrect + or_incorrect + neither_incorrect\n",
    "    \n",
    "#     # Ensure at least one correct exists and enough incorrect answers\n",
    "#     valid_categories = [cat for cat, lst in all_correct_types if lst]\n",
    "#     if valid_categories and len(all_incorrect_types) >= 3:\n",
    "#         chosen_category = random.choice(valid_categories)\n",
    "#         chosen_correct_list = dict(all_correct_types)[chosen_category]\n",
    "#         correct_ans = random.choice(chosen_correct_list)\n",
    "#         qa_item = create_qa_item(question, correct_ans, all_incorrect_types, 'Mixed')\n",
    "#         if qa_item:\n",
    "#             qa_sets['Mixed'].append(qa_item)\n",
    "#             type_counts['Mixed'] += 1\n",
    "#             # print(f\"Mixed Question {type_counts['Mixed']}: Label {qa_item['correct_label']}\")\n",
    "\n",
    "# print(f\"\\n=== GENERATION COMPLETE ===\")\n",
    "# for qtype, count in type_counts.items():\n",
    "#     print(f\"{qtype}: {count} questions generated\")\n",
    "\n",
    "# # --- Convert to DataFrames and save ---\n",
    "# for key, qlist in qa_sets.items():\n",
    "#     if qlist:  # Only save if we have questions\n",
    "#         df_out = pd.DataFrame(qlist)\n",
    "#         df_out.to_csv(f'train_qa_{key}.csv', index=False)\n",
    "#         print(f\"\\n{key} QA saved: {len(df_out)} questions in train_qa_{key}.csv\")\n",
    "        \n",
    "#         # Show label distribution for verification\n",
    "#         label_counts = df_out['correct_label'].value_counts().sort_index()\n",
    "#         print(f\"  Label distribution: {dict(label_counts)}\")\n",
    "        \n",
    "#         # Show label sequence for first 8 questions to verify rotation\n",
    "#         print(f\"  Label sequence (first 8): {list(df_out['correct_label'].head(8))}\")\n",
    "#     else:\n",
    "#         print(f\"{key}: No valid QA pairs generated\")\n",
    "\n",
    "# # Overall statistics\n",
    "# total_questions = sum(len(qlist) for qlist in qa_sets.values())\n",
    "# print(f\"\\nFinal total questions generated: {total_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be97a1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.205497Z",
     "iopub.status.busy": "2025-11-18T03:53:27.204764Z",
     "iopub.status.idle": "2025-11-18T03:53:27.207986Z",
     "shell.execute_reply": "2025-11-18T03:53:27.207408Z"
    },
    "papermill": {
     "duration": 0.008618,
     "end_time": "2025-11-18T03:53:27.209134",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.200516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and  = pd.read_csv('/kaggle/working/test_qa_AND.csv')\n",
    "\n",
    "# train_qa_and.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e71716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.217468Z",
     "iopub.status.busy": "2025-11-18T03:53:27.217204Z",
     "iopub.status.idle": "2025-11-18T03:53:27.220691Z",
     "shell.execute_reply": "2025-11-18T03:53:27.219963Z"
    },
    "papermill": {
     "duration": 0.009064,
     "end_time": "2025-11-18T03:53:27.221916",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.212852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7accf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.230266Z",
     "iopub.status.busy": "2025-11-18T03:53:27.229635Z",
     "iopub.status.idle": "2025-11-18T03:53:27.233731Z",
     "shell.execute_reply": "2025-11-18T03:53:27.233139Z"
    },
    "papermill": {
     "duration": 0.009443,
     "end_time": "2025-11-18T03:53:27.234923",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.225480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# and_df = pd.read_csv(\"train_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"train_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"train_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"train_qa_Mixed.csv\")\n",
    "\n",
    "# train_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# train_df.to_csv(\"train_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"dev_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"dev_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"dev_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"dev_qa_Mixed.csv\")\n",
    "\n",
    "# dev_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# dev_df.to_csv(\"dev_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"test_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"test_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"test_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"test_qa_Mixed.csv\")\n",
    "\n",
    "# test_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# test_df.to_csv(\"test_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93abab9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.243260Z",
     "iopub.status.busy": "2025-11-18T03:53:27.242900Z",
     "iopub.status.idle": "2025-11-18T03:53:27.246662Z",
     "shell.execute_reply": "2025-11-18T03:53:27.245948Z"
    },
    "papermill": {
     "duration": 0.009203,
     "end_time": "2025-11-18T03:53:27.247815",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.238612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "# train_df[\"choices\"] = train_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# train_df[\"label\"] = train_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_train_df = train_df[[\"question\", \"choices\", \"label\", \"qa_type\"]]\n",
    "\n",
    "# hf_train_df.to_json(\"train_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# dev_df[\"choices\"] = dev_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# dev_df[\"label\"] = dev_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_dev_df = dev_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_dev_df.to_json(\"dev_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "# test_df[\"choices\"] = test_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# test_df[\"label\"] = test_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_test_df = test_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_test_df.to_json(\"test_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1182ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.255933Z",
     "iopub.status.busy": "2025-11-18T03:53:27.255490Z",
     "iopub.status.idle": "2025-11-18T03:53:27.258790Z",
     "shell.execute_reply": "2025-11-18T03:53:27.258042Z"
    },
    "papermill": {
     "duration": 0.008736,
     "end_time": "2025-11-18T03:53:27.260085",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.251349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e248349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:27.267954Z",
     "iopub.status.busy": "2025-11-18T03:53:27.267564Z",
     "iopub.status.idle": "2025-11-18T03:53:39.991517Z",
     "shell.execute_reply": "2025-11-18T03:53:39.990491Z"
    },
    "papermill": {
     "duration": 12.729365,
     "end_time": "2025-11-18T03:53:39.992929",
     "exception": false,
     "start_time": "2025-11-18T03:53:27.263564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n",
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "  PyArrow 19.0.1\n",
      "  Datasets 4.4.1\n",
      "  Transformers 4.53.3\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Clean uninstall everything\n",
    "# !pip uninstall -y protobuf pyarrow google-protobuf datasets transformers accelerate bitsandbytes peft trl\n",
    "\n",
    "# # Step 2: Install in the correct order with compatible versions\n",
    "!pip install --upgrade --no-cache-dir protobuf==3.20.3\n",
    "# !pip install --no-cache-dir pyarrow==12.0.1\n",
    "# !pip install --no-cache-dir datasets==2.14.0\n",
    "# !pip install --no-cache-dir transformers==4.35.2\n",
    "# !pip install --no-cache-dir accelerate\n",
    "\n",
    "# Step 3: Verify installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "try:\n",
    "    import pyarrow as pa\n",
    "    print(f\"  PyArrow {pa.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PyArrow failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"  Datasets {datasets.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Datasets failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import __version__\n",
    "    print(f\"  Transformers {__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Transformers failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ff9a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:40.003334Z",
     "iopub.status.busy": "2025-11-18T03:53:40.002330Z",
     "iopub.status.idle": "2025-11-18T03:53:40.006424Z",
     "shell.execute_reply": "2025-11-18T03:53:40.005644Z"
    },
    "papermill": {
     "duration": 0.010357,
     "end_time": "2025-11-18T03:53:40.007585",
     "exception": false,
     "start_time": "2025-11-18T03:53:39.997228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Uninstall and reinstall datasets with matching pyarrow version\n",
    "# !pip uninstall -y datasets  pyarrow\n",
    "# !pip install --no-cache-dir pyarrow\n",
    "# !pip install --no-cache-dir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e240a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:40.016472Z",
     "iopub.status.busy": "2025-11-18T03:53:40.016009Z",
     "iopub.status.idle": "2025-11-18T03:53:48.026434Z",
     "shell.execute_reply": "2025-11-18T03:53:48.025275Z"
    },
    "papermill": {
     "duration": 8.016599,
     "end_time": "2025-11-18T03:53:48.027974",
     "exception": false,
     "start_time": "2025-11-18T03:53:40.011375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\r\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyarrow, evaluate\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9294439c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:48.040819Z",
     "iopub.status.busy": "2025-11-18T03:53:48.040488Z",
     "iopub.status.idle": "2025-11-18T03:53:48.046406Z",
     "shell.execute_reply": "2025-11-18T03:53:48.045540Z"
    },
    "papermill": {
     "duration": 0.014051,
     "end_time": "2025-11-18T03:53:48.047836",
     "exception": false,
     "start_time": "2025-11-18T03:53:48.033785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "# from transformers import TrainingArguments, Trainer, DataCollatorForMultipleChoice\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import json\n",
    "# import evaluate\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # Custom Dataset class to replace datasets.load_dataset\n",
    "# import json\n",
    "\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item[\"qa_type\"] \n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type \n",
    "#         }\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", tokenizer)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", tokenizer)\n",
    "\n",
    "# data_collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "\n",
    "# # Rest of your code remains the same\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = p.predictions.argmax(-1)\n",
    "#     return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./deberta-v3-mcqa\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=1e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=4,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_steps=50,\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb09769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:48.060311Z",
     "iopub.status.busy": "2025-11-18T03:53:48.060023Z",
     "iopub.status.idle": "2025-11-18T03:53:48.072442Z",
     "shell.execute_reply": "2025-11-18T03:53:48.071667Z"
    },
    "papermill": {
     "duration": 0.020665,
     "end_time": "2025-11-18T03:53:48.073688",
     "exception": false,
     "start_time": "2025-11-18T03:53:48.053023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch\n",
    "# from torch.optim import AdamW\n",
    "# from tqdm.auto import tqdm\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "# import random\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# training_config = {\n",
    "#     'max_epochs': 10,\n",
    "#     'patience': 3,  # Early stopping patience\n",
    "#     'min_delta': 0.001,  # Minimum improvement to count\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 2e-5,\n",
    "#     'warmup_steps': 500,\n",
    "#     'gradient_accumulation_steps': 2,\n",
    "#     'weight_decay': 0.01,\n",
    "#     'max_length': 256\n",
    "# }\n",
    "\n",
    "# print(\"\\nTraining Configuration:\")\n",
    "# for key, value in training_config.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "# # Custom Dataset\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 if line.strip():\n",
    "#                     self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#         print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "#         # Print dataset statistics\n",
    "#         type_counts = defaultdict(int)\n",
    "#         for item in self.data:\n",
    "#             type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "#         print(\"Dataset composition:\")\n",
    "#         for qa_type, count in sorted(type_counts.items()):\n",
    "#             print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type\n",
    "#         }\n",
    "\n",
    "# def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "#     \"\"\"\n",
    "#     Compute comprehensive metrics for dataset paper\n",
    "#     Returns per-type metrics with BOTH micro and macro averaging\n",
    "#     \"\"\"\n",
    "#     predictions = np.array(predictions)\n",
    "#     labels = np.array(labels)\n",
    "#     qa_types = np.array(qa_types)\n",
    "    \n",
    "#     unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "#     results = {\n",
    "#         'per_type': {},\n",
    "#         'macro_across_types': {},\n",
    "#         'micro_overall': {},\n",
    "#         'confusion_matrices': {}\n",
    "#     }\n",
    "    \n",
    "#     # Per-type metrics (with both micro and macro within type)\n",
    "#     for qa_type in unique_types:\n",
    "#         mask = qa_types == qa_type\n",
    "#         type_preds = predictions[mask]\n",
    "#         type_labels = labels[mask]\n",
    "        \n",
    "#         if len(type_preds) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         # MACRO: Average metrics across the 4 answer choices for this type\n",
    "#         macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # MICRO: Global metrics for this type (same as accuracy)\n",
    "#         micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         # Per-class metrics for this type (for detailed analysis)\n",
    "#         per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "#         results['per_type'][qa_type] = {\n",
    "#             # Macro metrics (average across 4 answer choices)\n",
    "#             'macro': {\n",
    "#                 'precision': macro_precision,\n",
    "#                 'recall': macro_recall,\n",
    "#                 'f1': macro_f1,\n",
    "#             },\n",
    "#             # Micro metrics (global for this type)\n",
    "#             'micro': {\n",
    "#                 'precision': micro_precision,  # same as accuracy\n",
    "#                 'recall': micro_recall,        # same as accuracy\n",
    "#                 'f1': micro_f1,                # same as accuracy\n",
    "#                 'accuracy': accuracy,\n",
    "#             },\n",
    "#             # Per-answer-choice metrics\n",
    "#             'per_choice': {\n",
    "#                 f'choice_{i}': {\n",
    "#                     'precision': per_class_precision[i],\n",
    "#                     'recall': per_class_recall[i],\n",
    "#                     'f1': per_class_f1[i],\n",
    "#                     'support': per_class_support[i]\n",
    "#                 } for i in range(4)\n",
    "#             },\n",
    "#             'support': len(type_preds),\n",
    "#             'correct': (type_preds == type_labels).sum()\n",
    "#         }\n",
    "        \n",
    "#         # Confusion matrix for this type\n",
    "#         results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "#             type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "    \n",
    "#     # Macro metrics across logical types (what you typically report in paper)\n",
    "#     macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "#     macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "#     macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "#     macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "#     results['macro_across_types'] = {\n",
    "#         'precision': macro_across_types_precision,\n",
    "#         'recall': macro_across_types_recall,\n",
    "#         'f1': macro_across_types_f1,\n",
    "#         'accuracy': macro_across_types_accuracy\n",
    "#     }\n",
    "    \n",
    "#     # Micro metrics overall (global across all instances)\n",
    "#     micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#         labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#     )\n",
    "#     micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "#     results['micro_overall'] = {\n",
    "#         'accuracy': micro_accuracy,\n",
    "#         'precision': micro_precision,\n",
    "#         'recall': micro_recall,\n",
    "#         'f1': micro_f1,\n",
    "#         'support': len(predictions),\n",
    "#         'correct': (predictions == labels).sum()\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def evaluate_comprehensive(model, dataloader, device):\n",
    "#     \"\"\"Comprehensive evaluation with all metrics\"\"\"\n",
    "#     model.eval()\n",
    "    \n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "#     all_types = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "#             qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "#             all_predictions.extend(predictions.cpu().tolist())\n",
    "#             all_labels.extend(labels.cpu().tolist())\n",
    "#             all_types.extend(qa_types)\n",
    "    \n",
    "#     metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "#     return metrics\n",
    "\n",
    "# def print_results_table(metrics, epoch=None, model_name=None):\n",
    "#     \"\"\"Print results table\"\"\"\n",
    "    \n",
    "#     if epoch is not None:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         if model_name:\n",
    "#             print(f\"Model: {model_name} | Epoch {epoch}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "    \n",
    "#     print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for qa_type in sorted(metrics['per_type'].keys()):\n",
    "#         m_macro = metrics['per_type'][qa_type]['macro']\n",
    "#         m_micro = metrics['per_type'][qa_type]['micro']\n",
    "#         support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "#         print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "#               f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     m = metrics['macro_across_types']\n",
    "#     print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "#     m = metrics['micro_overall']\n",
    "#     print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", \n",
    "#                            tokenizer, max_length=256)\n",
    "# eval_dataset = MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", \n",
    "#                           tokenizer, max_length=256)\n",
    "\n",
    "# # Setup data loaders\n",
    "# batch_size = training_config['batch_size']\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Setup model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"\\nDevice: {device}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Setup optimizer and scheduler\n",
    "# optimizer = AdamW(model.parameters(), \n",
    "#                  lr=training_config['learning_rate'], \n",
    "#                  weight_decay=training_config['weight_decay'])\n",
    "# num_training_steps = training_config['max_epochs'] * len(train_loader) // training_config['gradient_accumulation_steps']\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=training_config['warmup_steps'],\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "# # Training loop with early stopping\n",
    "# best_macro_f1 = 0\n",
    "# best_epoch = 0\n",
    "# epochs_without_improvement = 0\n",
    "# best_metrics = None\n",
    "# training_history = []\n",
    "\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(f\"Training {model_name} with Early Stopping\")\n",
    "# print(f\"Max Epochs: {training_config['max_epochs']}, Patience: {training_config['patience']}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# for epoch in range(training_config['max_epochs']):\n",
    "#     print(f\"\\n{'='*100}\")\n",
    "#     print(f\"Epoch {epoch + 1}/{training_config['max_epochs']}\")\n",
    "#     print(f\"{'='*100}\")\n",
    "    \n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "#     for step, batch in enumerate(progress_bar):\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "#         # Forward pass (no mixed precision for P100)\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "#         loss = outputs.loss / training_config['gradient_accumulation_steps']\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Gradient accumulation\n",
    "#         if (step + 1) % training_config['gradient_accumulation_steps'] == 0:\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "        \n",
    "#         total_loss += loss.item() * training_config['gradient_accumulation_steps']\n",
    "#         progress_bar.set_postfix({\"loss\": f\"{total_loss / (step + 1):.4f}\"})\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     print(f\"\\nTrain Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "#     # Evaluation\n",
    "#     print(\"\\nEvaluating...\")\n",
    "#     metrics = evaluate_comprehensive(model, eval_loader, device)\n",
    "#     print_results_table(metrics, epoch=epoch + 1, model_name=model_name)\n",
    "    \n",
    "#     macro_f1 = metrics['macro_across_types']['f1']\n",
    "#     macro_acc = metrics['macro_across_types']['accuracy']\n",
    "    \n",
    "#     # Save history\n",
    "#     training_history.append({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'train_loss': avg_train_loss,\n",
    "#         'macro_f1': macro_f1,\n",
    "#         'macro_accuracy': macro_acc,\n",
    "#         'macro_precision': metrics['macro_across_types']['precision'],\n",
    "#         'macro_recall': metrics['macro_across_types']['recall']\n",
    "#     })\n",
    "    \n",
    "#     # Early stopping check\n",
    "#     improvement = macro_f1 - best_macro_f1\n",
    "    \n",
    "#     if improvement > training_config['min_delta']:\n",
    "#         best_macro_f1 = macro_f1\n",
    "#         best_epoch = epoch + 1\n",
    "#         best_metrics = metrics\n",
    "#         epochs_without_improvement = 0\n",
    "        \n",
    "#         save_dir = f\"./{model_name.replace('/', '-')}-best\"\n",
    "#         print(f\"\\n  New best Macro F1: {macro_f1:.4f} (↑{improvement:.4f})! Saving to {save_dir}\")\n",
    "#         model.save_pretrained(save_dir)\n",
    "#         tokenizer.save_pretrained(save_dir)\n",
    "        \n",
    "#         def convert_to_serializable(obj):\n",
    "#             if isinstance(obj, dict):\n",
    "#                 return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "#             elif isinstance(obj, (np.integer, np.floating)):\n",
    "#                 return float(obj)\n",
    "#             elif isinstance(obj, np.ndarray):\n",
    "#                 return obj.tolist()\n",
    "#             return obj\n",
    "        \n",
    "#         results_for_paper = {\n",
    "#             'model': model_name,\n",
    "#             'best_epoch': best_epoch,\n",
    "#             'training_config': training_config,\n",
    "#             'training_history': training_history,\n",
    "#             'best_metrics': convert_to_serializable(best_metrics)\n",
    "#         }\n",
    "        \n",
    "#         with open(f\"{save_dir}/results_detailed.json\", \"w\") as f:\n",
    "#             json.dump(results_for_paper, f, indent=2)\n",
    "#     else:\n",
    "#         epochs_without_improvement += 1\n",
    "#         print(f\"\\n   No improvement for {epochs_without_improvement} epoch(s) \"\n",
    "#               f\"(current: {macro_f1:.4f}, best: {best_macro_f1:.4f})\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if epochs_without_improvement >= training_config['patience']:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         print(f\"Early stopping triggered!\")\n",
    "#         print(f\"Best Macro F1: {best_macro_f1:.4f} at epoch {best_epoch}\")\n",
    "#         print(f\"Training stopped at epoch {epoch + 1}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "#         break\n",
    "\n",
    "# # Final summary\n",
    "# print(f\"\\n{'='*100}\")\n",
    "# print(\"Training Complete!\")\n",
    "# print(f\"{'='*100}\")\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}/{epoch + 1}\")\n",
    "# print(f\"Best Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"{'='*100}\")\n",
    "\n",
    "# if best_metrics is not None:\n",
    "#     print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "#     print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# else:\n",
    "#     print(\"Best Validation Macro F1: n/a (no improvement over initial baseline)\")\n",
    "#     print(\"Best Validation Macro Accuracy: n/a\")\n",
    "\n",
    "\n",
    "# # Plot training curves\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# epochs_list = [h['epoch'] for h in training_history]\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.plot(epochs_list, [h['train_loss'] for h in training_history], marker='o', label='Train Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.plot(epochs_list, [h['macro_f1'] for h in training_history], marker='o', color='green', label='Macro F1')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Macro F1')\n",
    "# plt.title('Validation Macro F1')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.plot(epochs_list, [h['macro_accuracy'] for h in training_history], marker='o', color='blue', label='Macro Accuracy')\n",
    "# plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Macro Accuracy')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{model_name.replace(\"/\", \"-\")}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "# print(f\"\\n  Saved training curves to {model_name.replace('/', '-')}_training_curves.png\")\n",
    "\n",
    "# # Summary table for paper\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY FOR PAPER:\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Model: {model_name}\")\n",
    "# print(f\"Best Epoch: {best_epoch}\")\n",
    "# print(f\"Total Epochs Trained: {len(training_history)}\")\n",
    "# print(f\"Converged: {'Yes (early stopping)' if epochs_without_improvement >= training_config['patience'] else 'No (completed all epochs)'}\")\n",
    "# print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "# print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c3e859d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T03:53:48.086828Z",
     "iopub.status.busy": "2025-11-18T03:53:48.086552Z",
     "iopub.status.idle": "2025-11-18T04:00:01.036421Z",
     "shell.execute_reply": "2025-11-18T04:00:01.035335Z"
    },
    "papermill": {
     "duration": 372.958797,
     "end_time": "2025-11-18T04:00:01.037974",
     "exception": false,
     "start_time": "2025-11-18T03:53:48.079177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Configuration:\n",
      "  batch_size: 4\n",
      "  max_length: 256\n",
      "Model: microsoft/deberta-v3-base\n",
      "\n",
      "Loading model: microsoft/deberta-v3-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13d60653cd9496c8136da8dbbe25650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3dfd2e4a6542c9be1f30d199130aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95c820fd9a5420ca6fa115ac876342f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "2025-11-18 03:54:03.217668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763438043.432430      18 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763438043.488648      18 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a42a62021cd47b98e4c668ac8d1f8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9169e8f1804a76b353224a1d2e8d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6000 examples from /kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 1500 (25.0%)\n",
      "  Mixed: 1500 (25.0%)\n",
      "  NEITHER: 1500 (25.0%)\n",
      "  OR: 1500 (25.0%)\n",
      "Loaded 2000 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 500 (25.0%)\n",
      "  Mixed: 500 (25.0%)\n",
      "  NEITHER: 500 (25.0%)\n",
      "  OR: 500 (25.0%)\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Dev Set Evaluation: microsoft/deberta-v3-base\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5814839a54644c55b3b67cd4d429052e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: microsoft/deberta-v3-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.2580     0.2580     0.2580     0.2580     1500\n",
      "Mixed            0.2987     0.2986     0.2987     0.2986     1500\n",
      "NEITHER          0.2660     0.2659     0.2660     0.2659     1500\n",
      "OR               0.3460     0.3459     0.3460     0.3458     1500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.2922     0.2921     0.2922     0.2921        -\n",
      "Micro Avg        0.2922     0.2922     0.2922     0.2922     6000\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Test Set Evaluation: microsoft/deberta-v3-base\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186a55ba15d64ff3bbf5976af310dc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: microsoft/deberta-v3-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.2840     0.2843     0.2840     0.2835      500\n",
      "Mixed            0.3040     0.3048     0.3040     0.3037      500\n",
      "NEITHER          0.2600     0.2598     0.2600     0.2595      500\n",
      "OR               0.3200     0.3206     0.3200     0.3200      500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.2920     0.2924     0.2920     0.2917        -\n",
      "Micro Avg        0.2920     0.2920     0.2920     0.2920     2000\n",
      "====================================================================================================\n",
      "\n",
      "Results saved to microsoft-deberta-v3-base_zeroshot_results.json\n",
      "\n",
      "====================================================================================================\n",
      "ZERO-SHOT RESULTS SUMMARY (TEST SET):\n",
      "====================================================================================================\n",
      "Model: microsoft/deberta-v3-base\n",
      "Evaluation Type: Zero-Shot (No Training)\n",
      "Test Examples: 2000\n",
      "Macro F1 (across types): 0.2917\n",
      "Macro Accuracy (across types): 0.2920\n",
      "Micro F1 (overall): 0.2920\n",
      "Micro Accuracy (overall): 0.2920\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "\n",
    "eval_config = {\n",
    "    'batch_size': 4,  # Can use larger batch for inference\n",
    "    'max_length': 256\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluation Configuration:\")\n",
    "for key, value in eval_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nLoading model: {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "class MCQADataset(Dataset):\n",
    "    def __init__(self, json_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        with open(json_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    self.data.append(json.loads(line.strip()))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "        # Print dataset statistics\n",
    "        type_counts = defaultdict(int)\n",
    "        for item in self.data:\n",
    "            type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "        print(\"Dataset composition:\")\n",
    "        for qa_type, count in sorted(type_counts.items()):\n",
    "            print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item[\"question\"]\n",
    "        choices = item[\"choices\"]\n",
    "        label = item[\"label\"]\n",
    "        qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            [question] * 4,\n",
    "            choices,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(label),\n",
    "            \"qa_type\": qa_type\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "    \"\"\"Compute comprehensive metrics\"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    qa_types = np.array(qa_types)\n",
    "    \n",
    "    unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "    results = {\n",
    "        'per_type': {},\n",
    "        'macro_across_types': {},\n",
    "        'micro_overall': {},\n",
    "        'confusion_matrices': {}\n",
    "    }\n",
    "    \n",
    "    for qa_type in unique_types:\n",
    "        mask = qa_types == qa_type\n",
    "        type_preds = predictions[mask]\n",
    "        type_labels = labels[mask]\n",
    "        \n",
    "        if len(type_preds) == 0:\n",
    "            continue\n",
    "        \n",
    "        macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "        results['per_type'][qa_type] = {\n",
    "            'macro': {\n",
    "                'precision': macro_precision,\n",
    "                'recall': macro_recall,\n",
    "                'f1': macro_f1,\n",
    "            },\n",
    "            'micro': {\n",
    "                'precision': micro_precision,\n",
    "                'recall': micro_recall,\n",
    "                'f1': micro_f1,\n",
    "                'accuracy': accuracy,\n",
    "            },\n",
    "            'per_choice': {\n",
    "                f'choice_{i}': {\n",
    "                    'precision': per_class_precision[i],\n",
    "                    'recall': per_class_recall[i],\n",
    "                    'f1': per_class_f1[i],\n",
    "                    'support': per_class_support[i]\n",
    "                } for i in range(4)\n",
    "            },\n",
    "            'support': len(type_preds),\n",
    "            'correct': (type_preds == type_labels).sum()\n",
    "        }\n",
    "        \n",
    "        results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "            type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "    \n",
    "    macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "    macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "    macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "    macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "    results['macro_across_types'] = {\n",
    "        'precision': macro_across_types_precision,\n",
    "        'recall': macro_across_types_recall,\n",
    "        'f1': macro_across_types_f1,\n",
    "        'accuracy': macro_across_types_accuracy\n",
    "    }\n",
    "    \n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "    )\n",
    "    micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "    results['micro_overall'] = {\n",
    "        'accuracy': micro_accuracy,\n",
    "        'precision': micro_precision,\n",
    "        'recall': micro_recall,\n",
    "        'f1': micro_f1,\n",
    "        'support': len(predictions),\n",
    "        'correct': (predictions == labels).sum()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_zero_shot(model, dataloader, tokenizer, device):\n",
    "    \"\"\"Zero-shot evaluation\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_types = []\n",
    "    \n",
    "    print(\"\\nRunning zero-shot evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            correct_labels = batch[\"labels\"]\n",
    "            qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(correct_labels.cpu().tolist())\n",
    "            all_types.extend(qa_types)\n",
    "    \n",
    "    metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_results_table(metrics, model_name=None):\n",
    "    \"\"\"Print results table\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    if model_name:\n",
    "        print(f\"Model: {model_name} (Zero-Shot)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for qa_type in sorted(metrics['per_type'].keys()):\n",
    "        m_macro = metrics['per_type'][qa_type]['macro']\n",
    "        m_micro = metrics['per_type'][qa_type]['micro']\n",
    "        support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "        print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "              f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    m = metrics['macro_across_types']\n",
    "    print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "    m = metrics['micro_overall']\n",
    "    print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Load test dataset\n",
    "dev_dataset = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_dataset = MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Dev Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "dev_metrics = evaluate_zero_shot(model, dev_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(dev_metrics, model_name=model_name)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Test Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "# Save results\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "# Save both\n",
    "results_for_paper = {\n",
    "    'model': model_name,\n",
    "    'evaluation_type': 'zero-shot',\n",
    "    'config': eval_config,\n",
    "    'dev_metrics': convert_to_serializable(dev_metrics),\n",
    "    'test_metrics': convert_to_serializable(test_metrics),\n",
    "}\n",
    "\n",
    "output_file = f\"{model_name.replace('/', '-')}_zeroshot_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results_for_paper, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "# Summary based on test set\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ZERO-SHOT RESULTS SUMMARY (TEST SET):\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Evaluation Type: Zero-Shot (No Training)\")\n",
    "print(f\"Test Examples: {test_metrics['micro_overall']['support']}\")\n",
    "print(f\"Macro F1 (across types): {test_metrics['macro_across_types']['f1']:.4f}\")\n",
    "print(f\"Macro Accuracy (across types): {test_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "print(f\"Micro F1 (overall): {test_metrics['micro_overall']['f1']:.4f}\")\n",
    "print(f\"Micro Accuracy (overall): {test_metrics['micro_overall']['accuracy']:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8229833,
     "sourceId": 13735887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 403.185376,
   "end_time": "2025-11-18T04:00:04.736090",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-18T03:53:21.550714",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00cc0bbc5d0d46c5acfa18ba5b5c4d74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02b9c7b1aa984d0fb86f26028b6da1f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08cf55e25672429a9eaf294ab1d18bcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "08dd21485eeb4f4db4115723aae71739": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0a31b71215284a7c81d4e0c985f3f865": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b159a666f3e2415b8a31ae25c65990b6",
       "placeholder": "​",
       "style": "IPY_MODEL_6b0fd9675ef74ae6b5b50f1353963cf4",
       "tabbable": null,
       "tooltip": null,
       "value": " 1500/1500 [04:11&lt;00:00,  6.00it/s]"
      }
     },
     "0bd81cee1d694f8a9e62a8f801723849": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f422a17602e4bc9bd368af0fc93cada": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8181a338c57747dd80f0896dd16efda7",
       "placeholder": "​",
       "style": "IPY_MODEL_0bd81cee1d694f8a9e62a8f801723849",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "11f3bd13d87247d19c6c3bf482b2ec15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c713940b29c5459b998a1c8a17ccb3af",
       "placeholder": "​",
       "style": "IPY_MODEL_daf73841719145408e3b9e201c1246bb",
       "tabbable": null,
       "tooltip": null,
       "value": " 371M/371M [00:02&lt;00:00, 217MB/s]"
      }
     },
     "186a55ba15d64ff3bbf5976af310dc47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30c719fed6864701bdbf487f61776ebc",
        "IPY_MODEL_ef4aeb77bb014836805e9d8585299cfd",
        "IPY_MODEL_5c324c9335b84b24a16008d40e0f0022"
       ],
       "layout": "IPY_MODEL_ff312a97202845b2964c1d87bc477b82",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1d512049ce72417f897e9613d35bdd9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6279e98b5da48ffac950e86d05dcc80",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bb6acefdee014ce1887ff0d5e4bfec5c",
       "tabbable": null,
       "tooltip": null,
       "value": 52.0
      }
     },
     "1fae37641182466ca29d006568b0564e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f7039862ff4e432fbc2d9d1f09450bfc",
       "placeholder": "​",
       "style": "IPY_MODEL_f6c862b9c7ba4ed4ab34df430070b558",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "27028c72f5e7492a8fca5e9c73be2d5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6dcbe4a63eb146aa9476b143a3b05302",
       "max": 371146213.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_809104c9a2b04210a9861daef3081ec4",
       "tabbable": null,
       "tooltip": null,
       "value": 371146213.0
      }
     },
     "30c719fed6864701bdbf487f61776ebc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a0a25b32f5564c86b7decf11fca85807",
       "placeholder": "​",
       "style": "IPY_MODEL_7995bdf4ea5c44cfb8ec617e29ea6747",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "3320e5159d2247e6a2cf89161fac511f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3372215c33e04431b40f18bae93ec044": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33c48bdc0272455d9a5ab5252443c084": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3525cc70673d41a284cef9a0a3762669": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "356017f7047b42068d2fa07f078e3bb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_33c48bdc0272455d9a5ab5252443c084",
       "placeholder": "​",
       "style": "IPY_MODEL_c1f28a4d694d480588d1989811c61823",
       "tabbable": null,
       "tooltip": null,
       "value": " 371M/371M [00:01&lt;00:00, 397MB/s]"
      }
     },
     "39e647c5fcb3437abc34907007f3a1bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c066387173a4cbebe3dbf75e7ad1d12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4892ab14c580407eb5909b7998c238ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4cdd6682c69d4e6bb2f604ac9b54f837",
       "max": 1500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_08dd21485eeb4f4db4115723aae71739",
       "tabbable": null,
       "tooltip": null,
       "value": 1500.0
      }
     },
     "49945c4f5bcb4223bd03a3df4b964b42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4cdd6682c69d4e6bb2f604ac9b54f837": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50cdf951cade46f9bc5830f140472572": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "549bd6397fe64d34871db0dda88d8452": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5814839a54644c55b3b67cd4d429052e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7eaae077e7ab4acebbef35721ab9601b",
        "IPY_MODEL_4892ab14c580407eb5909b7998c238ed",
        "IPY_MODEL_0a31b71215284a7c81d4e0c985f3f865"
       ],
       "layout": "IPY_MODEL_c477f829912d432da5f50df6265757d9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5c324c9335b84b24a16008d40e0f0022": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02b9c7b1aa984d0fb86f26028b6da1f3",
       "placeholder": "​",
       "style": "IPY_MODEL_85baf8c394a647dc8ccd5c8fd650b0b4",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [01:23&lt;00:00,  5.99it/s]"
      }
     },
     "5da55b68a3844d8d987f859aa8364ea4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6ebfc34754542fcbe6b56c8a2e32ddf",
       "placeholder": "​",
       "style": "IPY_MODEL_93dbc29f9ac84e56be17dccb49c793cf",
       "tabbable": null,
       "tooltip": null,
       "value": " 579/579 [00:00&lt;00:00, 60.8kB/s]"
      }
     },
     "663543707c454b66b0ef06f2986aed3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68ff9789bf8b4ed481444a03c172a773": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a10638e06484545bde11eeb720e09d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6aaceaa404bd49db918e21433f8ffe0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6b0fd9675ef74ae6b5b50f1353963cf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6dcbe4a63eb146aa9476b143a3b05302": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7995bdf4ea5c44cfb8ec617e29ea6747": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7b9169e8f1804a76b353224a1d2e8d47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afd02f82544c4866817b1c5738845e90",
        "IPY_MODEL_af8bc362c87144b8b0a2d5d3aabf9285",
        "IPY_MODEL_356017f7047b42068d2fa07f078e3bb5"
       ],
       "layout": "IPY_MODEL_3372215c33e04431b40f18bae93ec044",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7eaae077e7ab4acebbef35721ab9601b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_663543707c454b66b0ef06f2986aed3e",
       "placeholder": "​",
       "style": "IPY_MODEL_6a10638e06484545bde11eeb720e09d3",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "809104c9a2b04210a9861daef3081ec4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8181a338c57747dd80f0896dd16efda7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85baf8c394a647dc8ccd5c8fd650b0b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8613460cdcf5440c846de363d6c94b60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a42a62021cd47b98e4c668ac8d1f8c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c9c7849245984d0b9cbad19f2d3353fc",
        "IPY_MODEL_27028c72f5e7492a8fca5e9c73be2d5e",
        "IPY_MODEL_11f3bd13d87247d19c6c3bf482b2ec15"
       ],
       "layout": "IPY_MODEL_8613460cdcf5440c846de363d6c94b60",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8e3dfd2e4a6542c9be1f30d199130aa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1fae37641182466ca29d006568b0564e",
        "IPY_MODEL_9b866ee944e2404ca1536cb6f0d30a73",
        "IPY_MODEL_5da55b68a3844d8d987f859aa8364ea4"
       ],
       "layout": "IPY_MODEL_3c066387173a4cbebe3dbf75e7ad1d12",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8e896a7d2afc44659cebae081ed583c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "908f28a98416497fae5fe18a849d89e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b47437edabe8483598909a221647ee2d",
       "placeholder": "​",
       "style": "IPY_MODEL_6aaceaa404bd49db918e21433f8ffe0a",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.46M/2.46M [00:00&lt;00:00, 6.04MB/s]"
      }
     },
     "934c2401dcce4b42a27ca2bbd94432f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93dbc29f9ac84e56be17dccb49c793cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "99da3636f76b4cddb5422c4b84df2e2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b866ee944e2404ca1536cb6f0d30a73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_00cc0bbc5d0d46c5acfa18ba5b5c4d74",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_49945c4f5bcb4223bd03a3df4b964b42",
       "tabbable": null,
       "tooltip": null,
       "value": 579.0
      }
     },
     "a0a25b32f5564c86b7decf11fca85807": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a30dde91571947698abdc049b259b490": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_549bd6397fe64d34871db0dda88d8452",
       "placeholder": "​",
       "style": "IPY_MODEL_c8f6cc4dba6b402cb76b06d281ad39e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 52.0/52.0 [00:00&lt;00:00, 6.14kB/s]"
      }
     },
     "a8043be9a8544405a8f7df2906fce5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "af8bc362c87144b8b0a2d5d3aabf9285": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef76c79023ec44938ebc8a0d603ebb2a",
       "max": 371101258.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50cdf951cade46f9bc5830f140472572",
       "tabbable": null,
       "tooltip": null,
       "value": 371101258.0
      }
     },
     "afd02f82544c4866817b1c5738845e90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3525cc70673d41a284cef9a0a3762669",
       "placeholder": "​",
       "style": "IPY_MODEL_de29f82acc6c4a88924b27f1768f84de",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b159a666f3e2415b8a31ae25c65990b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b47437edabe8483598909a221647ee2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6279e98b5da48ffac950e86d05dcc80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6ebfc34754542fcbe6b56c8a2e32ddf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb6acefdee014ce1887ff0d5e4bfec5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c13d60653cd9496c8136da8dbbe25650": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f422a17602e4bc9bd368af0fc93cada",
        "IPY_MODEL_1d512049ce72417f897e9613d35bdd9f",
        "IPY_MODEL_a30dde91571947698abdc049b259b490"
       ],
       "layout": "IPY_MODEL_99da3636f76b4cddb5422c4b84df2e2e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c1f28a4d694d480588d1989811c61823": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c477f829912d432da5f50df6265757d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c713940b29c5459b998a1c8a17ccb3af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8f6cc4dba6b402cb76b06d281ad39e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c915c3b6270147239bf3e4dde8dc1e46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9c7849245984d0b9cbad19f2d3353fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e029654c0da24233bc335e964d36ae4c",
       "placeholder": "​",
       "style": "IPY_MODEL_c915c3b6270147239bf3e4dde8dc1e46",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "d95c820fd9a5420ca6fa115ac876342f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9d2e46681094a1ca6b5f8faccbd5ad9",
        "IPY_MODEL_df9af5a69fe4403ca26137f931923cc5",
        "IPY_MODEL_908f28a98416497fae5fe18a849d89e5"
       ],
       "layout": "IPY_MODEL_8e896a7d2afc44659cebae081ed583c2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "daf73841719145408e3b9e201c1246bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de29f82acc6c4a88924b27f1768f84de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df9af5a69fe4403ca26137f931923cc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68ff9789bf8b4ed481444a03c172a773",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3320e5159d2247e6a2cf89161fac511f",
       "tabbable": null,
       "tooltip": null,
       "value": 2464616.0
      }
     },
     "e029654c0da24233bc335e964d36ae4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9d2e46681094a1ca6b5f8faccbd5ad9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_934c2401dcce4b42a27ca2bbd94432f8",
       "placeholder": "​",
       "style": "IPY_MODEL_08cf55e25672429a9eaf294ab1d18bcb",
       "tabbable": null,
       "tooltip": null,
       "value": "spm.model: 100%"
      }
     },
     "ef4aeb77bb014836805e9d8585299cfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39e647c5fcb3437abc34907007f3a1bb",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a8043be9a8544405a8f7df2906fce5f6",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "ef76c79023ec44938ebc8a0d603ebb2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6c862b9c7ba4ed4ab34df430070b558": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7039862ff4e432fbc2d9d1f09450bfc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff312a97202845b2964c1d87bc477b82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
