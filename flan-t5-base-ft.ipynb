{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bece29b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:39.805941Z",
     "iopub.status.busy": "2025-12-27T15:17:39.805212Z",
     "iopub.status.idle": "2025-12-27T15:17:41.326464Z",
     "shell.execute_reply": "2025-12-27T15:17:41.325462Z"
    },
    "papermill": {
     "duration": 1.528286,
     "end_time": "2025-12-27T15:17:41.327820",
     "exception": false,
     "start_time": "2025-12-27T15:17:39.799534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\n",
      "/kaggle/input/csqa-logicalcombinations/train_all_hf.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/__huggingface_repos__.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base_training_curves.png\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/config.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/spiece.model\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/results_detailed.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/tokenizer_config.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/model.safetensors\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/special_tokens_map.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/added_tokens.json\n",
      "/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1c4714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.337056Z",
     "iopub.status.busy": "2025-12-27T15:17:41.336374Z",
     "iopub.status.idle": "2025-12-27T15:17:41.340294Z",
     "shell.execute_reply": "2025-12-27T15:17:41.339604Z"
    },
    "papermill": {
     "duration": 0.009595,
     "end_time": "2025-12-27T15:17:41.341420",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.331825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/train_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# train_df = pd.DataFrame(data[\"questions\"])\n",
    "# train_df.to_csv('train_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/dev_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# dev_df = pd.DataFrame(data[\"questions\"])\n",
    "# dev_df.to_csv('dev_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# dev_df.head()\n",
    "\n",
    "\n",
    "# # Load JSON\n",
    "# with open(\"/kaggle/input/csqa-logicalcombinations/test_logical_combinations_output.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Convert the 'questions' list to a DataFrame\n",
    "# test_df = pd.DataFrame(data[\"questions\"])\n",
    "# test_df.to_csv('test_logical_combinations_output.csv',index=False)\n",
    "\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fc1991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.350480Z",
     "iopub.status.busy": "2025-12-27T15:17:41.350081Z",
     "iopub.status.idle": "2025-12-27T15:17:41.353135Z",
     "shell.execute_reply": "2025-12-27T15:17:41.352459Z"
    },
    "papermill": {
     "duration": 0.008542,
     "end_time": "2025-12-27T15:17:41.354217",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.345675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2d811d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.362318Z",
     "iopub.status.busy": "2025-12-27T15:17:41.362092Z",
     "iopub.status.idle": "2025-12-27T15:17:41.367771Z",
     "shell.execute_reply": "2025-12-27T15:17:41.367084Z"
    },
    "papermill": {
     "duration": 0.011167,
     "end_time": "2025-12-27T15:17:41.368857",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.357690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "# import ast\n",
    "\n",
    "# # Load your dataset\n",
    "# df = pd.read_csv(\"/kaggle/working/train_logical_combinations_output.csv\")  # replace with your file\n",
    "\n",
    "# # Safe eval to ensure lists are properly loaded\n",
    "# def safe_eval(val):\n",
    "#     if isinstance(val, list):\n",
    "#         return val\n",
    "#     if pd.isna(val):\n",
    "#         return []\n",
    "#     if isinstance(val, str):\n",
    "#         try:\n",
    "#             return ast.literal_eval(val)\n",
    "#         except:\n",
    "#             return []\n",
    "#     return []\n",
    "\n",
    "# df['logical_combinations'] = df['logical_combinations'].apply(safe_eval)\n",
    "\n",
    "# # Prepare storage for QA sets\n",
    "# qa_sets = {\n",
    "#     'AND': [],\n",
    "#     'OR': [],\n",
    "#     'NEITHER': [],\n",
    "#     'Mixed': []\n",
    "# }\n",
    "\n",
    "# # Label rotation - separate rotator for each question type\n",
    "# class LabelRotator:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.labels = ['A', 'B', 'C', 'D']\n",
    "#         self.current_index = 0\n",
    "    \n",
    "#     def get_next_label(self):\n",
    "#         label = self.labels[self.current_index]\n",
    "#         self.current_index = (self.current_index + 1) % len(self.labels)\n",
    "#         # print(f\"DEBUG {self.name}: Assigned label {label}, next will be {self.labels[self.current_index]}\")\n",
    "#         return label\n",
    "\n",
    "# # Create separate rotators for each question type\n",
    "# rotators = {\n",
    "#     'AND': LabelRotator('AND'),\n",
    "#     'OR': LabelRotator('OR'),\n",
    "#     'NEITHER': LabelRotator('NEITHER'),\n",
    "#     'Mixed': LabelRotator('Mixed')\n",
    "# }\n",
    "\n",
    "# def create_qa_item(question, correct_ans, incorrect_ans, qa_type):\n",
    "#     \"\"\"Helper function to create a QA item with proper label rotation\"\"\"\n",
    "    \n",
    "#     # Get correct label from the appropriate rotator\n",
    "#     correct_label = rotators[qa_type].get_next_label()\n",
    "    \n",
    "#     # Ensure we have exactly 3 incorrect answers\n",
    "#     if len(incorrect_ans) < 3:\n",
    "#         print(f\"Warning: Only {len(incorrect_ans)} incorrect answers available for {qa_type}\")\n",
    "#         return None\n",
    "    \n",
    "#     selected_incorrect = random.sample(incorrect_ans, 3)\n",
    "    \n",
    "#     # Create options array with 4 positions\n",
    "#     options = [''] * 4\n",
    "    \n",
    "#     # Place correct answer at the designated position\n",
    "#     correct_pos = rotators[qa_type].labels.index(correct_label)\n",
    "#     options[correct_pos] = correct_ans\n",
    "    \n",
    "#     # Fill remaining positions with incorrect answers\n",
    "#     incorrect_positions = [i for i in range(4) if i != correct_pos]\n",
    "#     for i, pos in enumerate(incorrect_positions):\n",
    "#         options[pos] = selected_incorrect[i]\n",
    "    \n",
    "#     return {\n",
    "#         'question': question,\n",
    "#         'A': options[0],\n",
    "#         'B': options[1],\n",
    "#         'C': options[2],\n",
    "#         'D': options[3],\n",
    "#         'correct_label': correct_label,\n",
    "#         'correct_answer_text': correct_ans,\n",
    "#         'qa_type': qa_type\n",
    "#     }\n",
    "\n",
    "# # Track counts for each type\n",
    "# type_counts = {'AND': 0, 'OR': 0, 'NEITHER': 0, 'Mixed': 0}\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     question = row['question']\n",
    "#     combos = row['logical_combinations']\n",
    "    \n",
    "#     # Extract AND/OR/NEITHER correct and incorrect lists\n",
    "#     and_correct = combos.get('AND_combinations', {}).get('correct', [])\n",
    "#     and_incorrect = combos.get('AND_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     or_correct = combos.get('OR_combinations', {}).get('correct', [])\n",
    "#     or_incorrect = combos.get('OR_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     neither_correct = combos.get('NEITHER_combinations', {}).get('correct', [])\n",
    "#     neither_incorrect = combos.get('NEITHER_combinations', {}).get('incorrect', [])\n",
    "    \n",
    "#     # --- AND-only QA ---\n",
    "#     if and_correct and len(and_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(and_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, and_incorrect, 'AND')\n",
    "#         if qa_item:\n",
    "#             qa_sets['AND'].append(qa_item)\n",
    "#             type_counts['AND'] += 1\n",
    "#             # print(f\"AND Question {type_counts['AND']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- OR-only QA ---\n",
    "#     if or_correct and len(or_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(or_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, or_incorrect, 'OR')\n",
    "#         if qa_item:\n",
    "#             qa_sets['OR'].append(qa_item)\n",
    "#             type_counts['OR'] += 1\n",
    "#             # print(f\"OR Question {type_counts['OR']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- NEITHER-only QA ---\n",
    "#     if neither_correct and len(neither_incorrect) >= 3:\n",
    "#         correct_ans = random.choice(neither_correct)\n",
    "#         qa_item = create_qa_item(question, correct_ans, neither_incorrect, 'NEITHER')\n",
    "#         if qa_item:\n",
    "#             qa_sets['NEITHER'].append(qa_item)\n",
    "#             type_counts['NEITHER'] += 1\n",
    "#             # print(f\"NEITHER Question {type_counts['NEITHER']}: Label {qa_item['correct_label']}\")\n",
    "    \n",
    "#     # --- Mixed QA ---\n",
    "#     all_correct_types = [\n",
    "#         ('AND', and_correct),\n",
    "#         ('OR', or_correct),\n",
    "#         ('NEITHER', neither_correct)\n",
    "#     ]\n",
    "#     all_incorrect_types = and_incorrect + or_incorrect + neither_incorrect\n",
    "    \n",
    "#     # Ensure at least one correct exists and enough incorrect answers\n",
    "#     valid_categories = [cat for cat, lst in all_correct_types if lst]\n",
    "#     if valid_categories and len(all_incorrect_types) >= 3:\n",
    "#         chosen_category = random.choice(valid_categories)\n",
    "#         chosen_correct_list = dict(all_correct_types)[chosen_category]\n",
    "#         correct_ans = random.choice(chosen_correct_list)\n",
    "#         qa_item = create_qa_item(question, correct_ans, all_incorrect_types, 'Mixed')\n",
    "#         if qa_item:\n",
    "#             qa_sets['Mixed'].append(qa_item)\n",
    "#             type_counts['Mixed'] += 1\n",
    "#             # print(f\"Mixed Question {type_counts['Mixed']}: Label {qa_item['correct_label']}\")\n",
    "\n",
    "# print(f\"\\n=== GENERATION COMPLETE ===\")\n",
    "# for qtype, count in type_counts.items():\n",
    "#     print(f\"{qtype}: {count} questions generated\")\n",
    "\n",
    "# # --- Convert to DataFrames and save ---\n",
    "# for key, qlist in qa_sets.items():\n",
    "#     if qlist:  # Only save if we have questions\n",
    "#         df_out = pd.DataFrame(qlist)\n",
    "#         df_out.to_csv(f'train_qa_{key}.csv', index=False)\n",
    "#         print(f\"\\n{key} QA saved: {len(df_out)} questions in train_qa_{key}.csv\")\n",
    "        \n",
    "#         # Show label distribution for verification\n",
    "#         label_counts = df_out['correct_label'].value_counts().sort_index()\n",
    "#         print(f\"  Label distribution: {dict(label_counts)}\")\n",
    "        \n",
    "#         # Show label sequence for first 8 questions to verify rotation\n",
    "#         print(f\"  Label sequence (first 8): {list(df_out['correct_label'].head(8))}\")\n",
    "#     else:\n",
    "#         print(f\"{key}: No valid QA pairs generated\")\n",
    "\n",
    "# # Overall statistics\n",
    "# total_questions = sum(len(qlist) for qlist in qa_sets.values())\n",
    "# print(f\"\\nFinal total questions generated: {total_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6809f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.376716Z",
     "iopub.status.busy": "2025-12-27T15:17:41.376273Z",
     "iopub.status.idle": "2025-12-27T15:17:41.379341Z",
     "shell.execute_reply": "2025-12-27T15:17:41.378677Z"
    },
    "papermill": {
     "duration": 0.008226,
     "end_time": "2025-12-27T15:17:41.380533",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.372307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and  = pd.read_csv('/kaggle/working/test_qa_AND.csv')\n",
    "\n",
    "# train_qa_and.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f707fe0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.388349Z",
     "iopub.status.busy": "2025-12-27T15:17:41.387992Z",
     "iopub.status.idle": "2025-12-27T15:17:41.390756Z",
     "shell.execute_reply": "2025-12-27T15:17:41.390227Z"
    },
    "papermill": {
     "duration": 0.007848,
     "end_time": "2025-12-27T15:17:41.391791",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.383943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_qa_and.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9a4ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.399583Z",
     "iopub.status.busy": "2025-12-27T15:17:41.399163Z",
     "iopub.status.idle": "2025-12-27T15:17:41.402243Z",
     "shell.execute_reply": "2025-12-27T15:17:41.401772Z"
    },
    "papermill": {
     "duration": 0.007989,
     "end_time": "2025-12-27T15:17:41.403222",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.395233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# and_df = pd.read_csv(\"train_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"train_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"train_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"train_qa_Mixed.csv\")\n",
    "\n",
    "# train_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# train_df.to_csv(\"train_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"dev_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"dev_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"dev_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"dev_qa_Mixed.csv\")\n",
    "\n",
    "# dev_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# dev_df.to_csv(\"dev_all.csv\", index=False)\n",
    "\n",
    "\n",
    "# and_df = pd.read_csv(\"test_qa_AND.csv\")\n",
    "# or_df = pd.read_csv(\"test_qa_OR.csv\")\n",
    "# neither_df = pd.read_csv(\"test_qa_NEITHER.csv\")\n",
    "# mixed_df = pd.read_csv(\"test_qa_Mixed.csv\")\n",
    "\n",
    "# test_df = pd.concat([and_df, or_df, neither_df, mixed_df], ignore_index=True)\n",
    "# test_df.to_csv(\"test_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0fa2e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.411376Z",
     "iopub.status.busy": "2025-12-27T15:17:41.410767Z",
     "iopub.status.idle": "2025-12-27T15:17:41.414349Z",
     "shell.execute_reply": "2025-12-27T15:17:41.413693Z"
    },
    "papermill": {
     "duration": 0.00863,
     "end_time": "2025-12-27T15:17:41.415394",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.406764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "# train_df[\"choices\"] = train_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# train_df[\"label\"] = train_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_train_df = train_df[[\"question\", \"choices\", \"label\", \"qa_type\"]]\n",
    "\n",
    "# hf_train_df.to_json(\"train_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# dev_df[\"choices\"] = dev_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# dev_df[\"label\"] = dev_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_dev_df = dev_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_dev_df.to_json(\"dev_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "# test_df[\"choices\"] = test_df.apply(lambda r: [r[\"A\"], r[\"B\"], r[\"C\"], r[\"D\"]], axis=1)\n",
    "# test_df[\"label\"] = test_df[\"correct_label\"].map(label_map)\n",
    "\n",
    "# # Keep only columns needed\n",
    "# hf_test_df = test_df[[\"question\", \"choices\", \"label\",\"qa_type\"]]\n",
    "\n",
    "# hf_test_df.to_json(\"test_all_hf.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7844e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.423259Z",
     "iopub.status.busy": "2025-12-27T15:17:41.422773Z",
     "iopub.status.idle": "2025-12-27T15:17:41.425721Z",
     "shell.execute_reply": "2025-12-27T15:17:41.425200Z"
    },
    "papermill": {
     "duration": 0.007893,
     "end_time": "2025-12-27T15:17:41.426772",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.418879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054bfe5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:41.434550Z",
     "iopub.status.busy": "2025-12-27T15:17:41.434122Z",
     "iopub.status.idle": "2025-12-27T15:17:53.171483Z",
     "shell.execute_reply": "2025-12-27T15:17:53.170599Z"
    },
    "papermill": {
     "duration": 11.742537,
     "end_time": "2025-12-27T15:17:53.172650",
     "exception": false,
     "start_time": "2025-12-27T15:17:41.430113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n",
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "✓ PyArrow 19.0.1\n",
      "✓ Datasets 4.4.1\n",
      "✓ Transformers 4.53.3\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Clean uninstall everything\n",
    "# !pip uninstall -y protobuf pyarrow google-protobuf datasets transformers accelerate bitsandbytes peft trl\n",
    "\n",
    "# # Step 2: Install in the correct order with compatible versions\n",
    "!pip install --upgrade --no-cache-dir protobuf==3.20.3\n",
    "# !pip install --no-cache-dir pyarrow==12.0.1\n",
    "# !pip install --no-cache-dir datasets==2.14.0\n",
    "# !pip install --no-cache-dir transformers==4.35.2\n",
    "# !pip install --no-cache-dir accelerate\n",
    "\n",
    "# Step 3: Verify installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "try:\n",
    "    import pyarrow as pa\n",
    "    print(f\"✓ PyArrow {pa.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PyArrow failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"✓ Datasets {datasets.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Datasets failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import __version__\n",
    "    print(f\"✓ Transformers {__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Transformers failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "504db21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:53.181939Z",
     "iopub.status.busy": "2025-12-27T15:17:53.181560Z",
     "iopub.status.idle": "2025-12-27T15:17:53.185161Z",
     "shell.execute_reply": "2025-12-27T15:17:53.184488Z"
    },
    "papermill": {
     "duration": 0.009559,
     "end_time": "2025-12-27T15:17:53.186333",
     "exception": false,
     "start_time": "2025-12-27T15:17:53.176774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Uninstall and reinstall datasets with matching pyarrow version\n",
    "# !pip uninstall -y datasets  pyarrow\n",
    "# !pip install --no-cache-dir pyarrow\n",
    "# !pip install --no-cache-dir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353b0aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:17:53.195228Z",
     "iopub.status.busy": "2025-12-27T15:17:53.194991Z",
     "iopub.status.idle": "2025-12-27T15:18:00.155486Z",
     "shell.execute_reply": "2025-12-27T15:18:00.154751Z"
    },
    "papermill": {
     "duration": 6.966633,
     "end_time": "2025-12-27T15:18:00.156863",
     "exception": false,
     "start_time": "2025-12-27T15:17:53.190230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\r\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyarrow, evaluate\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e7e0aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:18:00.168316Z",
     "iopub.status.busy": "2025-12-27T15:18:00.168059Z",
     "iopub.status.idle": "2025-12-27T15:18:00.173070Z",
     "shell.execute_reply": "2025-12-27T15:18:00.172367Z"
    },
    "papermill": {
     "duration": 0.011875,
     "end_time": "2025-12-27T15:18:00.174137",
     "exception": false,
     "start_time": "2025-12-27T15:18:00.162262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "# from transformers import TrainingArguments, Trainer, DataCollatorForMultipleChoice\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import json\n",
    "# import evaluate\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # Custom Dataset class to replace datasets.load_dataset\n",
    "# import json\n",
    "\n",
    "# class MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=256):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item[\"qa_type\"] \n",
    "        \n",
    "#         tokenized = self.tokenizer(\n",
    "#             [question] * 4,\n",
    "#             choices,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"],\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "#             \"labels\": torch.tensor(label),\n",
    "#             \"qa_type\": qa_type \n",
    "#         }\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = T5MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", tokenizer)\n",
    "# eval_dataset = T5MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", tokenizer)\n",
    "\n",
    "# data_collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "\n",
    "# # Rest of your code remains the same\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = p.predictions.argmax(-1)\n",
    "#     return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./deberta-v3-mcqa\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=1e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=4,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_steps=50,\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efcf45b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:18:00.185072Z",
     "iopub.status.busy": "2025-12-27T15:18:00.184866Z",
     "iopub.status.idle": "2025-12-27T15:18:00.196334Z",
     "shell.execute_reply": "2025-12-27T15:18:00.195649Z"
    },
    "papermill": {
     "duration": 0.018398,
     "end_time": "2025-12-27T15:18:00.197374",
     "exception": false,
     "start_time": "2025-12-27T15:18:00.178976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch\n",
    "# from torch.optim import AdamW\n",
    "# from tqdm.auto import tqdm\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ============================================================================\n",
    "# # CONFIGURATION\n",
    "# # ============================================================================\n",
    "# model_name = \"google/flan-t5-base\"\n",
    "\n",
    "# training_config = {\n",
    "#     'max_epochs': 10,\n",
    "#     'patience': 3,  # Early stopping patience\n",
    "#     'min_delta': 0.001,  # Minimum improvement to count\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 5e-5,\n",
    "#     'warmup_steps': 500,\n",
    "#     'gradient_accumulation_steps': 2,\n",
    "#     'weight_decay': 0.01,\n",
    "#     'max_length': 512\n",
    "# }\n",
    "\n",
    "# print(\"\\nTraining Configuration:\")\n",
    "# for key, value in training_config.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "# # ============================================================================\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# # Custom Dataset for T5\n",
    "# class T5MCQADataset(Dataset):\n",
    "#     def __init__(self, json_path, tokenizer, max_length=512):\n",
    "#         self.data = []\n",
    "#         with open(json_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 if line.strip():\n",
    "#                     self.data.append(json.loads(line.strip()))\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#         print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "#         type_counts = defaultdict(int)\n",
    "#         for item in self.data:\n",
    "#             type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "#         print(\"Dataset composition:\")\n",
    "#         for qa_type, count in sorted(type_counts.items()):\n",
    "#             print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.data[idx]\n",
    "#         question = item[\"question\"]\n",
    "#         choices = item[\"choices\"]\n",
    "#         label = item[\"label\"]\n",
    "#         qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "#         # Format as T5 input\n",
    "#         input_text = f\"question: {question} \"\n",
    "#         for i, choice in enumerate(choices):\n",
    "#             input_text += f\"choice {chr(65+i)}: {choice} \"\n",
    "        \n",
    "#         target_text = chr(65 + label)\n",
    "        \n",
    "#         input_encoding = self.tokenizer(\n",
    "#             input_text,\n",
    "#             max_length=self.max_length,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         target_encoding = self.tokenizer(\n",
    "#             target_text,\n",
    "#             max_length=2,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(),\n",
    "#             \"labels\": target_encoding[\"input_ids\"].squeeze(),\n",
    "#             \"qa_type\": qa_type,\n",
    "#             \"correct_label\": label\n",
    "#         }\n",
    "\n",
    "# def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "#     \"\"\"Compute comprehensive metrics\"\"\"\n",
    "#     predictions = np.array(predictions)\n",
    "#     labels = np.array(labels)\n",
    "#     qa_types = np.array(qa_types)\n",
    "    \n",
    "#     unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "#     results = {\n",
    "#         'per_type': {},\n",
    "#         'macro_across_types': {},\n",
    "#         'micro_overall': {},\n",
    "#         'confusion_matrices': {}\n",
    "#     }\n",
    "    \n",
    "#     for qa_type in unique_types:\n",
    "#         mask = qa_types == qa_type\n",
    "#         type_preds = predictions[mask]\n",
    "#         type_labels = labels[mask]\n",
    "        \n",
    "#         if len(type_preds) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "#             type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "        \n",
    "#         accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "#         results['per_type'][qa_type] = {\n",
    "#             'macro': {\n",
    "#                 'precision': macro_precision,\n",
    "#                 'recall': macro_recall,\n",
    "#                 'f1': macro_f1,\n",
    "#             },\n",
    "#             'micro': {\n",
    "#                 'precision': micro_precision,\n",
    "#                 'recall': micro_recall,\n",
    "#                 'f1': micro_f1,\n",
    "#                 'accuracy': accuracy,\n",
    "#             },\n",
    "#             'per_choice': {\n",
    "#                 f'choice_{i}': {\n",
    "#                     'precision': per_class_precision[i],\n",
    "#                     'recall': per_class_recall[i],\n",
    "#                     'f1': per_class_f1[i],\n",
    "#                     'support': per_class_support[i]\n",
    "#                 } for i in range(4)\n",
    "#             },\n",
    "#             'support': len(type_preds),\n",
    "#             'correct': (type_preds == type_labels).sum()\n",
    "#         }\n",
    "        \n",
    "#         results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "#             type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "#         )\n",
    "    \n",
    "#     macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "#     macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "#     macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "#     macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "#     results['macro_across_types'] = {\n",
    "#         'precision': macro_across_types_precision,\n",
    "#         'recall': macro_across_types_recall,\n",
    "#         'f1': macro_across_types_f1,\n",
    "#         'accuracy': macro_across_types_accuracy\n",
    "#     }\n",
    "    \n",
    "#     micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "#         labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "#     )\n",
    "#     micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "#     results['micro_overall'] = {\n",
    "#         'accuracy': micro_accuracy,\n",
    "#         'precision': micro_precision,\n",
    "#         'recall': micro_recall,\n",
    "#         'f1': micro_f1,\n",
    "#         'support': len(predictions),\n",
    "#         'correct': (predictions == labels).sum()\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def evaluate_comprehensive(model, dataloader, tokenizer, device):\n",
    "#     \"\"\"Comprehensive evaluation for T5\"\"\"\n",
    "#     model.eval()\n",
    "    \n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "#     all_types = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             correct_labels = batch[\"correct_label\"]\n",
    "#             qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "#             outputs = model.generate(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask,\n",
    "#                 max_new_tokens=1,\n",
    "#                 num_beams=1,\n",
    "#                 do_sample=False,\n",
    "#             )\n",
    "            \n",
    "#             for i, output in enumerate(outputs):\n",
    "#                 decoded = tokenizer.decode(output, skip_special_tokens=True).strip()\n",
    "                \n",
    "#                 if len(decoded) > 0 and decoded[0] in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "#                     pred_label = ord(decoded[0]) - ord(\"A\")\n",
    "#                 else:\n",
    "#                     pred_label = 0\n",
    "                \n",
    "#                 all_predictions.append(pred_label)\n",
    "#                 all_labels.append(correct_labels[i].item())\n",
    "#                 all_types.append(qa_types[i])\n",
    "    \n",
    "#     metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "#     return metrics\n",
    "\n",
    "# def print_results_table(metrics, epoch=None, model_name=None):\n",
    "#     \"\"\"Print results table\"\"\"\n",
    "    \n",
    "#     if epoch is not None:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         if model_name:\n",
    "#             print(f\"Model: {model_name} | Epoch {epoch}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "    \n",
    "#     print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for qa_type in sorted(metrics['per_type'].keys()):\n",
    "#         m_macro = metrics['per_type'][qa_type]['macro']\n",
    "#         m_micro = metrics['per_type'][qa_type]['micro']\n",
    "#         support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "#         print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "#               f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     m = metrics['macro_across_types']\n",
    "#     print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "#     m = metrics['micro_overall']\n",
    "#     print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "#           f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = T5MCQADataset(\"/kaggle/input/csqa-logicalcombinations/train_all_hf.json\", \n",
    "#                               tokenizer, max_length=training_config['max_length'])\n",
    "# eval_dataset = T5MCQADataset(\"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\", \n",
    "#                              tokenizer, max_length=training_config['max_length'])\n",
    "\n",
    "# # Setup data loaders\n",
    "# batch_size = training_config['batch_size']\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Setup model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"\\nDevice: {device}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Setup optimizer and scheduler\n",
    "# optimizer = AdamW(model.parameters(), \n",
    "#                  lr=training_config['learning_rate'], \n",
    "#                  weight_decay=training_config['weight_decay'])\n",
    "# num_training_steps = training_config['max_epochs'] * len(train_loader) // training_config['gradient_accumulation_steps']\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=training_config['warmup_steps'],\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "\n",
    "# # Training loop with early stopping\n",
    "# best_macro_f1 = 0\n",
    "# best_epoch = 0\n",
    "# epochs_without_improvement = 0\n",
    "# best_metrics = None\n",
    "# training_history = []\n",
    "\n",
    "# # print(f\"\\n{'='*100}\")\n",
    "# # print(f\"Training {model_name} with Early Stopping\")\n",
    "# # print(f\"Max Epochs: {training_config['max_epochs']}, Patience: {training_config['patience']}\")\n",
    "# # print(f\"{'='*100}\")\n",
    "\n",
    "# # for epoch in range(training_config['max_epochs']):\n",
    "# #     print(f\"\\n{'='*100}\")\n",
    "# #     print(f\"Epoch {epoch + 1}/{training_config['max_epochs']}\")\n",
    "# #     print(f\"{'='*100}\")\n",
    "    \n",
    "# #     # Training\n",
    "# #     model.train()\n",
    "# #     total_loss = 0\n",
    "# #     optimizer.zero_grad()\n",
    "    \n",
    "# #     progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "# #     for step, batch in enumerate(progress_bar):\n",
    "# #         input_ids = batch[\"input_ids\"].to(device)\n",
    "# #         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "# #         labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "# #         # Replace padding token id's in labels with -100\n",
    "# #         labels[labels == tokenizer.pad_token_id] = -100\n",
    "        \n",
    "# #         outputs = model(\n",
    "# #             input_ids=input_ids,\n",
    "# #             attention_mask=attention_mask,\n",
    "# #             labels=labels  # This is all you need for training\n",
    "# #         )\n",
    "# #         loss = outputs.loss / training_config['gradient_accumulation_steps']\n",
    "        \n",
    "# #         loss.backward()\n",
    "        \n",
    "# #         # Gradient accumulation\n",
    "# #         if (step + 1) % training_config['gradient_accumulation_steps'] == 0:\n",
    "# #             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "# #             optimizer.step()\n",
    "# #             lr_scheduler.step()\n",
    "# #             optimizer.zero_grad()\n",
    "        \n",
    "# #         total_loss += loss.item() * training_config['gradient_accumulation_steps']\n",
    "# #         progress_bar.set_postfix({\"loss\": f\"{total_loss / (step + 1):.4f}\"})\n",
    "    \n",
    "# #     avg_train_loss = total_loss / len(train_loader)\n",
    "# #     print(f\"\\nTrain Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "#     # Evaluation\n",
    "#     print(\"\\nEvaluating...\")\n",
    "#     metrics = evaluate_comprehensive(model, eval_loader, tokenizer, device)\n",
    "#     print_results_table(metrics, epoch=epoch + 1, model_name=model_name)\n",
    "    \n",
    "#     macro_f1 = metrics['macro_across_types']['f1']\n",
    "#     macro_acc = metrics['macro_across_types']['accuracy']\n",
    "    \n",
    "#     # Save history\n",
    "#     training_history.append({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'train_loss': avg_train_loss,\n",
    "#         'macro_f1': macro_f1,\n",
    "#         'macro_accuracy': macro_acc,\n",
    "#         'macro_precision': metrics['macro_across_types']['precision'],\n",
    "#         'macro_recall': metrics['macro_across_types']['recall']\n",
    "#     })\n",
    "    \n",
    "#     # Early stopping check\n",
    "#     improvement = macro_f1 - best_macro_f1\n",
    "    \n",
    "#     if improvement > training_config['min_delta']:\n",
    "#         best_macro_f1 = macro_f1\n",
    "#         best_epoch = epoch + 1\n",
    "#         best_metrics = metrics\n",
    "#         epochs_without_improvement = 0\n",
    "        \n",
    "#         save_dir = f\"./{model_name.replace('/', '-')}-best\"\n",
    "#         print(f\"\\nNew best Macro F1: {macro_f1:.4f} (improvement {improvement:.4f}). Saving to {save_dir}\")\n",
    "#         model.save_pretrained(save_dir)\n",
    "#         tokenizer.save_pretrained(save_dir)\n",
    "        \n",
    "#         def convert_to_serializable(obj):\n",
    "#             if isinstance(obj, dict):\n",
    "#                 return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "#             elif isinstance(obj, (np.integer, np.floating)):\n",
    "#                 return float(obj)\n",
    "#             elif isinstance(obj, np.ndarray):\n",
    "#                 return obj.tolist()\n",
    "#             return obj\n",
    "        \n",
    "#         results_for_paper = {\n",
    "#             'model': model_name,\n",
    "#             'best_epoch': best_epoch,\n",
    "#             'training_config': training_config,\n",
    "#             'training_history': training_history,\n",
    "#             'best_metrics': convert_to_serializable(best_metrics)\n",
    "#         }\n",
    "        \n",
    "#         with open(f\"{save_dir}/results_detailed.json\", \"w\") as f:\n",
    "#             json.dump(results_for_paper, f, indent=2)\n",
    "#     else:\n",
    "#         epochs_without_improvement += 1\n",
    "#         print(f\"\\nNo improvement for {epochs_without_improvement} epoch(s) \"\n",
    "#               f\"(current Macro F1: {macro_f1:.4f}, best: {best_macro_f1:.4f})\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if epochs_without_improvement >= training_config['patience']:\n",
    "#         print(f\"\\n{'='*100}\")\n",
    "#         print(\"Early stopping triggered.\")\n",
    "#         print(f\"Best Macro F1: {best_macro_f1:.4f} at epoch {best_epoch}\")\n",
    "#         print(f\"Training stopped at epoch {epoch + 1}\")\n",
    "#         print(f\"{'='*100}\")\n",
    "#         break\n",
    "\n",
    "# # # Final summary\n",
    "# # print(f\"\\n{'='*100}\")\n",
    "# # print(\"Training Complete.\")\n",
    "# # print(f\"{'='*100}\")\n",
    "# # print(f\"Model: {model_name}\")\n",
    "# # print(f\"Best Epoch: {best_epoch}/{epoch + 1}\")\n",
    "# # print(f\"Best Macro F1: {best_macro_f1:.4f}\")\n",
    "# # print(f\"{'='*100}\")\n",
    "\n",
    "# # if best_metrics:\n",
    "# #     print(\"\\nFinal Best Results:\")\n",
    "# #     print_results_table(best_metrics, model_name=model_name)\n",
    "\n",
    "# # # Plot training curves\n",
    "# # plt.figure(figsize=(15, 5))\n",
    "\n",
    "# # epochs_list = [h['epoch'] for h in training_history]\n",
    "\n",
    "# # plt.subplot(1, 3, 1)\n",
    "# # plt.plot(epochs_list, [h['train_loss'] for h in training_history], marker='o', label='Train Loss')\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Loss')\n",
    "# # plt.title('Training Loss')\n",
    "# # plt.grid(True)\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.subplot(1, 3, 2)\n",
    "# # plt.plot(epochs_list, [h['macro_f1'] for h in training_history], marker='o', color='green', label='Macro F1')\n",
    "# # plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Macro F1')\n",
    "# # plt.title('Validation Macro F1')\n",
    "# # plt.grid(True)\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.subplot(1, 3, 3)\n",
    "# # plt.plot(epochs_list, [h['macro_accuracy'] for h in training_history], marker='o', color='blue', label='Macro Accuracy')\n",
    "# # plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Accuracy')\n",
    "# # plt.title('Validation Macro Accuracy')\n",
    "# # plt.grid(True)\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig(f'{model_name.replace(\"/\", \"-\")}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "# # print(f\"\\nSaved training curves to {model_name.replace('/', '-')}_training_curves.png\")\n",
    "\n",
    "# # # Summary table for paper\n",
    "# # print(\"\\n\" + \"=\"*100)\n",
    "# # print(\"SUMMARY FOR PAPER:\")\n",
    "# # print(\"=\"*100)\n",
    "# # print(f\"Model: {model_name}\")\n",
    "# # print(f\"Best Epoch: {best_epoch}\")\n",
    "# # print(f\"Total Epochs Trained: {len(training_history)}\")\n",
    "# # print(f\"Converged: {'Yes (early stopping)' if epochs_without_improvement >= training_config['patience'] else 'No (completed all epochs)'}\")\n",
    "# # print(f\"Best Validation Macro F1: {best_macro_f1:.4f}\")\n",
    "# # print(f\"Best Validation Macro Accuracy: {best_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "# # print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dea9ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:18:00.207790Z",
     "iopub.status.busy": "2025-12-27T15:18:00.207585Z",
     "iopub.status.idle": "2025-12-27T15:18:00.210861Z",
     "shell.execute_reply": "2025-12-27T15:18:00.210175Z"
    },
    "papermill": {
     "duration": 0.009779,
     "end_time": "2025-12-27T15:18:00.211938",
     "exception": false,
     "start_time": "2025-12-27T15:18:00.202159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = list(range(1, len(train_losses_per_epoch) + 1))\n",
    "\n",
    "# plt.figure(figsize=(12,5))\n",
    "\n",
    "# # --- Loss curve ---\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(epochs, train_losses_per_epoch, marker='o')\n",
    "# plt.title(\"Training Loss per Epoch\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.grid(True)\n",
    "\n",
    "# # --- Macro-F1 curve ---\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(epochs, macro_f1_per_epoch, marker='o')\n",
    "# plt.title(\"Macro-F1 per Epoch (Dev Set)\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Macro F1\")\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0bddc73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:18:00.223158Z",
     "iopub.status.busy": "2025-12-27T15:18:00.222933Z",
     "iopub.status.idle": "2025-12-27T15:21:58.425481Z",
     "shell.execute_reply": "2025-12-27T15:21:58.424424Z"
    },
    "papermill": {
     "duration": 238.209825,
     "end_time": "2025-12-27T15:21:58.426709",
     "exception": false,
     "start_time": "2025-12-27T15:18:00.216884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 15:18:10.178659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766848690.370977      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766848690.422360      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Configuration:\n",
      "  batch_size: 8\n",
      "  max_length: 512\n",
      "Model: flan-t5-base\n",
      "\n",
      "Loading model: flan-t5-base...\n",
      "Loaded 6000 examples from /kaggle/input/csqa-logicalcombinations/dev_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 1500 (25.0%)\n",
      "  Mixed: 1500 (25.0%)\n",
      "  NEITHER: 1500 (25.0%)\n",
      "  OR: 1500 (25.0%)\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Dev Set Evaluation: flan-t5-base\n",
      "====================================================================================================\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca57b9db0b44aa6938f0fcc689580d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.9073     0.9077     0.9073     0.9074     1500\n",
      "Mixed            0.8727     0.8727     0.8727     0.8727     1500\n",
      "NEITHER          0.9100     0.9103     0.9100     0.9101     1500\n",
      "OR               0.9447     0.9450     0.9447     0.9446     1500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9087     0.9089     0.9087     0.9087        -\n",
      "Micro Avg        0.9087     0.9087     0.9087     0.9087     6000\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b0f2c3d1e94b8ba8dad0f6d8cf2891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.9280     0.9281     0.9281     0.9280      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9280     0.9281     0.9281     0.9280        -\n",
      "Micro Avg        0.9280     0.9280     0.9280     0.9280      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  AND: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32efed53bf8d496097e5a742ec1ccdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "AND              0.9480     0.9488     0.9480     0.9480      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9480     0.9488     0.9480     0.9480        -\n",
      "Micro Avg        0.9480     0.9480     0.9480     0.9480      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  OR: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42874e7e483c448089ee83b86b2dd4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "OR               0.9240     0.9241     0.9240     0.9240      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9240     0.9241     0.9240     0.9240        -\n",
      "Micro Avg        0.9240     0.9240     0.9240     0.9240      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  OR: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3356e636ce14c80b05a4f6450867363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "OR               0.9760     0.9767     0.9761     0.9761      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9760     0.9767     0.9761     0.9761        -\n",
      "Micro Avg        0.9760     0.9760     0.9760     0.9760      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  NEITHER: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4a0553f2645adadd771a05ee62f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEITHER          0.8920     0.8934     0.8922     0.8926      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8920     0.8934     0.8922     0.8926        -\n",
      "Micro Avg        0.8920     0.8920     0.8920     0.8920      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  NEITHER: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036b994db6724f3ea5182a4fe8cfe59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEITHER          0.9320     0.9347     0.9317     0.9319      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.9320     0.9347     0.9317     0.9319        -\n",
      "Micro Avg        0.9320     0.9320     0.9320     0.9320      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  Mixed: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd80af7cb6b418dac5097d2b31670fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mixed            0.8960     0.8967     0.8961     0.8960      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8960     0.8967     0.8961     0.8960        -\n",
      "Micro Avg        0.8960     0.8960     0.8960     0.8960      250\n",
      "====================================================================================================\n",
      "Loaded 250 examples from /kaggle/input/csqa-logicalcombinations/test_all_hf.json\n",
      "Dataset composition:\n",
      "  Mixed: 250 (100.0%)\n",
      "\n",
      "Running zero-shot evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bdd29fd3494d73860e8437b936d8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: flan-t5-base (Zero-Shot)\n",
      "====================================================================================================\n",
      "\n",
      "Type         Accuracy     Macro-P      Macro-R      Macro-F1     Support   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mixed            0.8720     0.8726     0.8720     0.8721      250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Macro Avg        0.8720     0.8726     0.8720     0.8721        -\n",
      "Micro Avg        0.8720     0.8720     0.8720     0.8720      250\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Zero-Shot Test Set Evaluation: flan-t5-base\n",
      "====================================================================================================\n",
      "\n",
      "Results saved to flan-t5-base_zeroshot_results.json\n",
      "\n",
      "====================================================================================================\n",
      "ZERO-SHOT RESULTS SUMMARY (TEST SET):\n",
      "====================================================================================================\n",
      "Model: flan-t5-base\n",
      "Evaluation Type: Zero-Shot (No Training)\n",
      "Test Examples: 250\n",
      "Macro F1 (across types): 0.8721\n",
      "Macro Accuracy (across types): 0.8720\n",
      "Micro F1 (overall): 0.8720\n",
      "Micro Accuracy (overall): 0.8720\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "model_path = '/kaggle/input/flant5-csqalogic/pytorch/default/1/google-flan-t5-base-best'\n",
    "model_name = \"flan-t5-base\"\n",
    "\n",
    "eval_config = {\n",
    "    'batch_size': 8,  # Can use larger batch for inference\n",
    "    'max_length': 512\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluation Configuration:\")\n",
    "for key, value in eval_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nLoading model: {model_name}...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Custom Dataset for T5\n",
    "class T5MCQADataset(Dataset):\n",
    "    def __init__(self, json_path, tokenizer, max_length=512, start_idx=None, end_idx=None):\n",
    "        self.data = []\n",
    "        with open(json_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    self.data.append(json.loads(line.strip()))\n",
    "\n",
    "        # Apply partitioning\n",
    "        if start_idx is not None or end_idx is not None:\n",
    "            self.data = self.data[start_idx:end_idx]\n",
    "            \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        print(f\"Loaded {len(self.data)} examples from {json_path}\")\n",
    "        \n",
    "        type_counts = defaultdict(int)\n",
    "        for item in self.data:\n",
    "            type_counts[item.get(\"qa_type\", \"unknown\")] += 1\n",
    "        print(\"Dataset composition:\")\n",
    "        for qa_type, count in sorted(type_counts.items()):\n",
    "            print(f\"  {qa_type}: {count} ({count/len(self.data)*100:.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item[\"question\"]\n",
    "        choices = item[\"choices\"]\n",
    "        label = item[\"label\"]\n",
    "        qa_type = item.get(\"qa_type\", \"unknown\")\n",
    "        \n",
    "        # Format as T5 input\n",
    "        input_text = f\"question: {question} \"\n",
    "        for i, choice in enumerate(choices):\n",
    "            input_text += f\"choice {chr(65+i)}: {choice} \"\n",
    "        \n",
    "        target_text = chr(65 + label)\n",
    "        \n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=2,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": target_encoding[\"input_ids\"].squeeze(),\n",
    "            \"qa_type\": qa_type,\n",
    "            \"correct_label\": label\n",
    "        }\n",
    "\n",
    "def compute_metrics_by_type(predictions, labels, qa_types):\n",
    "    \"\"\"Compute comprehensive metrics\"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    qa_types = np.array(qa_types)\n",
    "    \n",
    "    unique_types = sorted([t for t in set(qa_types) if t != 'overall'])\n",
    "    \n",
    "    results = {\n",
    "        'per_type': {},\n",
    "        'macro_across_types': {},\n",
    "        'micro_overall': {},\n",
    "        'confusion_matrices': {}\n",
    "    }\n",
    "    \n",
    "    for qa_type in unique_types:\n",
    "        mask = qa_types == qa_type\n",
    "        type_preds = predictions[mask]\n",
    "        type_labels = labels[mask]\n",
    "        \n",
    "        if len(type_preds) == 0:\n",
    "            continue\n",
    "        \n",
    "        macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='macro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
    "            type_labels, type_preds, average=None, zero_division=0, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "        \n",
    "        accuracy = (type_preds == type_labels).mean()\n",
    "        \n",
    "        results['per_type'][qa_type] = {\n",
    "            'macro': {\n",
    "                'precision': macro_precision,\n",
    "                'recall': macro_recall,\n",
    "                'f1': macro_f1,\n",
    "            },\n",
    "            'micro': {\n",
    "                'precision': micro_precision,\n",
    "                'recall': micro_recall,\n",
    "                'f1': micro_f1,\n",
    "                'accuracy': accuracy,\n",
    "            },\n",
    "            'per_choice': {\n",
    "                f'choice_{i}': {\n",
    "                    'precision': per_class_precision[i],\n",
    "                    'recall': per_class_recall[i],\n",
    "                    'f1': per_class_f1[i],\n",
    "                    'support': per_class_support[i]\n",
    "                } for i in range(4)\n",
    "            },\n",
    "            'support': len(type_preds),\n",
    "            'correct': (type_preds == type_labels).sum()\n",
    "        }\n",
    "        \n",
    "        results['confusion_matrices'][qa_type] = confusion_matrix(\n",
    "            type_labels, type_preds, labels=[0, 1, 2, 3]\n",
    "        )\n",
    "    \n",
    "    macro_across_types_precision = np.mean([results['per_type'][t]['macro']['precision'] for t in unique_types])\n",
    "    macro_across_types_recall = np.mean([results['per_type'][t]['macro']['recall'] for t in unique_types])\n",
    "    macro_across_types_f1 = np.mean([results['per_type'][t]['macro']['f1'] for t in unique_types])\n",
    "    macro_across_types_accuracy = np.mean([results['per_type'][t]['micro']['accuracy'] for t in unique_types])\n",
    "    \n",
    "    results['macro_across_types'] = {\n",
    "        'precision': macro_across_types_precision,\n",
    "        'recall': macro_across_types_recall,\n",
    "        'f1': macro_across_types_f1,\n",
    "        'accuracy': macro_across_types_accuracy\n",
    "    }\n",
    "    \n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='micro', zero_division=0, labels=[0, 1, 2, 3]\n",
    "    )\n",
    "    micro_accuracy = (predictions == labels).mean()\n",
    "    \n",
    "    results['micro_overall'] = {\n",
    "        'accuracy': micro_accuracy,\n",
    "        'precision': micro_precision,\n",
    "        'recall': micro_recall,\n",
    "        'f1': micro_f1,\n",
    "        'support': len(predictions),\n",
    "        'correct': (predictions == labels).sum()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_zero_shot(model, dataloader, tokenizer, device):\n",
    "    \"\"\"Zero-shot evaluation for T5 (no training)\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_types = []\n",
    "    \n",
    "    print(\"\\nRunning zero-shot evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            correct_labels = batch[\"correct_label\"]\n",
    "            qa_types = batch[\"qa_type\"]\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=1,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "            )\n",
    "            \n",
    "            for i, output in enumerate(outputs):\n",
    "                decoded = tokenizer.decode(output, skip_special_tokens=True).strip()\n",
    "                \n",
    "                decoded_clean = decoded.strip()\n",
    "                if decoded_clean and decoded_clean[0] in [\"A\",\"B\",\"C\",\"D\"]:\n",
    "                    pred_label = ord(decoded_clean[0]) - ord(\"A\")\n",
    "                else:\n",
    "                    pred_label = 0\n",
    "\n",
    "                \n",
    "                all_predictions.append(pred_label)\n",
    "                all_labels.append(correct_labels[i].item())\n",
    "                all_types.append(qa_types[i])\n",
    "    \n",
    "    metrics = compute_metrics_by_type(all_predictions, all_labels, all_types)\n",
    "    return metrics\n",
    "\n",
    "def print_results_table(metrics, model_name=None):\n",
    "    \"\"\"Print results table\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    if model_name:\n",
    "        print(f\"Model: {model_name} (Zero-Shot)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\n{'Type':<12} {'Accuracy':<12} {'Macro-P':<12} {'Macro-R':<12} {'Macro-F1':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for qa_type in sorted(metrics['per_type'].keys()):\n",
    "        m_macro = metrics['per_type'][qa_type]['macro']\n",
    "        m_micro = metrics['per_type'][qa_type]['micro']\n",
    "        support = metrics['per_type'][qa_type]['support']\n",
    "        \n",
    "        print(f\"{qa_type:<12} {m_micro['accuracy']:>10.4f} {m_macro['precision']:>10.4f} \"\n",
    "              f\"{m_macro['recall']:>10.4f} {m_macro['f1']:>10.4f} {support:>8}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    m = metrics['macro_across_types']\n",
    "    print(f\"{'Macro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {'-':>8}\")\n",
    "    \n",
    "    m = metrics['micro_overall']\n",
    "    print(f\"{'Micro Avg':<12} {m['accuracy']:>10.4f} {m['precision']:>10.4f} \"\n",
    "          f\"{m['recall']:>10.4f} {m['f1']:>10.4f} {m['support']:>8}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Load test dataset\n",
    "dev_dataset = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/dev_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length']\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=eval_config['batch_size'])\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Dev Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "dev_metrics = evaluate_zero_shot(model, dev_loader, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(dev_metrics, model_name=model_name)\n",
    "\n",
    "\n",
    "#AND\n",
    "test_dataset_first = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=0,\n",
    "    end_idx=250\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=250,\n",
    "    end_idx=500\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#OR\n",
    "test_dataset_first = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=500,\n",
    "    end_idx=750\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=750,\n",
    "    end_idx=1000\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#NNOR\n",
    "test_dataset_first = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1000,\n",
    "    end_idx=1250\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1250,\n",
    "    end_idx=1500\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "#Mixed\n",
    "test_dataset_first = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1500,\n",
    "    end_idx=1750\n",
    ")\n",
    "\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_first = DataLoader(test_dataset_first, batch_size=eval_config['batch_size'])\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_first, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "test_dataset_second = T5MCQADataset(\n",
    "    \"/kaggle/input/csqa-logicalcombinations/test_all_hf.json\",  # or test file\n",
    "    tokenizer, \n",
    "    max_length=eval_config['max_length'],\n",
    "    start_idx=1750,\n",
    "    end_idx=2000\n",
    ")\n",
    "\n",
    "# Setup data loader\n",
    "test_loader_second = DataLoader(test_dataset_second, batch_size=eval_config['batch_size'])\n",
    "\n",
    "\n",
    "test_metrics = evaluate_zero_shot(model, test_loader_second, tokenizer, device)\n",
    "\n",
    "# Print results\n",
    "print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "\n",
    "# Run zero-shot evaluation\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Zero-Shot Test Set Evaluation: {model_name}\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# test_metrics = evaluate_zero_shot(model, test_loader, tokenizer, device)\n",
    "\n",
    "# # Print results\n",
    "# print_results_table(test_metrics, model_name=model_name)\n",
    "\n",
    "# Save results\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "# Save both\n",
    "results_for_paper = {\n",
    "    'model': model_name,\n",
    "    'evaluation_type': 'zero-shot',\n",
    "    'config': eval_config,\n",
    "    'dev_metrics': convert_to_serializable(dev_metrics),\n",
    "    'test_metrics': convert_to_serializable(test_metrics),\n",
    "}\n",
    "\n",
    "output_file = f\"{model_name.replace('/', '-')}_zeroshot_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results_for_paper, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "# Summary based on test set\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ZERO-SHOT RESULTS SUMMARY (TEST SET):\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Evaluation Type: Zero-Shot (No Training)\")\n",
    "print(f\"Test Examples: {test_metrics['micro_overall']['support']}\")\n",
    "print(f\"Macro F1 (across types): {test_metrics['macro_across_types']['f1']:.4f}\")\n",
    "print(f\"Macro Accuracy (across types): {test_metrics['macro_across_types']['accuracy']:.4f}\")\n",
    "print(f\"Micro F1 (overall): {test_metrics['micro_overall']['f1']:.4f}\")\n",
    "print(f\"Micro Accuracy (overall): {test_metrics['micro_overall']['accuracy']:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268f8fa",
   "metadata": {
    "papermill": {
     "duration": 0.006446,
     "end_time": "2025-12-27T15:21:58.440612",
     "exception": false,
     "start_time": "2025-12-27T15:21:58.434166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8229833,
     "sourceId": 13735887,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 543694,
     "modelInstanceId": 529701,
     "sourceId": 698311,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.102307,
   "end_time": "2025-12-27T15:22:02.158313",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-27T15:17:36.056006",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "036b994db6724f3ea5182a4fe8cfe59c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6049b6a0de2a4146b42d513e74a726f9",
        "IPY_MODEL_7373d89982da45d392780a445a903476",
        "IPY_MODEL_31962e489a5f40beb9e22c602df0e98e"
       ],
       "layout": "IPY_MODEL_3fe86cf5388f4292be4d3daefaa97f0c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0ad4a0553f2645adadd771a05ee62f3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2c767c7d14b44b09b68f07b707835ed",
        "IPY_MODEL_d78c2108cf4d426794dad7375b1d88fc",
        "IPY_MODEL_ee461d07ac4148d5a9fad6b936c755b4"
       ],
       "layout": "IPY_MODEL_db902f5df83a4f369098eae21c33b75d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0f35ca761eb44933b14011d00926cae4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b800838e68742dbac4f8e56afacf75c",
       "placeholder": "​",
       "style": "IPY_MODEL_71ac947f74424669b6f487ee1a85c314",
       "tabbable": null,
       "tooltip": null,
       "value": " 750/750 [02:31&lt;00:00,  4.98it/s]"
      }
     },
     "0f83a52f0cf84be791113c3f7def25be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e165b5e6c1294611a8e1a9469d99ff67",
       "placeholder": "​",
       "style": "IPY_MODEL_ed5012fa51d64c138dd4b76405ce5267",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.96it/s]"
      }
     },
     "18c7ad69e7ae46ef982adc6855d4470f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21e3b5f0c09345f6969862ee052c1ba9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "242fe9a8eb4943eca7d354b53852c083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "275f47c6cf5c47b09a8d1efc0aeab2c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18c7ad69e7ae46ef982adc6855d4470f",
       "placeholder": "​",
       "style": "IPY_MODEL_675bf8881dcd4858bc5572944bceaf6d",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "28283f7ced9e4b03ae32e3486487de8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ae70db7c9f24bf1a5790e67a5f6505c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31962e489a5f40beb9e22c602df0e98e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_656b2bdbb20e4f1ca14f2a9881d9a3e7",
       "placeholder": "​",
       "style": "IPY_MODEL_bc842f0107c14b5dabd398c919cd7355",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.97it/s]"
      }
     },
     "321bfc71e65c4643959ab33da07514fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32efed53bf8d496097e5a742ec1ccdac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_275f47c6cf5c47b09a8d1efc0aeab2c2",
        "IPY_MODEL_fa8cd96e3eb04d9a879f35676d832abd",
        "IPY_MODEL_8f4e3b8e8f8645e09c515269df600c18"
       ],
       "layout": "IPY_MODEL_70383c4cdd5a4b4e921292a3886f09d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3782c02ee6524485824cc6a7555c9f14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ec0debbf64624821ad5cc6254c4b19e3",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcf6141f9b244eeaa71e4b2c2c5b749c",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "388264b4c21044e1bdcf22c3355f9762": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "394c6b2a11c842d1bea5f94265522627": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fe86cf5388f4292be4d3daefaa97f0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42874e7e483c448089ee83b86b2dd4ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5340b4943a1449d4ba012fa7d4541483",
        "IPY_MODEL_cfe216a3647e4ae68cea97cb4be361b2",
        "IPY_MODEL_bef1fafbbcea484c97380bbf3703ec7d"
       ],
       "layout": "IPY_MODEL_918757c8606a4aebaa6a9ae1a6ac3160",
       "tabbable": null,
       "tooltip": null
      }
     },
     "43d99c45bd48416cbbbf0552fffcdb13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47f74291c51846a7808c1fd5973a4fe7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "50dfc5b9119d461294fdfd882e50ac65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5340b4943a1449d4ba012fa7d4541483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28283f7ced9e4b03ae32e3486487de8b",
       "placeholder": "​",
       "style": "IPY_MODEL_5862184b2b4243ed9e2318d781056cc1",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "56c2e8a5e6ee483bbf5a54a7368c9c9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5862184b2b4243ed9e2318d781056cc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "592f8bc4ae4e46d08953fe28d6a4cbe1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b747ee2cfb9497a8a4045104ef38a12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e5b8c5198fd4605bc7c66a789467729": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5eb906641c9f4f418f63a685abf53003": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6049b6a0de2a4146b42d513e74a726f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_394c6b2a11c842d1bea5f94265522627",
       "placeholder": "​",
       "style": "IPY_MODEL_eff8a236384647e4b5b748a5ce3de81d",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "622de50078f441f79044963d24bb37ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_592f8bc4ae4e46d08953fe28d6a4cbe1",
       "placeholder": "​",
       "style": "IPY_MODEL_242fe9a8eb4943eca7d354b53852c083",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.97it/s]"
      }
     },
     "654ae6e67d034d749c421a4bd774814b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "656b2bdbb20e4f1ca14f2a9881d9a3e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "675bf8881dcd4858bc5572944bceaf6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6985997fab8a4c7f9ea2bcc110481aa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a3b1ea3fbba44829bf62530788be40b4",
       "placeholder": "​",
       "style": "IPY_MODEL_96e687c81ab94e11b50f160b33cd9ea6",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.97it/s]"
      }
     },
     "6b0a95fa2ee24fc1ab888109e2af83b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_72260f7ad5154c5c98e8bbd8a7ce6bc8",
       "placeholder": "​",
       "style": "IPY_MODEL_fca40a7db5fa4738a0e709c6b1fa6edb",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "70383c4cdd5a4b4e921292a3886f09d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "716a618ffdb5485dbde2f232b96e0a17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f92f7b6e61384683bb999d45136b8efa",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9ab82489397c4996bf9bc09ec1896f42",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "71ac947f74424669b6f487ee1a85c314": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "72260f7ad5154c5c98e8bbd8a7ce6bc8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7373d89982da45d392780a445a903476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5eb906641c9f4f418f63a685abf53003",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ff622e4ca6ff466b9d91d2e31f48c7c1",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "756be5f91b22404695d1a48e00e53f39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76f3bd7acab74e75b34fb09fdf9acf71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88fdfa4bfcc544cf8f0bcd9f5b9fab61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f46c9096e436468d87772425e96781f8",
       "placeholder": "​",
       "style": "IPY_MODEL_47f74291c51846a7808c1fd5973a4fe7",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "8983d4067855417aa2d4cd5d172cbbef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b8213c23a9b4eacb58958dfec763da5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8dac43fcf39a4af58ebdcee0c33cc986": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f4e3b8e8f8645e09c515269df600c18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21e3b5f0c09345f6969862ee052c1ba9",
       "placeholder": "​",
       "style": "IPY_MODEL_b391089beb594fef97cc771c019af376",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.98it/s]"
      }
     },
     "918757c8606a4aebaa6a9ae1a6ac3160": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9536c09006524fc28f258cab7c152c6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96e687c81ab94e11b50f160b33cd9ea6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "989ec48ce58644f6870ee0bae28cde44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ab82489397c4996bf9bc09ec1896f42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9b800838e68742dbac4f8e56afacf75c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0eacf9c12e14ce3b3a3d332fc6df7ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a11fe9a45d81459aad2aa051f04eb03d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a1faca3da12c4a27846d3adfc0984e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a3b1ea3fbba44829bf62530788be40b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac96bd0fa11c445a9b355f6ce7d608b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad75a0f894fe4e37b9a796c7e28a760e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b21c0d7a07514ba8b0d3fa897c12ad75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3356e636ce14c80b05a4f6450867363": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88fdfa4bfcc544cf8f0bcd9f5b9fab61",
        "IPY_MODEL_d01efb91323542b59e673a3c8d03d3da",
        "IPY_MODEL_6985997fab8a4c7f9ea2bcc110481aa7"
       ],
       "layout": "IPY_MODEL_8b8213c23a9b4eacb58958dfec763da5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b391089beb594fef97cc771c019af376": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b4b2685a7a0841a68a86b34b0d8d21f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5479dd74b8e482bba05559fcf4f77e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb23122f309946a2a0f85471a38d586a",
       "max": 750.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ea77b883a14f443894d9b7f5781c6a42",
       "tabbable": null,
       "tooltip": null,
       "value": 750.0
      }
     },
     "b6b0f2c3d1e94b8ba8dad0f6d8cf2891": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ff4c6b5f0bdd409f8bfc375e692fad38",
        "IPY_MODEL_3782c02ee6524485824cc6a7555c9f14",
        "IPY_MODEL_0f83a52f0cf84be791113c3f7def25be"
       ],
       "layout": "IPY_MODEL_76f3bd7acab74e75b34fb09fdf9acf71",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bc842f0107c14b5dabd398c919cd7355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd0f708e38c64c3084093f729665fba0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ad75a0f894fe4e37b9a796c7e28a760e",
       "placeholder": "​",
       "style": "IPY_MODEL_50dfc5b9119d461294fdfd882e50ac65",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "bd39ec1909bb47b68c585ccc489ec2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8983d4067855417aa2d4cd5d172cbbef",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_654ae6e67d034d749c421a4bd774814b",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "bef1fafbbcea484c97380bbf3703ec7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e234925788fd47b2ac07fe4e54bdb709",
       "placeholder": "​",
       "style": "IPY_MODEL_756be5f91b22404695d1a48e00e53f39",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.97it/s]"
      }
     },
     "bffcc5b5e5314260b16c65f241d14055": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb23122f309946a2a0f85471a38d586a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfe216a3647e4ae68cea97cb4be361b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac96bd0fa11c445a9b355f6ce7d608b5",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_989ec48ce58644f6870ee0bae28cde44",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "d01efb91323542b59e673a3c8d03d3da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ed718ce8894743f1b679d29121eedb13",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a11fe9a45d81459aad2aa051f04eb03d",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "d78c2108cf4d426794dad7375b1d88fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_321bfc71e65c4643959ab33da07514fa",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_43d99c45bd48416cbbbf0552fffcdb13",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "da3df685cfa64abb8715a35a022fbdc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b21c0d7a07514ba8b0d3fa897c12ad75",
       "placeholder": "​",
       "style": "IPY_MODEL_f4a4179c277846b3af32abee8861a5ac",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.96it/s]"
      }
     },
     "db902f5df83a4f369098eae21c33b75d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcf6141f9b244eeaa71e4b2c2c5b749c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ddd80af7cb6b418dac5097d2b31670fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e321b374eeec4dd4809eb983b0b73821",
        "IPY_MODEL_bd39ec1909bb47b68c585ccc489ec2e5",
        "IPY_MODEL_da3df685cfa64abb8715a35a022fbdc8"
       ],
       "layout": "IPY_MODEL_9536c09006524fc28f258cab7c152c6c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e165b5e6c1294611a8e1a9469d99ff67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e234925788fd47b2ac07fe4e54bdb709": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2c767c7d14b44b09b68f07b707835ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ae70db7c9f24bf1a5790e67a5f6505c",
       "placeholder": "​",
       "style": "IPY_MODEL_5e5b8c5198fd4605bc7c66a789467729",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "e321b374eeec4dd4809eb983b0b73821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b747ee2cfb9497a8a4045104ef38a12",
       "placeholder": "​",
       "style": "IPY_MODEL_bffcc5b5e5314260b16c65f241d14055",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "e9bdd29fd3494d73860e8437b936d8bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd0f708e38c64c3084093f729665fba0",
        "IPY_MODEL_716a618ffdb5485dbde2f232b96e0a17",
        "IPY_MODEL_622de50078f441f79044963d24bb37ab"
       ],
       "layout": "IPY_MODEL_8dac43fcf39a4af58ebdcee0c33cc986",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ea77b883a14f443894d9b7f5781c6a42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ec0debbf64624821ad5cc6254c4b19e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed5012fa51d64c138dd4b76405ce5267": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ed718ce8894743f1b679d29121eedb13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee461d07ac4148d5a9fad6b936c755b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4b2685a7a0841a68a86b34b0d8d21f7",
       "placeholder": "​",
       "style": "IPY_MODEL_a1faca3da12c4a27846d3adfc0984e6f",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:06&lt;00:00,  4.97it/s]"
      }
     },
     "eff8a236384647e4b5b748a5ce3de81d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f46c9096e436468d87772425e96781f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4a4179c277846b3af32abee8861a5ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f86facb586444cf3817eb5e1122850dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f92f7b6e61384683bb999d45136b8efa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa8cd96e3eb04d9a879f35676d832abd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_56c2e8a5e6ee483bbf5a54a7368c9c9e",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fb5d174c45884a62826f12c63c1ff2b2",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "fb5d174c45884a62826f12c63c1ff2b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fca40a7db5fa4738a0e709c6b1fa6edb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fca57b9db0b44aa6938f0fcc689580d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b0a95fa2ee24fc1ab888109e2af83b4",
        "IPY_MODEL_b5479dd74b8e482bba05559fcf4f77e0",
        "IPY_MODEL_0f35ca761eb44933b14011d00926cae4"
       ],
       "layout": "IPY_MODEL_388264b4c21044e1bdcf22c3355f9762",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ff4c6b5f0bdd409f8bfc375e692fad38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a0eacf9c12e14ce3b3a3d332fc6df7ca",
       "placeholder": "​",
       "style": "IPY_MODEL_f86facb586444cf3817eb5e1122850dc",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "ff622e4ca6ff466b9d91d2e31f48c7c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
